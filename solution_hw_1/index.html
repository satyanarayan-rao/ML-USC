<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">  
    <link rel="shortcut icon" href="../img/favicon.ico">

    <title>Homework 1 - Machine Learning</title>

    <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../css/base.css" rel="stylesheet">
    <link href="../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../css/highlight.css">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="..">Machine Learning</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="..">Home</a>
                    </li>
                
                
                
                    <li class="active">
                        <a href="./">Homework 1</a>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li >
                        <a rel="next" href="..">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li class="disabled">
                        <a rel="prev" >
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#naive-bayes">Naive Bayes</a></li>
            <li class="second-level"><a href="#parametric-form-of-naive-bayes-with-gaussian-assumption">Parametric form of Naive Bayes with Gaussian Assumption</a></li>
                
            <li class="second-level"><a href="#parametric-estimation-for-naive-bayes-with-gaussian-assumption">Parametric estimation for Naive Bayes with Gaussian assumption</a></li>
                
        <li class="first-level "><a href="#nearest-neighbor">Nearest Neighbor</a></li>
            <li class="second-level"><a href="#feature-weighting-in-low-dimension">Feature weighting in low dimension</a></li>
                
            <li class="second-level"><a href="#feature-weighting-in-higher-dimensions">Feature weighting in higher dimensions</a></li>
                
        <li class="first-level "><a href="#logistic-regression">Logistic regression</a></li>
            <li class="second-level"><a href="#negative-log-likelihood-or-loss-function">Negative log likelihood or Loss function</a></li>
                
            <li class="second-level"><a href="#proof-for-convexity-of-loss-function">Proof for convexity of loss function</a></li>
                
            <li class="second-level"><a href="#magnitude-of-optimal-w">Magnitude of optimal w</a></li>
                
            <li class="second-level"><a href="#regularized-logistic-regression">Regularized logistic regression</a></li>
                
            <li class="second-level"><a href="#unique-solution-of-the-regularized-loss-function">Unique solution of the regularized loss function</a></li>
                
        <li class="first-level "><a href="#decision-tree">Decision Tree</a></li>
            <li class="second-level"><a href="#building-a-decision-tree">Building a decision tree</a></li>
                
            <li class="second-level"><a href="#relationship-between-two-decision-trees">Relationship between two decision trees</a></li>
                
            <li class="second-level"><a href="#comparison-of-gini-index-and-cross-entropy">Comparison of Gini index and Cross entropy</a></li>
                
        <li class="first-level "><a href="#programming">Programming</a></li>
            <li class="second-level"><a href="#54-performace-comparision">5.4 Performace comparision</a></li>
                
            <li class="second-level"><a href="#55-decision-boundary">5.5 Decision Boundary</a></li>
                
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="naive-bayes">Naive Bayes</h1>
<h2 id="parametric-form-of-naive-bayes-with-gaussian-assumption">Parametric form of Naive Bayes with Gaussian Assumption</h2>
<p>Feature vector <span><span class="MathJax_Preview">X \in R^D</span><script type="math/tex">X \in R^D</script></span> and <span><span class="MathJax_Preview">Y</span><script type="math/tex">Y</script></span> is a binary random vector.</p>
<div>
<div class="MathJax_Preview">Y \sim Bern(\pi)</div>
<script type="math/tex; mode=display">Y \sim Bern(\pi)</script>
</div>
<div>
<div class="MathJax_Preview">X = \{X_1, ..., X_D\}</div>
<script type="math/tex; mode=display">X = \{X_1, ..., X_D\}</script>
</div>
<div>
<div class="MathJax_Preview">P (X_j| Y = y_k ) \sim N(\mu_{jk}, \sigma_j)</div>
<script type="math/tex; mode=display">P (X_j| Y = y_k ) \sim N(\mu_{jk}, \sigma_j)</script>
</div>
<p>Naive Bayes assumes the conditional independence of features given <span><span class="MathJax_Preview">Y</span><script type="math/tex">Y</script></span></p>
<div>
<div class="MathJax_Preview">P(X_i = x_i, X_j = x_j | Y = y_k) = P (X_i = x_i | Y =y_k)*P(X_j = x_j| Y= y_k) \space \forall i \neq j</div>
<script type="math/tex; mode=display">P(X_i = x_i, X_j = x_j | Y = y_k) = P (X_i = x_i | Y =y_k)*P(X_j = x_j| Y= y_k) \space \forall i \neq j</script>
</div>
<p>Here we have to show that the posterior probability can be written as
the posterior of logistic regression.Proceeding with above assumptions.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(Y = 1 | X ) = \frac{P(X| Y = 1)*P(Y = 1)}{P(X)}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(Y = 1 | X ) = \frac{P(X| Y = 1)*P(Y = 1)}{P(X)}\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(X) = P(X|Y = 0)*P(Y = 0) + P (X| Y = 1)* P(Y = 1 )\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(X) = P(X|Y = 0)*P(Y = 0) + P (X| Y = 1)* P(Y = 1 )\end{aligned}</script>
</div>
<p>Using eq. (1.2) in (1.1) and bringing the numerator to denominator
simplifies eq. (1) to the following.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(Y = 1 | X ) = \frac{1}{1 + \frac{P(X| Y = 0)*P(Y = 0)}{P(X| Y = 1 )*P(Y = 1)}}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(Y = 1 | X ) = \frac{1}{1 + \frac{P(X| Y = 0)*P(Y = 0)}{P(X| Y = 1 )*P(Y = 1)}}\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(X | Y = y_k) = \prod_{i=1}^D P (X_i| Y = y_k)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(X | Y = y_k) = \prod_{i=1}^D P (X_i| Y = y_k)\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(X_i | Y = y_k) = \frac{1}{(2\pi)^{1/2}\sigma_i}exp\left(-\frac{(X_i - \mu_{ik})^2}{2\sigma_{i}^2}\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(X_i | Y = y_k) = \frac{1}{(2\pi)^{1/2}\sigma_i}exp\left(-\frac{(X_i - \mu_{ik})^2}{2\sigma_{i}^2}\right)\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
P (Y = 1) = \pi , P (Y = 0 ) = 1 -\pi\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P (Y = 1) = \pi , P (Y = 0 ) = 1 -\pi\end{aligned}</script>
</div>
<p>Using eq. (1.4),(1.5) and (1.6) in eq. (1.3) we get the simplified form
as following</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(Y = 1 | X ) = \frac{1}
{1 + \frac{1 - \pi}
{\pi} *
\frac{\prod_{i = 1 }^{D} exp \left(- \frac{(X_i - \mu_{i0})^2}
{2\sigma_i^2}    \right)     }
{\prod_{i = 1 }^{D} exp \left(- \frac{(X_i - \mu_{i1})^2}
{2\sigma_i^2}    \right) } }\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(Y = 1 | X ) = \frac{1}
{1 + \frac{1 - \pi}
{\pi} *
\frac{\prod_{i = 1 }^{D} exp \left(- \frac{(X_i - \mu_{i0})^2}
{2\sigma_i^2}    \right)     }
{\prod_{i = 1 }^{D} exp \left(- \frac{(X_i - \mu_{i1})^2}
{2\sigma_i^2}    \right) } }\end{aligned}</script>
</div>
<p>Solving further to simpler terms by assuming the following:</p>
<div>
<div class="MathJax_Preview">Z_{i0} = \frac{(X_i - \mu_{i0})^2}
{2\sigma_i^2}</div>
<script type="math/tex; mode=display">Z_{i0} = \frac{(X_i - \mu_{i0})^2}
{2\sigma_i^2}</script>
</div>
<div>
<div class="MathJax_Preview">Z_{i1} = \frac{(X_i - \mu_{i1})^2}
{2\sigma_i^2}</div>
<script type="math/tex; mode=display">Z_{i1} = \frac{(X_i - \mu_{i1})^2}
{2\sigma_i^2}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
 Z_{i1} - Z_{i0}  = \frac{(2X_i - (\mu_{i0} + \mu_{i1}) )*(\mu_{i0} - \mu_{i1})}{2\sigma_i^2}
 \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
 Z_{i1} - Z_{i0}  = \frac{(2X_i - (\mu_{i0} + \mu_{i1}) )*(\mu_{i0} - \mu_{i1})}{2\sigma_i^2}
 \end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
= \frac{X_i*(\mu_{i0} - \mu_{i1})}{\sigma_i^2}  - \frac{(\mu_{i0}^2 - \mu_{i1}^2)}{2\sigma_i^2}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
= \frac{X_i*(\mu_{i0} - \mu_{i1})}{\sigma_i^2}  - \frac{(\mu_{i0}^2 - \mu_{i1}^2)}{2\sigma_i^2}\end{aligned}</script>
</div>
<p>eq. (1.7) can be rewritten using simplified terms like <span><span class="MathJax_Preview">Z_{i1} - Z_{i0}</span><script type="math/tex">Z_{i1} - Z_{i0}</script></span>
as following.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(Y = 1 | X ) = \frac{1}
{1 + \frac{1-\pi}
{\pi}*\prod_{i=1}^{D}exp \left( \frac{-(\mu_{i0}^2 - \mu_{i1}^2)}
{2\sigma_i^2} + \frac{(\mu_{i0} - \mu_{i1})}{\sigma_i^2}*X_i   \right)}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(Y = 1 | X ) = \frac{1}
{1 + \frac{1-\pi}
{\pi}*\prod_{i=1}^{D}exp \left( \frac{-(\mu_{i0}^2 - \mu_{i1}^2)}
{2\sigma_i^2} + \frac{(\mu_{i0} - \mu_{i1})}{\sigma_i^2}*X_i   \right)}\end{aligned}</script>
</div>
<p>Product term in denominator of eq. (1.8) can be substituted with summand
inside the exponential expression, and <span><span class="MathJax_Preview">\frac{1-\pi}{\pi}</span><script type="math/tex">\frac{1-\pi}{\pi}</script></span> can be
written as <span><span class="MathJax_Preview">exp\left(-log\frac{\pi}{1 - \pi}\right).</span><script type="math/tex">exp\left(-log\frac{\pi}{1 - \pi}\right).</script></span> Doing above
changes to eq. (1.8) it reduces to the following form.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(Y = 1 | X ) = \frac{1}
{1 + exp \left\lbrace - \left(log\frac{\pi}{1 - \pi}
+ \sum_{i = 1}^{D}\frac{(\mu_{i0}^2 - \mu_{i1}^2)}
{2\sigma_i^2}
\right)
+ \sum_{i = 1}^{D}\frac{(\mu_{i0} - \mu_{i1})}{\sigma_i^2}*X_i
\right\rbrace}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(Y = 1 | X ) = \frac{1}
{1 + exp \left\lbrace - \left(log\frac{\pi}{1 - \pi}
+ \sum_{i = 1}^{D}\frac{(\mu_{i0}^2 - \mu_{i1}^2)}
{2\sigma_i^2}
\right)
+ \sum_{i = 1}^{D}\frac{(\mu_{i0} - \mu_{i1})}{\sigma_i^2}*X_i
\right\rbrace}\end{aligned}</script>
</div>
<p>We can see clearly in eq. (1.9) that the posterior probability is taking
the form of logistic regression. Comparing with the logistic regression
expression. We can write the parameters as follows:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\omega_0 = \left(log\frac{\pi}{1 - \pi}
+ \sum_{i = 1}^{D}\frac{(\mu_{i0}^2 - \mu_{i1}^2)}
{2\sigma_i^2}
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\omega_0 = \left(log\frac{\pi}{1 - \pi}
+ \sum_{i = 1}^{D}\frac{(\mu_{i0}^2 - \mu_{i1}^2)}
{2\sigma_i^2}
\right)\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\textbf{w} = \left[\frac{(\mu_{00} - \mu_{01})}{\sigma_1^2} , ... , \frac{(\mu_{D0} - \mu_{D1})}{\sigma_D^2}\right]^T\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\textbf{w} = \left[\frac{(\mu_{00} - \mu_{01})}{\sigma_1^2} , ... , \frac{(\mu_{D0} - \mu_{D1})}{\sigma_D^2}\right]^T\end{aligned}</script>
</div>
<h2 id="parametric-estimation-for-naive-bayes-with-gaussian-assumption">Parametric estimation for Naive Bayes with Gaussian assumption</h2>
<p>We have training set of size <span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> of the form
<span><span class="MathJax_Preview">(\textbf{x}_\textbf{i}, y_i)</span><script type="math/tex">(\textbf{x}_\textbf{i}, y_i)</script></span>, where</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\textbf{x}_\textbf{i} = (x_{i1}, ..., x_{iD})^T, y_i \in \{0,1\}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\textbf{x}_\textbf{i} = (x_{i1}, ..., x_{iD})^T, y_i \in \{0,1\}\end{aligned}</script>
</div>
<p>Since we have to estimate the distribution parameters such as
<span><span class="MathJax_Preview">\pi_i, \mu_{jk},</span><script type="math/tex">\pi_i, \mu_{jk},</script></span> and <span><span class="MathJax_Preview">\sigma_j</span><script type="math/tex">\sigma_j</script></span>. We can do this by writing log
likelihood and differentiating w.r.t corresponding parameters and set to
zero to get the values. Following derivation are for the log likelihood
and parameter estimation.</p>
<p>Joint probability can be written as</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(X, Y ) = \prod_{i = 1 }^{N} P (X_i, Y_i)= \prod_{i = 1 }^{N} P(X_i | Y_i = y_k)*P (Y_i = y_k)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(X, Y ) = \prod_{i = 1 }^{N} P (X_i, Y_i)= \prod_{i = 1 }^{N} P(X_i | Y_i = y_k)*P (Y_i = y_k)\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
= \prod_{i = 1}^{N}P(Y_i = y_k)\prod_{j = 1}^{D}P(X_{ij} = x_{ij} | Y_i = y_k)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
= \prod_{i = 1}^{N}P(Y_i = y_k)\prod_{j = 1}^{D}P(X_{ij} = x_{ij} | Y_i = y_k)\end{aligned}</script>
</div>
<p>In above deduction we have used the naive bayes assumption. Now we know
the following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(Y_i = y_k) = \pi^{y_k}*(1-\pi)^{(1-y_k)}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(Y_i = y_k) = \pi^{y_k}*(1-\pi)^{(1-y_k)}\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(X_{ij} = x_{ij} | Y_i = y_k) = \frac{1}{(2\pi)^{1/2}\sigma_j}exp\left(-\frac{(x_{ij} - \mu_{jk})^2}{2\sigma_{j}^2}\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(X_{ij} = x_{ij} | Y_i = y_k) = \frac{1}{(2\pi)^{1/2}\sigma_j}exp\left(-\frac{(x_{ij} - \mu_{jk})^2}{2\sigma_{j}^2}\right)\end{aligned}</script>
</div>
<p>Since we know that log likelihood is the log of joint pdf. We can take
the log on both side of eq. (1.10) to get the log likelihood.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
l(\theta | X, Y) = logP(X,Y) = \sum_{i = 1}^{N}\left( log P(Y_i = y_k) + \sum_{j = 1}^{D} log P (X_{ij} = x_{ij} | Y_i = y_k)
\right)  \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
l(\theta | X, Y) = logP(X,Y) = \sum_{i = 1}^{N}\left( log P(Y_i = y_k) + \sum_{j = 1}^{D} log P (X_{ij} = x_{ij} | Y_i = y_k)
\right)  \end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
= \sum_{i = 1}^{N} \left( y_klog\pi + (1-y_k)log(1 - \pi) + \sum_{j = 1}^{D} \left( -log ( (2\pi)^{1/2}\sigma_j - \frac{(x_{ij} - \mu_{jk})^2}
{2\sigma_j^2}
\right)
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
= \sum_{i = 1}^{N} \left( y_klog\pi + (1-y_k)log(1 - \pi) + \sum_{j = 1}^{D} \left( -log ( (2\pi)^{1/2}\sigma_j - \frac{(x_{ij} - \mu_{jk})^2}
{2\sigma_j^2}
\right)
\right)\end{aligned}</script>
</div>
<p>Suppose there are m data points with label 1 and N-m with label 0, above
equation can be rewritten as following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
l(\theta | X, Y) = \sum_{i:Y_i = y_k = 1}y_klog\pi  + \sum_{i:Y_i = y_k = 0}(1-y_k)log(1-\pi) \\ + \sum_{i:Y_i = y_k = 1}\sum_{j=1}^{D}\left( -log (2\pi)^{1/2}\sigma_j - \frac{(x_{ij} - \mu_{j1})^2}{2\sigma} 
\right) \\ +  \sum_{i:Y_i = y_k = 0}\sum_{j=1}^{D}\left( -log (2\pi)^{1/2}\sigma_j - \frac{(x_{ij} - \mu_{j0})^2}{2\sigma} 
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
l(\theta | X, Y) = \sum_{i:Y_i = y_k = 1}y_klog\pi  + \sum_{i:Y_i = y_k = 0}(1-y_k)log(1-\pi) \\ + \sum_{i:Y_i = y_k = 1}\sum_{j=1}^{D}\left( -log (2\pi)^{1/2}\sigma_j - \frac{(x_{ij} - \mu_{j1})^2}{2\sigma} 
\right) \\ +  \sum_{i:Y_i = y_k = 0}\sum_{j=1}^{D}\left( -log (2\pi)^{1/2}\sigma_j - \frac{(x_{ij} - \mu_{j0})^2}{2\sigma} 
\right)\end{aligned}</script>
</div>
<p>Calculating MLE for <span><span class="MathJax_Preview">\pi</span><script type="math/tex">\pi</script></span>:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\hat{\pi} = \left\lbrace \pi: \frac{\partial l(\theta|X,Y)}{\partial\pi} = 0  \right\rbrace\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\pi} = \left\lbrace \pi: \frac{\partial l(\theta|X,Y)}{\partial\pi} = 0  \right\rbrace\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial l(\theta|X,Y)}{\partial\pi} = \frac{m}{\pi} - \frac{(N - m)}{1 - \pi} + 0 + 0  \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial l(\theta|X,Y)}{\partial\pi} = \frac{m}{\pi} - \frac{(N - m)}{1 - \pi} + 0 + 0  \end{aligned}</script>
</div>
<p>Equating the above equation to zero and solving for <span><span class="MathJax_Preview">\pi</span><script type="math/tex">\pi</script></span></p>
<div>
<div class="MathJax_Preview">\begin{aligned}
m(1 - \pi)  - (N-m)\pi = 0 
\implies m - N\pi = 0 
\implies \pi = \frac{m}{N} \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
m(1 - \pi)  - (N-m)\pi = 0 
\implies m - N\pi = 0 
\implies \pi = \frac{m}{N} \end{aligned}</script>
</div>
<p>So the likelihood parameter estimation of <span><span class="MathJax_Preview">\pi</span><script type="math/tex">\pi</script></span> is:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\hat{\pi} = \frac{m}{N} = \frac{\#label = 1 }{N}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\pi} = \frac{m}{N} = \frac{\#label = 1 }{N}\end{aligned}</script>
</div>
<p>Likelihood for <span><span class="MathJax_Preview">\mu_{jk}</span><script type="math/tex">\mu_{jk}</script></span>:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\hat{\mu}_{jk} = \left\lbrace \mu_{jk}: \frac{\partial l(\theta|X,Y)}{\partial\mu_{jk}} = 0  \right\rbrace\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\mu}_{jk} = \left\lbrace \mu_{jk}: \frac{\partial l(\theta|X,Y)}{\partial\mu_{jk}} = 0  \right\rbrace\end{aligned}</script>
</div>
<p>We can do this in two parts, k = 0 and k = 1 for k = 0, we shall only
have the fourth term in partial differentiation, other term will give
zeros.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial l(\theta|X,Y)}{\partial\pi}  = \sum_{i:Y_i = y_k = 0}- \frac{(x_{ij} - \mu_{jo})}{\sigma_j^2}*(-1) = 0 \\
\implies \sum_{i:Y_i = y_k = 0}(x_{ij} - \mu_{jo}) = 0 \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial l(\theta|X,Y)}{\partial\pi}  = \sum_{i:Y_i = y_k = 0}- \frac{(x_{ij} - \mu_{jo})}{\sigma_j^2}*(-1) = 0 \\
\implies \sum_{i:Y_i = y_k = 0}(x_{ij} - \mu_{jo}) = 0 \end{aligned}</script>
</div>
<p>From above assumption we know the count of zero labels are <span><span class="MathJax_Preview">N-m</span><script type="math/tex">N-m</script></span> Solving
above equality gives us the following</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
(N-m)*\mu_{j0} = \sum_{i:Y_i = y_k = 0} x_{ij}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
(N-m)*\mu_{j0} = \sum_{i:Y_i = y_k = 0} x_{ij}\end{aligned}</script>
</div>
<p>which gives us</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\hat{\mu}_{j0} = \frac{\sum_{i:Y_i = y_k = 0} x_{ij}}{(N-m)}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\mu}_{j0} = \frac{\sum_{i:Y_i = y_k = 0} x_{ij}}{(N-m)}\end{aligned}</script>
</div>
<p>Similarly we get the estimate for <span><span class="MathJax_Preview">\mu_{j1}</span><script type="math/tex">\mu_{j1}</script></span></p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\hat{\mu}_{j1} = \frac{\sum_{i:Y_i = y_k = 1} x_{ij}}{(m)}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\mu}_{j1} = \frac{\sum_{i:Y_i = y_k = 1} x_{ij}}{(m)}\end{aligned}</script>
</div>
<p>Likelihood for <span><span class="MathJax_Preview">\sigma_{j}</span><script type="math/tex">\sigma_{j}</script></span>:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\hat{\sigma}_{j} = \left\lbrace \sigma_{j}: \frac{\partial l(\theta|X,Y)}{\partial\sigma_{j}} = 0  \right\rbrace\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\hat{\sigma}_{j} = \left\lbrace \sigma_{j}: \frac{\partial l(\theta|X,Y)}{\partial\sigma_{j}} = 0  \right\rbrace\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial l(\theta|X,Y)}{\partial\sigma_{j}}  = \sum_{i:Y_i =y_k = 1} \left( -\frac{1}{\sigma_{j}} + \frac{(x_{ij} - \mu_{j1})^2}{\sigma_{j}^3}
\right)\\
+ \sum_{i:Y_i = y_k = 0} \left( -\frac{1}{\sigma_{j}} + \frac{(x_{ij} - \mu_{j0})^2}{\sigma_{j}^3}
\right)\\
= - \frac{N}{\sigma_{j}} + \frac{\sum_{i = 1 }^{N}\left( y_k (x_{ij} - \mu_{j1})^2 + (1 - y_k ) (x_{ij} - \mu_{j0})^2\right)}
{\sigma_{j}^3}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial l(\theta|X,Y)}{\partial\sigma_{j}}  = \sum_{i:Y_i =y_k = 1} \left( -\frac{1}{\sigma_{j}} + \frac{(x_{ij} - \mu_{j1})^2}{\sigma_{j}^3}
\right)\\
+ \sum_{i:Y_i = y_k = 0} \left( -\frac{1}{\sigma_{j}} + \frac{(x_{ij} - \mu_{j0})^2}{\sigma_{j}^3}
\right)\\
= - \frac{N}{\sigma_{j}} + \frac{\sum_{i = 1 }^{N}\left( y_k (x_{ij} - \mu_{j1})^2 + (1 - y_k ) (x_{ij} - \mu_{j0})^2\right)}
{\sigma_{j}^3}\end{aligned}</script>
</div>
<p>Equating it to zero will give the following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\sigma_{j}^2 = \frac{\sum_{i = 1 }^{N}\left( y_k (x_{ij} - \mu_{j1})^2 + (1 - y_k ) (x_{ij} - \mu_{j0})^2\right)}
{N}\\
\implies \hat{\sigma}_{j} = \sqrt{\frac{\sum_{i = 1 }^{N}\left( y_k (x_{ij} - \mu_{j1})^2 + (1 - y_k ) (x_{ij} - \mu_{j0})^2\right)}
{N}}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\sigma_{j}^2 = \frac{\sum_{i = 1 }^{N}\left( y_k (x_{ij} - \mu_{j1})^2 + (1 - y_k ) (x_{ij} - \mu_{j0})^2\right)}
{N}\\
\implies \hat{\sigma}_{j} = \sqrt{\frac{\sum_{i = 1 }^{N}\left( y_k (x_{ij} - \mu_{j1})^2 + (1 - y_k ) (x_{ij} - \mu_{j0})^2\right)}
{N}}\end{aligned}</script>
</div>
<h1 id="nearest-neighbor">Nearest Neighbor</h1>
<h2 id="feature-weighting-in-low-dimension">Feature weighting in low dimension</h2>
<p>Feature weighting is required in case of noise, because noise affect the
euclidean distance measures which can lead to poor performance of KNN.
This is also known as Achilles’ heel of KNN. In case of low dimension
<span><span class="MathJax_Preview">D = 3</span><script type="math/tex">D = 3</script></span> with discretized values of weights in each dimension. We can do
grid search to look for the optimal weights which can give the best
training accuracy. The procedure explained below can be used to find the
optimal weights for the features. Here we have following assumption</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
X_i = \left(x_{i1}, x_{i2}, x_{i3}\right)^T\\
W = \left(w_1, w_2, w_3\right)\\
w_i \in \{w_{i1}, w_{i2}, .,.,., w_{ik}\}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
X_i = \left(x_{i1}, x_{i2}, x_{i3}\right)^T\\
W = \left(w_1, w_2, w_3\right)\\
w_i \in \{w_{i1}, w_{i2}, .,.,., w_{ik}\}\end{aligned}</script>
</div>
<p>The weights has been discretized to <span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> values. We can just do grid
search by using following pseudo code. opt (W) = {} for
<span><span class="MathJax_Preview">w_1 = w_{11}:w_{1k}</span><script type="math/tex">w_1 = w_{11}:w_{1k}</script></span></p>
<p>for <span><span class="MathJax_Preview">w_2 = w_{21}:w_{2k}</span><script type="math/tex">w_2 = w_{21}:w_{2k}</script></span></p>
<p>for <span><span class="MathJax_Preview">w_3 = w_{31}:w_{3k}</span><script type="math/tex">w_3 = w_{31}:w_{3k}</script></span></p>
<p>for <span><span class="MathJax_Preview">i = 1:N</span><script type="math/tex">i = 1:N</script></span></p>
<p>for <span><span class="MathJax_Preview">j\neq i = 1:N</span><script type="math/tex">j\neq i = 1:N</script></span></p>
<p>compute <span><span class="MathJax_Preview">d(X_i, X_j)</span><script type="math/tex">d(X_i, X_j)</script></span></p>
<p>end</p>
<p>end</p>
<p>Compute the training accuracy and update opt(W) if accuracy is</p>
<p>better.</p>
<p>end</p>
<p>end</p>
<p>end</p>
<p>For this approach we can also use dynamic programming to reduce the
computation, we can maintain the <span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span>x<span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span>x<span><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span> matrix with entries of
euclidean distances of feature vectors. Afterwards we can use this
matrix as lookup table and just multiply with the weights to get the
weighted feature distance. Using the Dynamic programming approach will
lead to following complexity: Time complexity:</p>
<div>
<div class="MathJax_Preview">O(k^3)</div>
<script type="math/tex; mode=display">O(k^3)</script>
</div>
<p>Space complexity:</p>
<div>
<div class="MathJax_Preview">O(N^2)</div>
<script type="math/tex; mode=display">O(N^2)</script>
</div>
<h2 id="feature-weighting-in-higher-dimensions">Feature weighting in higher dimensions</h2>
<p>In higher dimension above approach of finding optimal weight will lead
to exponential time complexity <span><span class="MathJax_Preview">O(k^D)</span><script type="math/tex">O(k^D)</script></span>. This is curse of
dimensionality. As being instructed by TA that we do not have to use any
statistical approach to construct the method for assigning weights to
features (We have to design algorithm). If we present the weighted
distances calculation in matrix form, it will appear as follows:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\hat{Label}(X_1) = Label \left(X_j : j = \min_{j}
\begin{bmatrix}
w_1 &amp;  . &amp;  w_D
\end{bmatrix}
\begin{bmatrix}
(x_{11} - x_{21})^2 &amp;  (x_{11} - x_{31})^2 &amp;  . &amp; (x_{11} - x_{N1})^2 \\
(x_{12} - x_{22})^2  &amp; (x_{12} - x_{32})^2 &amp;  . &amp; (x_{12} - x_{N2})^2 \\
.  &amp; . &amp; .  &amp; . &amp; \\
.  &amp; . &amp; .  &amp; . &amp; \\
(x_{1D} - x_{2D})^2 &amp; (x_{1D} - x_{3D})^2  &amp;  . &amp; (x_{1D} - x_{ND})^2
\end{bmatrix}
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\hat{Label}(X_1) = Label \left(X_j : j = \min_{j}
\begin{bmatrix}
w_1 &  . &  w_D
\end{bmatrix}
\begin{bmatrix}
(x_{11} - x_{21})^2 &  (x_{11} - x_{31})^2 &  . & (x_{11} - x_{N1})^2 \\
(x_{12} - x_{22})^2  & (x_{12} - x_{32})^2 &  . & (x_{12} - x_{N2})^2 \\
.  & . & .  & . & \\
.  & . & .  & . & \\
(x_{1D} - x_{2D})^2 & (x_{1D} - x_{3D})^2  &  . & (x_{1D} - x_{ND})^2
\end{bmatrix}
\right)\end{aligned}</script>
</div>
<p>We do above calculation for every data point. Since there are <span><span class="MathJax_Preview">k^D</span><script type="math/tex">k^D</script></span>
possible matrices <span><span class="MathJax_Preview">[w_1 ... w_D ]</span><script type="math/tex">[w_1 ... w_D ]</script></span>, we can not calculate this in
polynomial time. One way to select meaningful features from the haystack
is to calculate the training accuracy on each individual feature by
setting other’s weight to zero. we assign the weight to be training
accuracy of that individual feature. We can decide how many feature we
have to take into consideration. This will result into the limited
features with weight assigned on each of them. <strong>2<sup>nd</sup> method</strong> Objective
function for above problem will look like following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
J(W) = \sum_{i=1}^{N}\left( \hat{Label}(X_i) - Label (X_i) \right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
J(W) = \sum_{i=1}^{N}\left( \hat{Label}(X_i) - Label (X_i) \right)\end{aligned}</script>
</div>
<p>The characteristic of above objective function is a curve in higher
dimension with multiple local minimum. We can use the gradient descent
approach to find the local minima’s we can start with different set of
random weight vectors and try to find the different minimum, select the
best one out of these and return those weight vectors as weighted
feature vector. This is a polynomial time algorithm, but of course this
may not give the optimal solution.</p>
<h1 id="logistic-regression">Logistic regression</h1>
<h2 id="negative-log-likelihood-or-loss-function">Negative log likelihood or Loss function</h2>
<div>
<div class="MathJax_Preview">\begin{aligned}
\mathcal{L}(\textbf{w}) = -\log\left( \prod_{1= 1}^{n}P (Y = Y_i | \textbf{X} = \textbf{x}_{\textbf{i}})
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L}(\textbf{w}) = -\log\left( \prod_{1= 1}^{n}P (Y = Y_i | \textbf{X} = \textbf{x}_{\textbf{i}})
\right)\end{aligned}</script>
</div>
<p>We know that</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P (Y = 1 | \textbf{X} = \textbf{x}_{\textbf{i}} ) = \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x}_{\textbf{i}})} = \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}})\\\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P (Y = 1 | \textbf{X} = \textbf{x}_{\textbf{i}} ) = \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x}_{\textbf{i}})} = \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}})\\\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
P (Y = 0 | \textbf{X} = \textbf{x}_{\textbf{i}} ) =  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}})\\\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P (Y = 0 | \textbf{X} = \textbf{x}_{\textbf{i}} ) =  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}})\\\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
P (Y = y_i | \textbf{X} = \textbf{x}_{\textbf{i}} ) = \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}})^{y_i} (  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) )^{1-y_i}\\
\log P (Y = y_i | \textbf{X} = \textbf{x}_{\textbf{i}} )  = y_i \log \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) + (1-y_i)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) )\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P (Y = y_i | \textbf{X} = \textbf{x}_{\textbf{i}} ) = \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}})^{y_i} (  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) )^{1-y_i}\\
\log P (Y = y_i | \textbf{X} = \textbf{x}_{\textbf{i}} )  = y_i \log \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) + (1-y_i)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) )\end{aligned}</script>
</div>
<p>Writing the negative log likelihood in simpler form using above
expression</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\mathcal{L}(\textbf{w}) = - \sum_{i = 1 }^{n} \log(P (Y = y_i| \textbf{X} = \textbf{x}_{\textbf{i}}))\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L}(\textbf{w}) = - \sum_{i = 1 }^{n} \log(P (Y = y_i| \textbf{X} = \textbf{x}_{\textbf{i}}))\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\mathcal{L}(\textbf{w}) = - \sum_{i = 1 }^{n} \left(y_i \log \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) + (1-y_i)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) ) 
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L}(\textbf{w}) = - \sum_{i = 1 }^{n} \left(y_i \log \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) + (1-y_i)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}_{\textbf{i}}) ) 
\right)\end{aligned}</script>
</div>
<h2 id="proof-for-convexity-of-loss-function">Proof for convexity of loss function</h2>
<p>To prove the convexity we are going to show that the hessian matrix will
be positive semidefinite. In order to make the derivation simpler we are
going to use the property of convex functions. If <span><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> and <span><span class="MathJax_Preview">g(x)</span><script type="math/tex">g(x)</script></span> are
two convex function then their sum <span><span class="MathJax_Preview">h(x)</span><script type="math/tex">h(x)</script></span> is also going to be the convex
function Proof: As we know from the property of convex function</p>
<div>
<div class="MathJax_Preview">f(\lambda x_1 + (1-\lambda)x_2 ) &lt;= \lambda f(x_1) + (1 - \lambda)f(x_2)</div>
<script type="math/tex; mode=display">f(\lambda x_1 + (1-\lambda)x_2 ) <= \lambda f(x_1) + (1 - \lambda)f(x_2)</script>
</div>
<div>
<div class="MathJax_Preview">g(\lambda x_1 + (1-\lambda)x_2 ) &lt;= \lambda g(x_1) + (1 - \lambda)g(x_2)</div>
<script type="math/tex; mode=display">g(\lambda x_1 + (1-\lambda)x_2 ) <= \lambda g(x_1) + (1 - \lambda)g(x_2)</script>
</div>
<p>Adding above two equations we get the following:</p>
<div>
<div class="MathJax_Preview">f(\lambda x_1 + (1-\lambda)x_2 ) + g(\lambda x_1 + (1-\lambda)x_2 ) &lt;= \lambda f(x_1) + (1 - \lambda)f(x_2) + \lambda g(x_1) + (1 - \lambda)g(x_2)</div>
<script type="math/tex; mode=display">f(\lambda x_1 + (1-\lambda)x_2 ) + g(\lambda x_1 + (1-\lambda)x_2 ) <= \lambda f(x_1) + (1 - \lambda)f(x_2) + \lambda g(x_1) + (1 - \lambda)g(x_2)</script>
</div>
<div>
<div class="MathJax_Preview">h(\lambda x_1 + (1-\lambda)x_2 )) &lt;= \lambda h(x_1) + (1 - \lambda)h(x_2)</div>
<script type="math/tex; mode=display">h(\lambda x_1 + (1-\lambda)x_2 )) <= \lambda h(x_1) + (1 - \lambda)h(x_2)</script>
</div>
<p>So <span><span class="MathJax_Preview">h(x)</span><script type="math/tex">h(x)</script></span> is also convex. Multiplying by any positive constant preserves
the convexity. Considering just one term from loss function.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
T(\textbf{w,x},y) = - \left(y \log \sigma(\textbf{w}^{T}\textbf{x}) + (1-y)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}) ) 
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
T(\textbf{w,x},y) = - \left(y \log \sigma(\textbf{w}^{T}\textbf{x}) + (1-y)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}) ) 
\right)\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\mathcal{L}(\textbf{w}) = \sum_{i = 1}^{n}T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L}(\textbf{w}) = \sum_{i = 1}^{n}T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i)\end{aligned}</script>
</div>
<p>If we prove that $T(\textbf{w,x},y) $ is convex then we can say that
<span><span class="MathJax_Preview">\mathcal{L}(\textbf{w})</span><script type="math/tex">\mathcal{L}(\textbf{w})</script></span> is convex (by above proved lemma).</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
T(\textbf{w,x},y) = - \left(y \log \sigma(\textbf{w}^{T}\textbf{x}) + (1-y)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}) ) 
\right)\\
= -y\log \left(\frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right) - (1-y)\log\left(1 - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right)\\
=y\log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right) - (1-y)\log\left(\frac{\exp(-\textbf{w}^{T}\textbf{x})}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right)\\
= y\log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right) - (1-y) \left( -\textbf{w}^{T}\textbf{x} - \log\left(  1 + \exp(-\textbf{w}^{T}\textbf{x}
\right)
\right)\\
=(1-y) \textbf{w}^{T}\textbf{x} + \log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
T(\textbf{w,x},y) = - \left(y \log \sigma(\textbf{w}^{T}\textbf{x}) + (1-y)\log(  1 - \sigma(\textbf{w}^{T}\textbf{x}) ) 
\right)\\
= -y\log \left(\frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right) - (1-y)\log\left(1 - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right)\\
=y\log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right) - (1-y)\log\left(\frac{\exp(-\textbf{w}^{T}\textbf{x})}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right)\\
= y\log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right) - (1-y) \left( -\textbf{w}^{T}\textbf{x} - \log\left(  1 + \exp(-\textbf{w}^{T}\textbf{x}
\right)
\right)\\
=(1-y) \textbf{w}^{T}\textbf{x} + \log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right)\end{aligned}</script>
</div>
<p>Finally we get:</p>
<div>
<div class="MathJax_Preview">T(\textbf{w,x},y) = (1-y) \textbf{w}^{T}\textbf{x} + \log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right)</div>
<script type="math/tex; mode=display">T(\textbf{w,x},y) = (1-y) \textbf{w}^{T}\textbf{x} + \log \left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right)</script>
</div>
<p>We need to find the hessian<span><span class="MathJax_Preview">(H)</span><script type="math/tex">(H)</script></span> of this which is basically <span><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span>x<span><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span>
matrix and the element <span><span class="MathJax_Preview">H(j,k)</span><script type="math/tex">H(j,k)</script></span> is:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
H(j,k) = \frac{\partial^2 T(\textbf{w,x},y)}{\partial w_j \partial w_k}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
H(j,k) = \frac{\partial^2 T(\textbf{w,x},y)}{\partial w_j \partial w_k}\end{aligned}</script>
</div>
<p>Now calculating the <span><span class="MathJax_Preview">H(j,k)</span><script type="math/tex">H(j,k)</script></span>. Calculating the first derivative.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial T(\textbf{w,x},y)}{\partial w_j} = \frac{-x_j * \exp(-\textbf{w}^{T}\textbf{x})}{ 1 + \exp(-\textbf{w}^{T}\textbf{x})} + x_j(1-y)\\
= -x_j\left( 1 - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right) +x_j(1-y)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial T(\textbf{w,x},y)}{\partial w_j} = \frac{-x_j * \exp(-\textbf{w}^{T}\textbf{x})}{ 1 + \exp(-\textbf{w}^{T}\textbf{x})} + x_j(1-y)\\
= -x_j\left( 1 - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}
\right) +x_j(1-y)\end{aligned}</script>
</div>
<p>Differentiating above w.r.t. <span><span class="MathJax_Preview">w_k</span><script type="math/tex">w_k</script></span></p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial^2 T(\textbf{w,x},y)}{\partial w_j \partial w_k} = 0 + x_j \left[ \frac{(-1)*\exp(-\textbf{w}^{T}\textbf{x})*(-x_k) }{\left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right)^2}
\right] + 0 \\
= x_j * \sigma(\textbf{w}^{T}\textbf{x})*(1-\sigma(\textbf{w}^{T}\textbf{x}))*x_k\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial^2 T(\textbf{w,x},y)}{\partial w_j \partial w_k} = 0 + x_j \left[ \frac{(-1)*\exp(-\textbf{w}^{T}\textbf{x})*(-x_k) }{\left( 1 + \exp(-\textbf{w}^{T}\textbf{x})
\right)^2}
\right] + 0 \\
= x_j * \sigma(\textbf{w}^{T}\textbf{x})*(1-\sigma(\textbf{w}^{T}\textbf{x}))*x_k\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial^2 T(\textbf{w,x},y)}{\partial w_j \partial w_k} = x_j * \sigma(\textbf{w}^{T}\textbf{x})*(1-\sigma(\textbf{w}^{T}\textbf{x}))*x_k \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial^2 T(\textbf{w,x},y)}{\partial w_j \partial w_k} = x_j * \sigma(\textbf{w}^{T}\textbf{x})*(1-\sigma(\textbf{w}^{T}\textbf{x}))*x_k \end{aligned}</script>
</div>
<p>Note: <span><span class="MathJax_Preview">\sigma(x) &gt;= 0 \hspace{8pt} \forall x</span><script type="math/tex">\sigma(x) >= 0 \hspace{8pt} \forall x</script></span></p>
<p>If we fill out the hessian matrix it will look like following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
H = \sigma(\textbf{w}^{T}\textbf{x})*(1-\sigma(\textbf{w}^{T}\textbf{x})) \begin{bmatrix}
x_1^2 &amp; x_1x_2 &amp;  . &amp; .&amp; . &amp; x_1x_D\\
.  &amp; . &amp; . &amp; . &amp; . &amp; . &amp; \\
.  &amp; . &amp; . &amp; . &amp; . &amp; . &amp; \\
.  &amp; . &amp; . &amp; . &amp; . &amp; . &amp; \\
x_Dx_1 &amp; x_Dx_2 &amp; . &amp; . &amp; . &amp; x_D^2
\end{bmatrix}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
H = \sigma(\textbf{w}^{T}\textbf{x})*(1-\sigma(\textbf{w}^{T}\textbf{x})) \begin{bmatrix}
x_1^2 & x_1x_2 &  . & .& . & x_1x_D\\
.  & . & . & . & . & . & \\
.  & . & . & . & . & . & \\
.  & . & . & . & . & . & \\
x_Dx_1 & x_Dx_2 & . & . & . & x_D^2
\end{bmatrix}\end{aligned}</script>
</div>
<p>Let
$ K =  \sigma(\textbf{w}<sup>{T}\textbf{x})*(1-\sigma(\textbf{w}</sup>{T}\textbf{x}))$
which is always greater than or equal to zero, matrix in above
expression can be decomposed into <span><span class="MathJax_Preview">XX^T</span><script type="math/tex">XX^T</script></span> where X is a column matrix. So
<span><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span> can be rewritten as</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
H = K XX^T\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
H = K XX^T\end{aligned}</script>
</div>
<p>where</p>
<div>
<div class="MathJax_Preview">X = \begin{bmatrix}
x_1 &amp; x_2 &amp; . &amp; . &amp; .&amp; . x_D
\end{bmatrix}^T</div>
<script type="math/tex; mode=display">X = \begin{bmatrix}
x_1 & x_2 & . & . & .& . x_D
\end{bmatrix}^T</script>
</div>
<p><span><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span> is a positive semidefinite matrix because if we take any vector <span><span class="MathJax_Preview">V</span><script type="math/tex">V</script></span>
and calculate <span><span class="MathJax_Preview">V^THV</span><script type="math/tex">V^THV</script></span> then it is always $&gt;= 0 $. Following is the proof.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
V^THV = V^T KXX^T V = K (X^TV)^T (X^TV) = K ||X^TV||^2 &gt;=0 \hspace{20pt} \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
V^THV = V^T KXX^T V = K (X^TV)^T (X^TV) = K ||X^TV||^2 >=0 \hspace{20pt} \end{aligned}</script>
</div>
<p>Since the hessian is PSD we can say that function is convex. Referring
to eq.(3.2) the loss function is just the linear combination of <span><span class="MathJax_Preview">T(.)</span><script type="math/tex">T(.)</script></span>.
As we proved in the lemma that sum of convex functions is a convex
function. Hence it is proved that the loss function is convex.</p>
<h2 id="magnitude-of-optimal-w">Magnitude of optimal w</h2>
<p>Considering the binary logistic regression and samples are linearly
separable.</p>
<h4 id="_1"></h4>
<p>When sample points are linearly separable then the features determine
the label deterministically, it implies that given the feature vector
(with true label 1) the regression model should predict the label with
probability close to 1, and if the feature vector belongs to label 0
then model should predict the probability close to zero. Lets look at
the logistic regression model</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
P(Y = 1 | X) = \sigma(\textbf{w}^{T}\textbf{x}) = \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
P(Y = 1 | X) = \sigma(\textbf{w}^{T}\textbf{x}) = \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x})}\end{aligned}</script>
</div>
<p>For linearly separable data <span><span class="MathJax_Preview">P (Y = 1 | X)</span><script type="math/tex">P (Y = 1 | X)</script></span> should either be 0 or 1 in
principle. This implies that <span><span class="MathJax_Preview">\textbf{w}^{T}\textbf{x}</span><script type="math/tex">\textbf{w}^{T}\textbf{x}</script></span> should either
goes to <span><span class="MathJax_Preview">-\infty</span><script type="math/tex">-\infty</script></span> or <span><span class="MathJax_Preview">\infty</span><script type="math/tex">\infty</script></span> irrespective of <span><span class="MathJax_Preview">\textbf{x}</span><script type="math/tex">\textbf{x}</script></span></p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\textbf{w}^{T}\textbf{x} \longrightarrow \infty \hspace{14pt} \text{when \textbf{x} determines Y = 1}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\textbf{w}^{T}\textbf{x} \longrightarrow \infty \hspace{14pt} \text{when \textbf{x} determines Y = 1}\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\textbf{w}^{T}\textbf{x} \longrightarrow -\infty \hspace{14pt} \text{when \textbf{x} determines Y = 0}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\textbf{w}^{T}\textbf{x} \longrightarrow -\infty \hspace{14pt} \text{when \textbf{x} determines Y = 0}\end{aligned}</script>
</div>
<p>both of above statement implies for perfect Logistic regression
classifier <span><span class="MathJax_Preview">||\textbf{w}||^2</span><script type="math/tex">||\textbf{w}||^2</script></span> should tend to infinity for above two
statements to be valid. Following figure can explain the behavior of
<span><span class="MathJax_Preview">\sigma (.)</span><script type="math/tex">\sigma (.)</script></span> on different values of w.</p>
<p><img alt="image" src="../logistic_regression_w_equals_1.png" /></p>
<p><img alt="image" src="../logistic_regression_w_equals_100.png" /></p>
<p><img alt="image" src="../logistic_regression_w_equals_1000.png" /></p>
<p>At high value of w (Fig.3), we can see the strong confidence of taking
the decision (no value of <span><span class="MathJax_Preview">\sigma(.)</span><script type="math/tex">\sigma(.)</script></span> lying between 0 and 1).</p>
<h2 id="regularized-logistic-regression">Regularized logistic regression</h2>
<p>Since optimal <span><span class="MathJax_Preview">\textbf{w} \longrightarrow \infty</span><script type="math/tex">\textbf{w} \longrightarrow \infty</script></span>, in order to handle
the numerical instability the regularization term is being added to the
loss function, and the regularized linear regression looks like
following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\mathcal{L} (\textbf{w}) = -\log\left( \prod_{1= 1}^{n}P (Y = Y_i | \textbf{X} = \textbf{x}_{\textbf{i}})
\right) + \lambda||\textbf{w}||_2^2\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L} (\textbf{w}) = -\log\left( \prod_{1= 1}^{n}P (Y = Y_i | \textbf{X} = \textbf{x}_{\textbf{i}})
\right) + \lambda||\textbf{w}||_2^2\end{aligned}</script>
</div>
<p>Computing gradient w.r.t. <span><span class="MathJax_Preview">\omega_i</span><script type="math/tex">\omega_i</script></span>. Referring to eq. (3.2) and the
first derivative of <span><span class="MathJax_Preview">T(\textbf{w,x},y)</span><script type="math/tex">T(\textbf{w,x},y)</script></span></p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\mathcal{L}(\textbf{w}) = \sum_{i = 1}^{n}T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i) +  \lambda||\textbf{w}||_2^2\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L}(\textbf{w}) = \sum_{i = 1}^{n}T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i) +  \lambda||\textbf{w}||_2^2\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  =  \sum_{i = 1 }^{n} \frac{\partial T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i) }{\partial \omega_j} + 2\lambda \omega_j\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  =  \sum_{i = 1 }^{n} \frac{\partial T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i) }{\partial \omega_j} + 2\lambda \omega_j\end{aligned}</script>
</div>
<p>We have already calculated the term
<span><span class="MathJax_Preview">\frac{\partial T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i) }{\partial \omega_j}</span><script type="math/tex">\frac{\partial T(\textbf{w,}\textbf{x}_{\textbf{i}},y_i) }{\partial \omega_j}</script></span>
in the process of proving the hessian matrix to be PSD. We can just
plugin that term here. After plugging in the term we get the following :</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  = \sum_{i = 1 }^{n} \left( -x_j\left( 1 - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x}_{\textbf{i}})}
\right) +x_j(1-y_i)
\right)
+ 2\lambda\omega_j\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  = \sum_{i = 1 }^{n} \left( -x_j\left( 1 - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x}_{\textbf{i}})}
\right) +x_j(1-y_i)
\right)
+ 2\lambda\omega_j\end{aligned}</script>
</div>
<p>Further simplifying above equation( <span><span class="MathJax_Preview">x_j</span><script type="math/tex">x_j</script></span> cancels out ).</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  = \sum_{i = 1 }^{n} \left( -x_j\left( y_i - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x}_{\textbf{i}})}
\right)
\right)
+ 2\lambda\omega_j \\
= -\sum_{i = 1 }^{n} \left( x_j\left( y_i - P(Y_i = 1 |X = \textbf{x}_{\textbf{i}} )
\right)
\right)
+ 2\lambda\omega_j\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  = \sum_{i = 1 }^{n} \left( -x_j\left( y_i - \frac{1}{1 + \exp(-\textbf{w}^{T}\textbf{x}_{\textbf{i}})}
\right)
\right)
+ 2\lambda\omega_j \\
= -\sum_{i = 1 }^{n} \left( x_j\left( y_i - P(Y_i = 1 |X = \textbf{x}_{\textbf{i}} )
\right)
\right)
+ 2\lambda\omega_j\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  =
-\sum_{i = 1 }^{n} \left( x_j\left( y_i - P(Y_i = 1 |X = \textbf{x}_{\textbf{i}} )
\right)
\right)
+ 2\lambda\omega_j\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\frac{\partial \mathcal{L}(\textbf{w})}{\partial \omega_j}  =
-\sum_{i = 1 }^{n} \left( x_j\left( y_i - P(Y_i = 1 |X = \textbf{x}_{\textbf{i}} )
\right)
\right)
+ 2\lambda\omega_j\end{aligned}</script>
</div>
<h2 id="unique-solution-of-the-regularized-loss-function">Unique solution of the regularized loss function</h2>
<p>Since we have already proven that the loss function without
regularization is convex and the regularization term is also convex
(because <span><span class="MathJax_Preview">\lambda &gt; 0</span><script type="math/tex">\lambda > 0</script></span> and <span><span class="MathJax_Preview">||\textbf{w}||^2 &gt; 0</span><script type="math/tex">||\textbf{w}||^2 > 0</script></span>) so the linear
combination will always be convex. There will be <span><span class="MathJax_Preview">\textbf{w}^*</span><script type="math/tex">\textbf{w}^*</script></span> for
which</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
\mathcal{L}(\textbf{w}^*) &lt;\mathcal{L}(\textbf{w}) \hspace{10pt} \forall \textbf{w}\neq \textbf{w}^*\in \textbf{W}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L}(\textbf{w}^*) <\mathcal{L}(\textbf{w}) \hspace{10pt} \forall \textbf{w}\neq \textbf{w}^*\in \textbf{W}\end{aligned}</script>
</div>
<p>We can start at any <span><span class="MathJax_Preview">\textbf{w}_0</span><script type="math/tex">\textbf{w}_0</script></span> and reach <span><span class="MathJax_Preview">\textbf{w}^*</span><script type="math/tex">\textbf{w}^*</script></span> by using
gradient descent approach.</p>
<h1 id="decision-tree">Decision Tree</h1>
<h2 id="building-a-decision-tree">Building a decision tree</h2>
<p><strong>Selection of predictor to form the decision tree</strong> We shall be
choosing the predictor which can maximize the information gain.</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
IG(Predictor) = H(Target) - H(Target|Predictor)\\\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
IG(Predictor) = H(Target) - H(Target|Predictor)\\\end{aligned}</script>
</div>
<p>Where <span><span class="MathJax_Preview">H(Target)</span><script type="math/tex">H(Target)</script></span> is the entropy of target and <span><span class="MathJax_Preview">H(Target|Predictor)</span><script type="math/tex">H(Target|Predictor)</script></span> is
conditional entropy over predictor which is basically weighted sum of
entropies of each branch after splitting using the predictor Here we
have</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
Predictor \in \{Weather, Traffic\}
,\hspace{10pt}Taget \in \{Accident\hspace{3pt}rate\}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
Predictor \in \{Weather, Traffic\}
,\hspace{10pt}Taget \in \{Accident\hspace{3pt}rate\}\end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
IG(Weather) = H(Accident\hspace{3pt}rate ) - H(Accident\hspace{3pt}rate|Weather)\\
IG(Traffic) = H(Accident\hspace{3pt}rate ) - H(Accident\hspace{3pt}rate|Traffic)\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
IG(Weather) = H(Accident\hspace{3pt}rate ) - H(Accident\hspace{3pt}rate|Weather)\\
IG(Traffic) = H(Accident\hspace{3pt}rate ) - H(Accident\hspace{3pt}rate|Traffic)\end{aligned}</script>
</div>
<p>Looking at eq. (4.1) and (4.2) we can say that the predictor which gives
minimum conditional entropy will lead to maximum information gain. So we
just calculate the conditional entropy and decide the predictor to do
the splitting in order to form decision tree.</p>
<p><strong>Case 1:</strong> Choosing <span><span class="MathJax_Preview">Weather</span><script type="math/tex">Weather</script></span> as root for sunny branch the uncertainty
will be following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
-\left(\frac{23}{28}\log_2\frac{23}{28} + \frac{5}{28}\log_2\frac{5}{28}
\right) = 0.6769\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
-\left(\frac{23}{28}\log_2\frac{23}{28} + \frac{5}{28}\log_2\frac{5}{28}
\right) = 0.6769\end{aligned}</script>
</div>
<p>for rainy branch the uncertainty will be following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
-\left(\frac{50}{72}\log_2\frac{50}{72} + \frac{22}{72}\log_2\frac{22}{72}
\right) = 0.8880\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
-\left(\frac{50}{72}\log_2\frac{50}{72} + \frac{22}{72}\log_2\frac{22}{72}
\right) = 0.8880\end{aligned}</script>
</div>
<p>the condition entropy would be the weighted average over the branches:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
H(Accident\hspace{3pt}rate | Weather) = \frac{28}{100}*0.6769 + \frac{72}{100}*0.8880 =  0.8289\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
H(Accident\hspace{3pt}rate | Weather) = \frac{28}{100}*0.6769 + \frac{72}{100}*0.8880 =  0.8289\end{aligned}</script>
</div>
<p><strong>Case 2:</strong> Choosing <span><span class="MathJax_Preview">Traffic</span><script type="math/tex">Traffic</script></span> as root for heavy branch the uncertainty
will be following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
-\left(\frac{73}{73}\log_2\frac{73}{73} + \frac{0}{73}\log_2\frac{0}{73}
\right) = 0\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
-\left(\frac{73}{73}\log_2\frac{73}{73} + \frac{0}{73}\log_2\frac{0}{73}
\right) = 0\end{aligned}</script>
</div>
<p>for light branch the uncertainty will be following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
-\left(\frac{0}{27}\log_2\frac{0}{27} + \frac{27}{27}\log_2\frac{27}{27}
\right) = 0\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
-\left(\frac{0}{27}\log_2\frac{0}{27} + \frac{27}{27}\log_2\frac{27}{27}
\right) = 0\end{aligned}</script>
</div>
<p>the condition entropy would be the weighted average over the branches:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
H(Accident\hspace{3pt}rate | Weather) = \frac{73}{100}*0 + \frac{27}{100}*0 =  0\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
H(Accident\hspace{3pt}rate | Weather) = \frac{73}{100}*0 + \frac{27}{100}*0 =  0\end{aligned}</script>
</div>
<p>So we choose the <span><span class="MathJax_Preview">Traffic</span><script type="math/tex">Traffic</script></span> predictor as the root of decision tree
because it will has the maximum information gain.</p>
<h2 id="relationship-between-two-decision-trees">Relationship between two decision trees</h2>
<p><strong>T1:</strong> Given the data, the decision tree has been built on some
parameter <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>. <strong>T2:</strong> The data has been normalized by subtracting
the mean and divided by variance. The tree has been built on this new
normalized data.</p>
<h4 id="_2"></h4>
<p><strong>T1</strong> and <strong>T2</strong> will be same if the parameters used in building the
decision tree is function of data points else it will be different. Here
is a simple example when <strong>T1</strong> and <strong>T2</strong> can be different suppose we
have five measurements of temperature as following</p>
<div>
<div class="MathJax_Preview">\{-90, -6, -1, 2, 5\}</div>
<script type="math/tex; mode=display">\{-90, -6, -1, 2, 5\}</script>
</div>
<p>Now we choose a parameter for splitting is <span><span class="MathJax_Preview">T&lt;0</span><script type="math/tex">T<0</script></span> belongs left subtree
and <span><span class="MathJax_Preview">T&gt;0</span><script type="math/tex">T>0</script></span> to right. Lets call this <strong>T1</strong>. The mean of above data set
<span><span class="MathJax_Preview">-15</span><script type="math/tex">-15</script></span>, the variance is always going to be positive, so it is not going
to make change, for this reason I am ignoring the variance. Let the
variance = <span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>. The new data set will look like following:</p>
<div>
<div class="MathJax_Preview">\{ -75/k, 9/k, 14/k, 17/k, 20/k\}</div>
<script type="math/tex; mode=display">\{ -75/k, 9/k, 14/k, 17/k, 20/k\}</script>
</div>
<p>Now if you use the same parameter to build the new tree we will have one
data point on left subtree and 4 data points on right subtree. Lets call
this <strong>T2</strong>. We can say for sure that <strong>T1</strong> and <strong>T2</strong> are different.
Since we had the splitting parameter independent of the data points.</p>
<h4 id="_3"></h4>
<p>In case of parameters being dependent on the data points, the
aforementioned transformation will not change the characteristics of
data in new setting. If we expand the transformation of data point, it
will look like following:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
 X_i \longrightarrow \left(\frac{X_i}{\sigma^2} - \frac{\mu}{\sigma^2}\right)
 \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
 X_i \longrightarrow \left(\frac{X_i}{\sigma^2} - \frac{\mu}{\sigma^2}\right)
 \end{aligned}</script>
</div>
<p>So it is one to one mapping from old reference system to new one (
scaled by <span><span class="MathJax_Preview">\frac{1}{\sigma^2}</span><script type="math/tex">\frac{1}{\sigma^2}</script></span> and then subtracted by
<span><span class="MathJax_Preview">\frac{\mu}{\sigma^2}</span><script type="math/tex">\frac{\mu}{\sigma^2}</script></span>). So the order of data points remain the same in
new reference system and the same effect will reflect to the
corresponding parameter calculations. In conclusion the new tree <strong>T2</strong>
will be same as <strong>T1</strong>.</p>
<h2 id="comparison-of-gini-index-and-cross-entropy">Comparison of Gini index and Cross entropy</h2>
<p>We are given:</p>
<div>
<div class="MathJax_Preview">\begin{aligned}
GI = \sum_{k=1}^{K} p_k(1-p_k) \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
GI = \sum_{k=1}^{K} p_k(1-p_k) \end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
CE = - \sum_{k=1}^{K} p_k \log p_k \end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
CE = - \sum_{k=1}^{K} p_k \log p_k \end{aligned}</script>
</div>
<div>
<div class="MathJax_Preview">\begin{aligned}
GI - CE = \sum_{k=1}^{K}p_k(1-p_k + \log(p_k)) \\
= \sum_{k = 1}^{K} p_k(q_k + \log(1-q_k))\\
=\sum_{k=1}^{K} p_k\left(q_k + \left( -q_k - \frac{q_k^2}{2} - \frac{q_k^3}{3} . . . 
\right)   
\right)\\
= \sum_{k=1}^{K} p_k\left(-\frac{q_k^2}{2} - \frac{q_k^3}{3} . . .
\right)&lt;=0 \\
\hspace{20pt} \\
\text{becasue }p_k, &amp; q_k \text{ are both non-negative}\end{aligned}</div>
<script type="math/tex; mode=display">\begin{aligned}
GI - CE = \sum_{k=1}^{K}p_k(1-p_k + \log(p_k)) \\
= \sum_{k = 1}^{K} p_k(q_k + \log(1-q_k))\\
=\sum_{k=1}^{K} p_k\left(q_k + \left( -q_k - \frac{q_k^2}{2} - \frac{q_k^3}{3} . . . 
\right)   
\right)\\
= \sum_{k=1}^{K} p_k\left(-\frac{q_k^2}{2} - \frac{q_k^3}{3} . . .
\right)<=0 \\
\hspace{20pt} \\
\text{becasue }p_k, & q_k \text{ are both non-negative}\end{aligned}</script>
</div>
<h1 id="programming">Programming</h1>
<h2 id="54-performace-comparision">5.4 Performace comparision</h2>
<p>In case of Naive bayes real valued feature has been used. I am changing
the code now, so I can not attach the new values, since it was informed
just one day before the assignment submission. I will try my best to
modify the code and submit the electronic version compatible with binary
feature support. But I believe the accuracies will remain the same.
Please take this into consideration. The tables below contain the
performance of different methods.</p>
<hr />
<pre><code>    K        Train accu.   Valid accu.   Test accu.
</code></pre>
<p>[0.5ex] 1     77.7895       75.5784      79.4344
        3          83.1579       80.4627      86.3753
        5          86.6316       83.2905      90.7455
        7          88.4211       84.0617      89.2031
        9          88.6316       86.8895      89.4602
       11          89.0526       86.3753      87.9177
       13         188.4211       85.6041      87.9177
       15          87.0526       82.7763      86.3753
       17          85.8947       82.5193      86.1183
       19          85.2632       82.2622      85.3470
       21          85.3684       80.9769      84.8329
       23          84.5263       82.5193      84.3188
     [1ex]                                </p>
<hr />
<p>: Performance at kNN at different values of k</p>
<div>
<div class="MathJax_Preview">table:nonlin</div>
<script type="math/tex; mode=display">table:nonlin</script>
</div>
<hr />
<pre><code> MinLeaf     Train accu.   Valid accu.   Test accu.
</code></pre>
<p>[0.5ex] 1     96.7368       93.3883      94.7636
        2          96.7368       93.3883      94.7636
        3          96.5263       93.9409      94.7636
        4          96.5263       93.9409      94.7636
        5          96.3158       94.1839      95.0642
        6          96.2105       94.6859      94.8224
        7          96.0000       94.9121      94.8797
        8          95.8947       95.1871      95.3046
        9          95.2632       94.6185      94.2199
       10          94.7368       93.8334      94.2786
     [1ex]                                </p>
<hr />
<p>: Decision Tree with different MinLeaf (Gini Index)</p>
<div>
<div class="MathJax_Preview">table:nonlin</div>
<script type="math/tex; mode=display">table:nonlin</script>
</div>
<hr />
<pre><code> MinLeaf     Train accu.   Valid accu.   Test accu.
</code></pre>
<p>[0.5ex] 1     97.0526       93.3505      94.2163
        2          97.0526       93.3505      94.2163
        3          96.8421       93.9032      94.2163
        4          96.8421       93.9032      94.2163
        5          96.6316       94.1462      94.5168
        6          96.5263       94.6482      94.2750
        7          96.3158       94.8744      94.3323
        8          95.8947       95.1871      95.3046
        9          95.2632       94.6185      94.2199
       10          94.7368       93.8334      94.2786
     [1ex]                                </p>
<hr />
<p>: Decision Tree with different MinLeaf (Cross Entropy)</p>
<div>
<div class="MathJax_Preview">table:nonlin</div>
<script type="math/tex; mode=display">table:nonlin</script>
</div>
<hr />
<pre><code>      Method           Train accu.   Valid accu.   Test accu.
</code></pre>
<p>[0.5ex] Naive Bayes      87.05         83.80        83.80
       Logistic reg           83.89         81.49        85.35
          [1ex]                                     </p>
<hr />
<p>: Performance of Naive Bayes and Logistic Reg.</p>
<div>
<div class="MathJax_Preview">table:nonlin</div>
<script type="math/tex; mode=display">table:nonlin</script>
</div>
<h2 id="55-decision-boundary">5.5 Decision Boundary</h2>
<p><img alt="image" src="../decision_boundary_k_equals_1.png" /></p>
<p><img alt="image" src="../decision_boundary_k_equals_5.png" /></p>
<p><img alt="image" src="../decision_boundary_k_equals_15.png" /></p>
<p><img alt="image" src="../decision_boundary_k_equals_20.png" /></p>
<p>As we can see in the figure when the value of K increases, the decision
boundary smoothen out. As we can see in case of K = 20, very less red
data points lying in the blue region and just one chunk of blue point
lying on left bottom of the figure.</p></div>
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../js/jquery-1.10.2.min.js"></script>
    <script src="../js/bootstrap-3.0.3.min.js"></script>
    <script src="../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '..';
    </script>
    <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>
    <script src="../js/base.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
