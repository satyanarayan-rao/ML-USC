{
    "docs": [
        {
            "location": "/",
            "text": "Machine learning course\n\n\nA total of 5 homeworks. I attempted to put my solutions of the homeworks (#2-5 will be uploaded soon; I only have it in \npdf\n version yet). All these homeworks were discussed in group but the solutions are purely mine. The contributors' name are: \n\n\n\n\nHimanshu Joshi\n\n\nRohit Kondekar\n\n\nMin-Gyong Shin\n\n\nWonjoon Eric Sohn",
            "title": "Home"
        },
        {
            "location": "/#machine-learning-course",
            "text": "A total of 5 homeworks. I attempted to put my solutions of the homeworks (#2-5 will be uploaded soon; I only have it in  pdf  version yet). All these homeworks were discussed in group but the solutions are purely mine. The contributors' name are:    Himanshu Joshi  Rohit Kondekar  Min-Gyong Shin  Wonjoon Eric Sohn",
            "title": "Machine learning course"
        },
        {
            "location": "/solution_hw_1/",
            "text": "Naive Bayes\n\n\nParametric form of Naive Bayes with Gaussian Assumption\n\n\nFeature vector \nX \\in R^D\nX \\in R^D\n and \nY\nY\n is a binary random vector.\n\n\n\n\nY \\sim Bern(\\pi)\n\n\nY \\sim Bern(\\pi)\n\n\n\n\n\n\nX = \\{X_1, ..., X_D\\}\n\n\nX = \\{X_1, ..., X_D\\}\n\n\n\n\n\n\nP (X_j| Y = y_k ) \\sim N(\\mu_{jk}, \\sigma_j)\n\n\nP (X_j| Y = y_k ) \\sim N(\\mu_{jk}, \\sigma_j)\n\n\n\n\nNaive Bayes assumes the conditional independence of features given \nY\nY\n\n\n\n\nP(X_i = x_i, X_j = x_j | Y = y_k) = P (X_i = x_i | Y =y_k)*P(X_j = x_j| Y= y_k) \\space \\forall i \\neq j\n\n\nP(X_i = x_i, X_j = x_j | Y = y_k) = P (X_i = x_i | Y =y_k)*P(X_j = x_j| Y= y_k) \\space \\forall i \\neq j\n\n\n\n\nHere we have to show that the posterior probability can be written as\nthe posterior of logistic regression.Proceeding with above assumptions.\n\n\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{P(X| Y = 1)*P(Y = 1)}{P(X)}\\end{aligned}\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{P(X| Y = 1)*P(Y = 1)}{P(X)}\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nP(X) = P(X|Y = 0)*P(Y = 0) + P (X| Y = 1)* P(Y = 1 )\\end{aligned}\n\n\n\\begin{aligned}\nP(X) = P(X|Y = 0)*P(Y = 0) + P (X| Y = 1)* P(Y = 1 )\\end{aligned}\n\n\n\n\nUsing eq. (1.2) in (1.1) and bringing the numerator to denominator\nsimplifies eq. (1) to the following.\n\n\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}{1 + \\frac{P(X| Y = 0)*P(Y = 0)}{P(X| Y = 1 )*P(Y = 1)}}\\end{aligned}\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}{1 + \\frac{P(X| Y = 0)*P(Y = 0)}{P(X| Y = 1 )*P(Y = 1)}}\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nP(X | Y = y_k) = \\prod_{i=1}^D P (X_i| Y = y_k)\\end{aligned}\n\n\n\\begin{aligned}\nP(X | Y = y_k) = \\prod_{i=1}^D P (X_i| Y = y_k)\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nP(X_i | Y = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_i}exp\\left(-\\frac{(X_i - \\mu_{ik})^2}{2\\sigma_{i}^2}\\right)\\end{aligned}\n\n\n\\begin{aligned}\nP(X_i | Y = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_i}exp\\left(-\\frac{(X_i - \\mu_{ik})^2}{2\\sigma_{i}^2}\\right)\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nP (Y = 1) = \\pi , P (Y = 0 ) = 1 -\\pi\\end{aligned}\n\n\n\\begin{aligned}\nP (Y = 1) = \\pi , P (Y = 0 ) = 1 -\\pi\\end{aligned}\n\n\n\n\nUsing eq. (1.4),(1.5) and (1.6) in eq. (1.3) we get the simplified form\nas following\n\n\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1 - \\pi}\n{\\pi} *\n\\frac{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}    \\right)     }\n{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}    \\right) } }\\end{aligned}\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1 - \\pi}\n{\\pi} *\n\\frac{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}    \\right)     }\n{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}    \\right) } }\\end{aligned}\n\n\n\n\nSolving further to simpler terms by assuming the following:\n\n\n\n\nZ_{i0} = \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}\n\n\nZ_{i0} = \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}\n\n\n\n\n\n\nZ_{i1} = \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}\n\n\nZ_{i1} = \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}\n\n\n\n\n\n\n\\begin{aligned}\n Z_{i1} - Z_{i0}  = \\frac{(2X_i - (\\mu_{i0} + \\mu_{i1}) )*(\\mu_{i0} - \\mu_{i1})}{2\\sigma_i^2}\n \\end{aligned}\n\n\n\\begin{aligned}\n Z_{i1} - Z_{i0}  = \\frac{(2X_i - (\\mu_{i0} + \\mu_{i1}) )*(\\mu_{i0} - \\mu_{i1})}{2\\sigma_i^2}\n \\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n= \\frac{X_i*(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}  - \\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}{2\\sigma_i^2}\\end{aligned}\n\n\n\\begin{aligned}\n= \\frac{X_i*(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}  - \\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}{2\\sigma_i^2}\\end{aligned}\n\n\n\n\neq. (1.7) can be rewritten using simplified terms like \nZ_{i1} - Z_{i0}\nZ_{i1} - Z_{i0}\n\nas following.\n\n\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1-\\pi}\n{\\pi}*\\prod_{i=1}^{D}exp \\left( \\frac{-(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2} + \\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i   \\right)}\\end{aligned}\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1-\\pi}\n{\\pi}*\\prod_{i=1}^{D}exp \\left( \\frac{-(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2} + \\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i   \\right)}\\end{aligned}\n\n\n\n\nProduct term in denominator of eq. (1.8) can be substituted with summand\ninside the exponential expression, and \n\\frac{1-\\pi}{\\pi}\n\\frac{1-\\pi}{\\pi}\n can be\nwritten as \nexp\\left(-log\\frac{\\pi}{1 - \\pi}\\right).\nexp\\left(-log\\frac{\\pi}{1 - \\pi}\\right).\n Doing above\nchanges to eq. (1.8) it reduces to the following form.\n\n\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + exp \\left\\lbrace - \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i\n\\right\\rbrace}\\end{aligned}\n\n\n\\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + exp \\left\\lbrace - \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i\n\\right\\rbrace}\\end{aligned}\n\n\n\n\nWe can see clearly in eq. (1.9) that the posterior probability is taking\nthe form of logistic regression. Comparing with the logistic regression\nexpression. We can write the parameters as follows:\n\n\n\n\n\\begin{aligned}\n\\omega_0 = \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\\end{aligned}\n\n\n\\begin{aligned}\n\\omega_0 = \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\textbf{w} = \\left[\\frac{(\\mu_{00} - \\mu_{01})}{\\sigma_1^2} , ... , \\frac{(\\mu_{D0} - \\mu_{D1})}{\\sigma_D^2}\\right]^T\\end{aligned}\n\n\n\\begin{aligned}\n\\textbf{w} = \\left[\\frac{(\\mu_{00} - \\mu_{01})}{\\sigma_1^2} , ... , \\frac{(\\mu_{D0} - \\mu_{D1})}{\\sigma_D^2}\\right]^T\\end{aligned}\n\n\n\n\nParametric estimation for Naive Bayes with Gaussian assumption\n\n\nWe have training set of size \nN\nN\n of the form\n\n(\\textbf{x}_\\textbf{i}, y_i)\n(\\textbf{x}_\\textbf{i}, y_i)\n, where\n\n\n\n\n\\begin{aligned}\n\\textbf{x}_\\textbf{i} = (x_{i1}, ..., x_{iD})^T, y_i \\in \\{0,1\\}\\end{aligned}\n\n\n\\begin{aligned}\n\\textbf{x}_\\textbf{i} = (x_{i1}, ..., x_{iD})^T, y_i \\in \\{0,1\\}\\end{aligned}\n\n\n\n\nSince we have to estimate the distribution parameters such as\n\n\\pi_i, \\mu_{jk},\n\\pi_i, \\mu_{jk},\n and \n\\sigma_j\n\\sigma_j\n. We can do this by writing log\nlikelihood and differentiating w.r.t corresponding parameters and set to\nzero to get the values. Following derivation are for the log likelihood\nand parameter estimation.\n\n\nJoint probability can be written as\n\n\n\n\n\\begin{aligned}\nP(X, Y ) = \\prod_{i = 1 }^{N} P (X_i, Y_i)= \\prod_{i = 1 }^{N} P(X_i | Y_i = y_k)*P (Y_i = y_k)\\end{aligned}\n\n\n\\begin{aligned}\nP(X, Y ) = \\prod_{i = 1 }^{N} P (X_i, Y_i)= \\prod_{i = 1 }^{N} P(X_i | Y_i = y_k)*P (Y_i = y_k)\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n= \\prod_{i = 1}^{N}P(Y_i = y_k)\\prod_{j = 1}^{D}P(X_{ij} = x_{ij} | Y_i = y_k)\\end{aligned}\n\n\n\\begin{aligned}\n= \\prod_{i = 1}^{N}P(Y_i = y_k)\\prod_{j = 1}^{D}P(X_{ij} = x_{ij} | Y_i = y_k)\\end{aligned}\n\n\n\n\nIn above deduction we have used the naive bayes assumption. Now we know\nthe following:\n\n\n\n\n\\begin{aligned}\nP(Y_i = y_k) = \\pi^{y_k}*(1-\\pi)^{(1-y_k)}\\end{aligned}\n\n\n\\begin{aligned}\nP(Y_i = y_k) = \\pi^{y_k}*(1-\\pi)^{(1-y_k)}\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nP(X_{ij} = x_{ij} | Y_i = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_j}exp\\left(-\\frac{(x_{ij} - \\mu_{jk})^2}{2\\sigma_{j}^2}\\right)\\end{aligned}\n\n\n\\begin{aligned}\nP(X_{ij} = x_{ij} | Y_i = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_j}exp\\left(-\\frac{(x_{ij} - \\mu_{jk})^2}{2\\sigma_{j}^2}\\right)\\end{aligned}\n\n\n\n\nSince we know that log likelihood is the log of joint pdf. We can take\nthe log on both side of eq. (1.10) to get the log likelihood.\n\n\n\n\n\\begin{aligned}\nl(\\theta | X, Y) = logP(X,Y) = \\sum_{i = 1}^{N}\\left( log P(Y_i = y_k) + \\sum_{j = 1}^{D} log P (X_{ij} = x_{ij} | Y_i = y_k)\n\\right)  \\end{aligned}\n\n\n\\begin{aligned}\nl(\\theta | X, Y) = logP(X,Y) = \\sum_{i = 1}^{N}\\left( log P(Y_i = y_k) + \\sum_{j = 1}^{D} log P (X_{ij} = x_{ij} | Y_i = y_k)\n\\right)  \\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n= \\sum_{i = 1}^{N} \\left( y_klog\\pi + (1-y_k)log(1 - \\pi) + \\sum_{j = 1}^{D} \\left( -log ( (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{jk})^2}\n{2\\sigma_j^2}\n\\right)\n\\right)\\end{aligned}\n\n\n\\begin{aligned}\n= \\sum_{i = 1}^{N} \\left( y_klog\\pi + (1-y_k)log(1 - \\pi) + \\sum_{j = 1}^{D} \\left( -log ( (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{jk})^2}\n{2\\sigma_j^2}\n\\right)\n\\right)\\end{aligned}\n\n\n\n\nSuppose there are m data points with label 1 and N-m with label 0, above\nequation can be rewritten as following:\n\n\n\n\n\\begin{aligned}\nl(\\theta | X, Y) = \\sum_{i:Y_i = y_k = 1}y_klog\\pi  + \\sum_{i:Y_i = y_k = 0}(1-y_k)log(1-\\pi) \\\\ + \\sum_{i:Y_i = y_k = 1}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j1})^2}{2\\sigma} \n\\right) \\\\ +  \\sum_{i:Y_i = y_k = 0}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j0})^2}{2\\sigma} \n\\right)\\end{aligned}\n\n\n\\begin{aligned}\nl(\\theta | X, Y) = \\sum_{i:Y_i = y_k = 1}y_klog\\pi  + \\sum_{i:Y_i = y_k = 0}(1-y_k)log(1-\\pi) \\\\ + \\sum_{i:Y_i = y_k = 1}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j1})^2}{2\\sigma} \n\\right) \\\\ +  \\sum_{i:Y_i = y_k = 0}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j0})^2}{2\\sigma} \n\\right)\\end{aligned}\n\n\n\n\nCalculating MLE for \n\\pi\n\\pi\n:\n\n\n\n\n\\begin{aligned}\n\\hat{\\pi} = \\left\\lbrace \\pi: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = 0  \\right\\rbrace\\end{aligned}\n\n\n\\begin{aligned}\n\\hat{\\pi} = \\left\\lbrace \\pi: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = 0  \\right\\rbrace\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = \\frac{m}{\\pi} - \\frac{(N - m)}{1 - \\pi} + 0 + 0  \\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = \\frac{m}{\\pi} - \\frac{(N - m)}{1 - \\pi} + 0 + 0  \\end{aligned}\n\n\n\n\nEquating the above equation to zero and solving for \n\\pi\n\\pi\n\n\n\n\n\\begin{aligned}\nm(1 - \\pi)  - (N-m)\\pi = 0 \n\\implies m - N\\pi = 0 \n\\implies \\pi = \\frac{m}{N} \\end{aligned}\n\n\n\\begin{aligned}\nm(1 - \\pi)  - (N-m)\\pi = 0 \n\\implies m - N\\pi = 0 \n\\implies \\pi = \\frac{m}{N} \\end{aligned}\n\n\n\n\nSo the likelihood parameter estimation of \n\\pi\n\\pi\n is:\n\n\n\n\n\\begin{aligned}\n\\hat{\\pi} = \\frac{m}{N} = \\frac{\\#label = 1 }{N}\\end{aligned}\n\n\n\\begin{aligned}\n\\hat{\\pi} = \\frac{m}{N} = \\frac{\\#label = 1 }{N}\\end{aligned}\n\n\n\n\nLikelihood for \n\\mu_{jk}\n\\mu_{jk}\n:\n\n\n\n\n\\begin{aligned}\n\\hat{\\mu}_{jk} = \\left\\lbrace \\mu_{jk}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\mu_{jk}} = 0  \\right\\rbrace\\end{aligned}\n\n\n\\begin{aligned}\n\\hat{\\mu}_{jk} = \\left\\lbrace \\mu_{jk}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\mu_{jk}} = 0  \\right\\rbrace\\end{aligned}\n\n\n\n\nWe can do this in two parts, k = 0 and k = 1 for k = 0, we shall only\nhave the fourth term in partial differentiation, other term will give\nzeros.\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi}  = \\sum_{i:Y_i = y_k = 0}- \\frac{(x_{ij} - \\mu_{jo})}{\\sigma_j^2}*(-1) = 0 \\\\\n\\implies \\sum_{i:Y_i = y_k = 0}(x_{ij} - \\mu_{jo}) = 0 \\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi}  = \\sum_{i:Y_i = y_k = 0}- \\frac{(x_{ij} - \\mu_{jo})}{\\sigma_j^2}*(-1) = 0 \\\\\n\\implies \\sum_{i:Y_i = y_k = 0}(x_{ij} - \\mu_{jo}) = 0 \\end{aligned}\n\n\n\n\nFrom above assumption we know the count of zero labels are \nN-m\nN-m\n Solving\nabove equality gives us the following\n\n\n\n\n\\begin{aligned}\n(N-m)*\\mu_{j0} = \\sum_{i:Y_i = y_k = 0} x_{ij}\\end{aligned}\n\n\n\\begin{aligned}\n(N-m)*\\mu_{j0} = \\sum_{i:Y_i = y_k = 0} x_{ij}\\end{aligned}\n\n\n\n\nwhich gives us\n\n\n\n\n\\begin{aligned}\n\\hat{\\mu}_{j0} = \\frac{\\sum_{i:Y_i = y_k = 0} x_{ij}}{(N-m)}\\end{aligned}\n\n\n\\begin{aligned}\n\\hat{\\mu}_{j0} = \\frac{\\sum_{i:Y_i = y_k = 0} x_{ij}}{(N-m)}\\end{aligned}\n\n\n\n\nSimilarly we get the estimate for \n\\mu_{j1}\n\\mu_{j1}\n\n\n\n\n\\begin{aligned}\n\\hat{\\mu}_{j1} = \\frac{\\sum_{i:Y_i = y_k = 1} x_{ij}}{(m)}\\end{aligned}\n\n\n\\begin{aligned}\n\\hat{\\mu}_{j1} = \\frac{\\sum_{i:Y_i = y_k = 1} x_{ij}}{(m)}\\end{aligned}\n\n\n\n\nLikelihood for \n\\sigma_{j}\n\\sigma_{j}\n:\n\n\n\n\n\\begin{aligned}\n\\hat{\\sigma}_{j} = \\left\\lbrace \\sigma_{j}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}} = 0  \\right\\rbrace\\end{aligned}\n\n\n\\begin{aligned}\n\\hat{\\sigma}_{j} = \\left\\lbrace \\sigma_{j}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}} = 0  \\right\\rbrace\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}}  = \\sum_{i:Y_i =y_k = 1} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j1})^2}{\\sigma_{j}^3}\n\\right)\\\\\n+ \\sum_{i:Y_i = y_k = 0} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j0})^2}{\\sigma_{j}^3}\n\\right)\\\\\n= - \\frac{N}{\\sigma_{j}} + \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{\\sigma_{j}^3}\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}}  = \\sum_{i:Y_i =y_k = 1} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j1})^2}{\\sigma_{j}^3}\n\\right)\\\\\n+ \\sum_{i:Y_i = y_k = 0} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j0})^2}{\\sigma_{j}^3}\n\\right)\\\\\n= - \\frac{N}{\\sigma_{j}} + \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{\\sigma_{j}^3}\\end{aligned}\n\n\n\n\nEquating it to zero will give the following:\n\n\n\n\n\\begin{aligned}\n\\sigma_{j}^2 = \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}\\\\\n\\implies \\hat{\\sigma}_{j} = \\sqrt{\\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}}\\end{aligned}\n\n\n\\begin{aligned}\n\\sigma_{j}^2 = \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}\\\\\n\\implies \\hat{\\sigma}_{j} = \\sqrt{\\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}}\\end{aligned}\n\n\n\n\nNearest Neighbor\n\n\nFeature weighting in low dimension\n\n\nFeature weighting is required in case of noise, because noise affect the\neuclidean distance measures which can lead to poor performance of KNN.\nThis is also known as Achilles\u2019 heel of KNN. In case of low dimension\n\nD = 3\nD = 3\n with discretized values of weights in each dimension. We can do\ngrid search to look for the optimal weights which can give the best\ntraining accuracy. The procedure explained below can be used to find the\noptimal weights for the features. Here we have following assumption\n\n\n\n\n\\begin{aligned}\nX_i = \\left(x_{i1}, x_{i2}, x_{i3}\\right)^T\\\\\nW = \\left(w_1, w_2, w_3\\right)\\\\\nw_i \\in \\{w_{i1}, w_{i2}, .,.,., w_{ik}\\}\\end{aligned}\n\n\n\\begin{aligned}\nX_i = \\left(x_{i1}, x_{i2}, x_{i3}\\right)^T\\\\\nW = \\left(w_1, w_2, w_3\\right)\\\\\nw_i \\in \\{w_{i1}, w_{i2}, .,.,., w_{ik}\\}\\end{aligned}\n\n\n\n\nThe weights has been discretized to \nk\nk\n values. We can just do grid\nsearch by using following pseudo code.\n\n\nopt (W) = {}\n\n\nfor \nw_1 = w_{11}:w_{1k}\nw_1 = w_{11}:w_{1k}\n\n\nfor \nw_2 = w_{21}:w_{2k}\nw_2 = w_{21}:w_{2k}\n\n\nfor \nw_3 = w_{31}:w_{3k}\nw_3 = w_{31}:w_{3k}\n\n\nfor \ni = 1:N\ni = 1:N\n\n\nfor \nj\\neq i = 1:N\nj\\neq i = 1:N\n\n\ncompute \nd(X_i, X_j)\nd(X_i, X_j)\n\n\nend\n\n\nend\n\n\nCompute the training accuracy and update opt(W) if accuracy is\n\n\nbetter.\n\n\nend\n\n\nend\n\n\nend\n\n\nFor this approach we can also use dynamic programming to reduce the\ncomputation, we can maintain the \nN\nN\nx\nN\nN\nx\nD\nD\n matrix with entries of\neuclidean distances of feature vectors. Afterwards we can use this\nmatrix as lookup table and just multiply with the weights to get the\nweighted feature distance. Using the Dynamic programming approach will\nlead to following complexity: Time complexity:\n\n\n\n\nO(k^3)\n\n\nO(k^3)\n\n\n\n\nSpace complexity:\n\n\n\n\nO(N^2)\n\n\nO(N^2)\n\n\n\n\nFeature weighting in higher dimensions\n\n\nIn higher dimension above approach of finding optimal weight will lead\nto exponential time complexity \nO(k^D)\nO(k^D)\n. This is curse of\ndimensionality. As being instructed by TA that we do not have to use any\nstatistical approach to construct the method for assigning weights to\nfeatures (We have to design algorithm). If we present the weighted\ndistances calculation in matrix form, it will appear as follows:\n\n\n\n\n\\begin{aligned}\n\\hat{Label}(X_1) = Label \\left(X_j : j = \\min_{j}\n\\begin{bmatrix}\nw_1 &  . &  w_D\n\\end{bmatrix}\n\\begin{bmatrix}\n(x_{11} - x_{21})^2 &  (x_{11} - x_{31})^2 &  . & (x_{11} - x_{N1})^2 \\\\\n(x_{12} - x_{22})^2  & (x_{12} - x_{32})^2 &  . & (x_{12} - x_{N2})^2 \\\\\n.  & . & .  & . & \\\\\n.  & . & .  & . & \\\\\n(x_{1D} - x_{2D})^2 & (x_{1D} - x_{3D})^2  &  . & (x_{1D} - x_{ND})^2\n\\end{bmatrix}\n\\right)\\end{aligned}\n\n\n\\begin{aligned}\n\\hat{Label}(X_1) = Label \\left(X_j : j = \\min_{j}\n\\begin{bmatrix}\nw_1 &  . &  w_D\n\\end{bmatrix}\n\\begin{bmatrix}\n(x_{11} - x_{21})^2 &  (x_{11} - x_{31})^2 &  . & (x_{11} - x_{N1})^2 \\\\\n(x_{12} - x_{22})^2  & (x_{12} - x_{32})^2 &  . & (x_{12} - x_{N2})^2 \\\\\n.  & . & .  & . & \\\\\n.  & . & .  & . & \\\\\n(x_{1D} - x_{2D})^2 & (x_{1D} - x_{3D})^2  &  . & (x_{1D} - x_{ND})^2\n\\end{bmatrix}\n\\right)\\end{aligned}\n\n\n\n\nWe do above calculation for every data point. Since there are \nk^D\nk^D\n\npossible matrices \n[w_1 ... w_D ]\n[w_1 ... w_D ]\n, we can not calculate this in\npolynomial time. One way to select meaningful features from the haystack\nis to calculate the training accuracy on each individual feature by\nsetting other\u2019s weight to zero. we assign the weight to be training\naccuracy of that individual feature. We can decide how many feature we\nhave to take into consideration. This will result into the limited\nfeatures with weight assigned on each of them. \n2\nnd\n method\n Objective\nfunction for above problem will look like following:\n\n\n\n\n\\begin{aligned}\nJ(W) = \\sum_{i=1}^{N}\\left( \\hat{Label}(X_i) - Label (X_i) \\right)\\end{aligned}\n\n\n\\begin{aligned}\nJ(W) = \\sum_{i=1}^{N}\\left( \\hat{Label}(X_i) - Label (X_i) \\right)\\end{aligned}\n\n\n\n\nThe characteristic of above objective function is a curve in higher\ndimension with multiple local minimum. We can use the gradient descent\napproach to find the local minima\u2019s we can start with different set of\nrandom weight vectors and try to find the different minimum, select the\nbest one out of these and return those weight vectors as weighted\nfeature vector. This is a polynomial time algorithm, but of course this\nmay not give the optimal solution.\n\n\nLogistic regression\n\n\nNegative log likelihood or Loss function\n\n\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right)\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right)\\end{aligned}\n\n\n\n\nWe know that\n\n\n\n\n\\begin{aligned}\nP (Y = 1 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})} = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}\n\n\n\\begin{aligned}\nP (Y = 1 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})} = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nP (Y = 0 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) =  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}\n\n\n\\begin{aligned}\nP (Y = 0 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) =  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nP (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})^{y_i} (  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )^{1-y_i}\\\\\n\\log P (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} )  = y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )\\end{aligned}\n\n\n\\begin{aligned}\nP (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})^{y_i} (  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )^{1-y_i}\\\\\n\\log P (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} )  = y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )\\end{aligned}\n\n\n\n\nWriting the negative log likelihood in simpler form using above\nexpression\n\n\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\log(P (Y = y_i| \\textbf{X} = \\textbf{x}_{\\textbf{i}}))\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\log(P (Y = y_i| \\textbf{X} = \\textbf{x}_{\\textbf{i}}))\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\left(y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) ) \n\\right)\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\left(y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) ) \n\\right)\\end{aligned}\n\n\n\n\nProof for convexity of loss function\n\n\nTo prove the convexity we are going to show that the hessian matrix will\nbe positive semidefinite. In order to make the derivation simpler we are\ngoing to use the property of convex functions. If \nf(x)\nf(x)\n and \ng(x)\ng(x)\n are\ntwo convex function then their sum \nh(x)\nh(x)\n is also going to be the convex\nfunction Proof: As we know from the property of convex function\n\n\n\n\nf(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2)\n\n\nf(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2)\n\n\n\n\n\n\ng(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda g(x_1) + (1 - \\lambda)g(x_2)\n\n\ng(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda g(x_1) + (1 - \\lambda)g(x_2)\n\n\n\n\nAdding above two equations we get the following:\n\n\n\n\nf(\\lambda x_1 + (1-\\lambda)x_2 ) + g(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2) + \\lambda g(x_1) + (1 - \\lambda)g(x_2)\n\n\nf(\\lambda x_1 + (1-\\lambda)x_2 ) + g(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2) + \\lambda g(x_1) + (1 - \\lambda)g(x_2)\n\n\n\n\n\n\nh(\\lambda x_1 + (1-\\lambda)x_2 )) <= \\lambda h(x_1) + (1 - \\lambda)h(x_2)\n\n\nh(\\lambda x_1 + (1-\\lambda)x_2 )) <= \\lambda h(x_1) + (1 - \\lambda)h(x_2)\n\n\n\n\nSo \nh(x)\nh(x)\n is also convex. Multiplying by any positive constant preserves\nthe convexity. Considering just one term from loss function.\n\n\n\n\n\\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\end{aligned}\n\n\n\\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i)\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i)\\end{aligned}\n\n\n\n\nIf we prove that $T(\\textbf{w,x},y) $ is convex then we can say that\n\n\\mathcal{L}(\\textbf{w})\n\\mathcal{L}(\\textbf{w})\n is convex (by above proved lemma).\n\n\n\n\n\\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\\\\n= -y\\log \\left(\\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) - (1-y)\\log\\left(1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n=y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y)\\log\\left(\\frac{\\exp(-\\textbf{w}^{T}\\textbf{x})}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n= y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y) \\left( -\\textbf{w}^{T}\\textbf{x} - \\log\\left(  1 + \\exp(-\\textbf{w}^{T}\\textbf{x}\n\\right)\n\\right)\\\\\n=(1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)\\end{aligned}\n\n\n\\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\\\\n= -y\\log \\left(\\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) - (1-y)\\log\\left(1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n=y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y)\\log\\left(\\frac{\\exp(-\\textbf{w}^{T}\\textbf{x})}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n= y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y) \\left( -\\textbf{w}^{T}\\textbf{x} - \\log\\left(  1 + \\exp(-\\textbf{w}^{T}\\textbf{x}\n\\right)\n\\right)\\\\\n=(1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)\\end{aligned}\n\n\n\n\nFinally we get:\n\n\n\n\nT(\\textbf{w,x},y) = (1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)\n\n\nT(\\textbf{w,x},y) = (1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)\n\n\n\n\nWe need to find the hessian\n(H)\n(H)\n of this which is basically \nD\nD\nx\nD\nD\n\nmatrix and the element \nH(j,k)\nH(j,k)\n is:\n\n\n\n\n\\begin{aligned}\nH(j,k) = \\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k}\\end{aligned}\n\n\n\\begin{aligned}\nH(j,k) = \\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k}\\end{aligned}\n\n\n\n\nNow calculating the \nH(j,k)\nH(j,k)\n. Calculating the first derivative.\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial T(\\textbf{w,x},y)}{\\partial w_j} = \\frac{-x_j * \\exp(-\\textbf{w}^{T}\\textbf{x})}{ 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})} + x_j(1-y)\\\\\n= -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) +x_j(1-y)\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial T(\\textbf{w,x},y)}{\\partial w_j} = \\frac{-x_j * \\exp(-\\textbf{w}^{T}\\textbf{x})}{ 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})} + x_j(1-y)\\\\\n= -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) +x_j(1-y)\\end{aligned}\n\n\n\n\nDifferentiating above w.r.t. \nw_k\nw_k\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = 0 + x_j \\left[ \\frac{(-1)*\\exp(-\\textbf{w}^{T}\\textbf{x})*(-x_k) }{\\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)^2}\n\\right] + 0 \\\\\n= x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = 0 + x_j \\left[ \\frac{(-1)*\\exp(-\\textbf{w}^{T}\\textbf{x})*(-x_k) }{\\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)^2}\n\\right] + 0 \\\\\n= x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k \\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k \\end{aligned}\n\n\n\n\nNote: \n\\sigma(x) >= 0 \\hspace{8pt} \\forall x\n\\sigma(x) >= 0 \\hspace{8pt} \\forall x\n\n\nIf we fill out the Hessian matrix it will look like following:\n\n\n\n\n\\begin{aligned}\nH = \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x})) \\begin{bmatrix}\nx_1^2 & x_1x_2 &  . & .& . & x_1x_D\\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\nx_Dx_1 & x_Dx_2 & . & . & . & x_D^2\n\\end{bmatrix}\\end{aligned}\n\n\n\\begin{aligned}\nH = \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x})) \\begin{bmatrix}\nx_1^2 & x_1x_2 &  . & .& . & x_1x_D\\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\nx_Dx_1 & x_Dx_2 & . & . & . & x_D^2\n\\end{bmatrix}\\end{aligned}\n\n\n\n\nLet\n\nK =  \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))\nK =  \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))\n\nwhich is always greater than or equal to zero, matrix in above\nexpression can be decomposed into \nXX^T\nXX^T\n where X is a column matrix. So\n\nH\nH\n can be rewritten as\n\n\n\n\n\\begin{aligned}\nH = K XX^T\\end{aligned}\n\n\n\\begin{aligned}\nH = K XX^T\\end{aligned}\n\n\n\n\nwhere\n\n\n\n\nX = \\begin{bmatrix}\nx_1 & x_2 & . & . & .& . x_D\n\\end{bmatrix}^T\n\n\nX = \\begin{bmatrix}\nx_1 & x_2 & . & . & .& . x_D\n\\end{bmatrix}^T\n\n\n\n\nH\nH\n is a positive semidefinite matrix because if we take any vector \nV\nV\n\nand calculate \nV^THV\nV^THV\n then it is always $>= 0 $. Following is the proof.\n\n\n\n\n\\begin{aligned}\nV^THV = V^T KXX^T V = K (X^TV)^T (X^TV) = K ||X^TV||^2 >=0 \\hspace{20pt} \\end{aligned}\n\n\n\\begin{aligned}\nV^THV = V^T KXX^T V = K (X^TV)^T (X^TV) = K ||X^TV||^2 >=0 \\hspace{20pt} \\end{aligned}\n\n\n\n\nSince the Hessian is a PSD we can say that function is convex. Referring\nto eq.(3.2) the loss function is just the linear combination of \nT(.)\nT(.)\n.\nAs we proved in the lemma that sum of convex functions is a convex\nfunction. Hence it is proved that the loss function is convex.\n\n\nMagnitude of optimal w\n\n\nConsidering the binary logistic regression and samples are linearly\nseparable.\n\n\n\n\nWhen sample points are linearly separable then the features determine\nthe label deterministically, it implies that given the feature vector\n(with true label 1) the regression model should predict the label with\nprobability close to 1, and if the feature vector belongs to label 0\nthen model should predict the probability close to zero. Lets look at\nthe logistic regression model\n\n\n\n\n\\begin{aligned}\nP(Y = 1 | X) = \\sigma(\\textbf{w}^{T}\\textbf{x}) = \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\\end{aligned}\n\n\n\\begin{aligned}\nP(Y = 1 | X) = \\sigma(\\textbf{w}^{T}\\textbf{x}) = \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\\end{aligned}\n\n\n\n\nFor linearly separable data \nP (Y = 1 | X)\nP (Y = 1 | X)\n should either be 0 or 1 in\nprinciple. This implies that \n\\textbf{w}^{T}\\textbf{x}\n\\textbf{w}^{T}\\textbf{x}\n should either\ngoes to \n-\\infty\n-\\infty\n or \n\\infty\n\\infty\n irrespective of \n\\textbf{x}\n\\textbf{x}\n\n\n\n\n\\begin{aligned}\n\\textbf{w}^{T}\\textbf{x} \\longrightarrow \\infty \\hspace{14pt} \\text{when } \\textbf{x } \\text{determines } Y = 1\\end{aligned}\n\n\n\\begin{aligned}\n\\textbf{w}^{T}\\textbf{x} \\longrightarrow \\infty \\hspace{14pt} \\text{when } \\textbf{x } \\text{determines } Y = 1\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\textbf{w}^{T}\\textbf{x} \\longrightarrow -\\infty \\hspace{14pt} \\text{when } \\textbf{x } \\text{determines } Y = 0\\end{aligned}\n\n\n\\begin{aligned}\n\\textbf{w}^{T}\\textbf{x} \\longrightarrow -\\infty \\hspace{14pt} \\text{when } \\textbf{x } \\text{determines } Y = 0\\end{aligned}\n\n\n\n\nboth of above statement implies for perfect Logistic regression\nclassifier \n||\\textbf{w}||^2\n||\\textbf{w}||^2\n should tend to infinity for above two\nstatements to be valid. Following figure can explain the behavior of\n\n\\sigma (.)\n\\sigma (.)\n on different values of w.\n\n\n\n\n\n\n\n\nAt high value of w (Fig.3), we can see the strong confidence of taking\nthe decision (no value of \n\\sigma(.)\n\\sigma(.)\n lying between 0 and 1).\n\n\nRegularized logistic regression\n\n\nSince optimal \n\\textbf{w} \\longrightarrow \\infty\n\\textbf{w} \\longrightarrow \\infty\n, in order to handle\nthe numerical instability the regularization term is being added to the\nloss function, and the regularized linear regression looks like\nfollowing:\n\n\n\n\n\\begin{aligned}\n\\mathcal{L} (\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right) + \\lambda||\\textbf{w}||_2^2\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{L} (\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right) + \\lambda||\\textbf{w}||_2^2\\end{aligned}\n\n\n\n\nComputing gradient w.r.t. \n\\omega_i\n\\omega_i\n. Referring to eq. (3.2) and the\nfirst derivative of \nT(\\textbf{w,x},y)\nT(\\textbf{w,x},y)\n\n\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) +  \\lambda||\\textbf{w}||_2^2\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) +  \\lambda||\\textbf{w}||_2^2\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =  \\sum_{i = 1 }^{n} \\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j} + 2\\lambda \\omega_j\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =  \\sum_{i = 1 }^{n} \\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j} + 2\\lambda \\omega_j\\end{aligned}\n\n\n\n\nWe have already calculated the term\n\n\\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j}\n\\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j}\n\nin the process of proving the hessian matrix to be PSD. We can just\nplugin that term here. After plugging in the term we get the following :\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right) +x_j(1-y_i)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right) +x_j(1-y_i)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}\n\n\n\n\nFurther simplifying above equation( \nx_j\nx_j\n cancels out ).\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( y_i - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right)\n\\right)\n+ 2\\lambda\\omega_j \\\\\n= -\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( y_i - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right)\n\\right)\n+ 2\\lambda\\omega_j \\\\\n= -\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =\n-\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}\n\n\n\\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =\n-\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}\n\n\n\n\nUnique solution of the regularized loss function\n\n\nSince we have already proven that the loss function without\nregularization is convex and the regularization term is also convex\n(because \n\\lambda > 0\n\\lambda > 0\n and \n||\\textbf{w}||^2 > 0\n||\\textbf{w}||^2 > 0\n) so the linear\ncombination will always be convex. There will be \n\\textbf{w}^*\n\\textbf{w}^*\n for\nwhich\n\n\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}^*) <\\mathcal{L}(\\textbf{w}) \\hspace{10pt} \\forall \\textbf{w}\\neq \\textbf{w}^*\\in \\textbf{W}\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{L}(\\textbf{w}^*) <\\mathcal{L}(\\textbf{w}) \\hspace{10pt} \\forall \\textbf{w}\\neq \\textbf{w}^*\\in \\textbf{W}\\end{aligned}\n\n\n\n\nWe can start at any \n\\textbf{w}_0\n\\textbf{w}_0\n and reach \n\\textbf{w}^*\n\\textbf{w}^*\n by using\ngradient descent approach.\n\n\nDecision Tree\n\n\nBuilding a decision tree\n\n\nSelection of predictor to form the decision tree\n We shall be\nchoosing the predictor which can maximize the information gain.\n\n\n\n\n\\begin{aligned}\nIG(Predictor) = H(Target) - H(Target|Predictor)\\\\\\end{aligned}\n\n\n\\begin{aligned}\nIG(Predictor) = H(Target) - H(Target|Predictor)\\\\\\end{aligned}\n\n\n\n\nWhere \nH(Target)\nH(Target)\n is the entropy of target and \nH(Target|Predictor)\nH(Target|Predictor)\n is\nconditional entropy over predictor which is basically weighted sum of\nentropies of each branch after splitting using the predictor Here we\nhave\n\n\n\n\n\\begin{aligned}\nPredictor \\in \\{Weather, Traffic\\}\n,\\hspace{10pt}Taget \\in \\{Accident\\hspace{3pt}rate\\}\\end{aligned}\n\n\n\\begin{aligned}\nPredictor \\in \\{Weather, Traffic\\}\n,\\hspace{10pt}Taget \\in \\{Accident\\hspace{3pt}rate\\}\\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nIG(Weather) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Weather)\\\\\nIG(Traffic) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Traffic)\\end{aligned}\n\n\n\\begin{aligned}\nIG(Weather) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Weather)\\\\\nIG(Traffic) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Traffic)\\end{aligned}\n\n\n\n\nLooking at eq. (4.1) and (4.2) we can say that the predictor which gives\nminimum conditional entropy will lead to maximum information gain. So we\njust calculate the conditional entropy and decide the predictor to do\nthe splitting in order to form decision tree.\n\n\nCase 1:\n Choosing \nWeather\nWeather\n as root for sunny branch the uncertainty\nwill be following:\n\n\n\n\n\\begin{aligned}\n-\\left(\\frac{23}{28}\\log_2\\frac{23}{28} + \\frac{5}{28}\\log_2\\frac{5}{28}\n\\right) = 0.6769\\end{aligned}\n\n\n\\begin{aligned}\n-\\left(\\frac{23}{28}\\log_2\\frac{23}{28} + \\frac{5}{28}\\log_2\\frac{5}{28}\n\\right) = 0.6769\\end{aligned}\n\n\n\n\nfor rainy branch the uncertainty will be following:\n\n\n\n\n\\begin{aligned}\n-\\left(\\frac{50}{72}\\log_2\\frac{50}{72} + \\frac{22}{72}\\log_2\\frac{22}{72}\n\\right) = 0.8880\\end{aligned}\n\n\n\\begin{aligned}\n-\\left(\\frac{50}{72}\\log_2\\frac{50}{72} + \\frac{22}{72}\\log_2\\frac{22}{72}\n\\right) = 0.8880\\end{aligned}\n\n\n\n\nthe condition entropy would be the weighted average over the branches:\n\n\n\n\n\\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{28}{100}*0.6769 + \\frac{72}{100}*0.8880 =  0.8289\\end{aligned}\n\n\n\\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{28}{100}*0.6769 + \\frac{72}{100}*0.8880 =  0.8289\\end{aligned}\n\n\n\n\nCase 2:\n Choosing \nTraffic\nTraffic\n as root for heavy branch the uncertainty\nwill be following:\n\n\n\n\n\\begin{aligned}\n-\\left(\\frac{73}{73}\\log_2\\frac{73}{73} + \\frac{0}{73}\\log_2\\frac{0}{73}\n\\right) = 0\\end{aligned}\n\n\n\\begin{aligned}\n-\\left(\\frac{73}{73}\\log_2\\frac{73}{73} + \\frac{0}{73}\\log_2\\frac{0}{73}\n\\right) = 0\\end{aligned}\n\n\n\n\nfor light branch the uncertainty will be following:\n\n\n\n\n\\begin{aligned}\n-\\left(\\frac{0}{27}\\log_2\\frac{0}{27} + \\frac{27}{27}\\log_2\\frac{27}{27}\n\\right) = 0\\end{aligned}\n\n\n\\begin{aligned}\n-\\left(\\frac{0}{27}\\log_2\\frac{0}{27} + \\frac{27}{27}\\log_2\\frac{27}{27}\n\\right) = 0\\end{aligned}\n\n\n\n\nthe condition entropy would be the weighted average over the branches:\n\n\n\n\n\\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{73}{100}*0 + \\frac{27}{100}*0 =  0\\end{aligned}\n\n\n\\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{73}{100}*0 + \\frac{27}{100}*0 =  0\\end{aligned}\n\n\n\n\nSo we choose the \nTraffic\nTraffic\n predictor as the root of decision tree\nbecause it will has the maximum information gain.\n\n\nRelationship between two decision trees\n\n\nT1:\n Given the data, the decision tree has been built on some\nparameter \n\\theta\n\\theta\n. \nT2:\n The data has been normalized by subtracting\nthe mean and divided by variance. The tree has been built on this new\nnormalized data.\n\n\n\n\nT1\n and \nT2\n will be same if the parameters used in building the\ndecision tree is function of data points else it will be different. Here\nis a simple example when \nT1\n and \nT2\n can be different suppose we\nhave five measurements of temperature as following\n\n\n\n\n\\{-90, -6, -1, 2, 5\\}\n\n\n\\{-90, -6, -1, 2, 5\\}\n\n\n\n\nNow we choose a parameter for splitting is \nT<0\nT<0\n belongs left subtree\nand \nT>0\nT>0\n to right. Lets call this \nT1\n. The mean of above data set\n\n-15\n-15\n, the variance is always going to be positive, so it is not going\nto make change, for this reason I am ignoring the variance. Let the\nvariance = \nk\nk\n. The new data set will look like following:\n\n\n\n\n\\{ -75/k, 9/k, 14/k, 17/k, 20/k\\}\n\n\n\\{ -75/k, 9/k, 14/k, 17/k, 20/k\\}\n\n\n\n\nNow if you use the same parameter to build the new tree we will have one\ndata point on left subtree and 4 data points on right subtree. Lets call\nthis \nT2\n. We can say for sure that \nT1\n and \nT2\n are different.\nSince we had the splitting parameter independent of the data points.\n\n\n\n\nIn case of parameters being dependent on the data points, the\naforementioned transformation will not change the characteristics of\ndata in new setting. If we expand the transformation of data point, it\nwill look like following:\n\n\n\n\n\\begin{aligned}\n X_i \\longrightarrow \\left(\\frac{X_i}{\\sigma^2} - \\frac{\\mu}{\\sigma^2}\\right)\n \\end{aligned}\n\n\n\\begin{aligned}\n X_i \\longrightarrow \\left(\\frac{X_i}{\\sigma^2} - \\frac{\\mu}{\\sigma^2}\\right)\n \\end{aligned}\n\n\n\n\nSo it is one to one mapping from old reference system to new one (\nscaled by \n\\frac{1}{\\sigma^2}\n\\frac{1}{\\sigma^2}\n and then subtracted by\n\n\\frac{\\mu}{\\sigma^2}\n\\frac{\\mu}{\\sigma^2}\n). So the order of data points remain the same in\nnew reference system and the same effect will reflect to the\ncorresponding parameter calculations. In conclusion the new tree \nT2\n\nwill be same as \nT1\n.\n\n\nComparison of Gini index and Cross entropy\n\n\nWe are given:\n\n\n\n\n\\begin{aligned}\nGI = \\sum_{k=1}^{K} p_k(1-p_k) \\end{aligned}\n\n\n\\begin{aligned}\nGI = \\sum_{k=1}^{K} p_k(1-p_k) \\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nCE = - \\sum_{k=1}^{K} p_k \\log p_k \\end{aligned}\n\n\n\\begin{aligned}\nCE = - \\sum_{k=1}^{K} p_k \\log p_k \\end{aligned}\n\n\n\n\n\n\n\\begin{aligned}\nGI - CE = \\sum_{k=1}^{K}p_k(1-p_k + \\log(p_k)) \\\\\n= \\sum_{k = 1}^{K} p_k(q_k + \\log(1-q_k))\\\\\n=\\sum_{k=1}^{K} p_k\\left(q_k + \\left( -q_k - \\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . . \n\\right)   \n\\right)\\\\\n= \\sum_{k=1}^{K} p_k\\left(-\\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . .\n\\right)<=0 \\\\\n\\hspace{20pt} \\\\\n\\text{becasue }p_k, & q_k \\text{ are both non-negative}\\end{aligned}\n\n\n\\begin{aligned}\nGI - CE = \\sum_{k=1}^{K}p_k(1-p_k + \\log(p_k)) \\\\\n= \\sum_{k = 1}^{K} p_k(q_k + \\log(1-q_k))\\\\\n=\\sum_{k=1}^{K} p_k\\left(q_k + \\left( -q_k - \\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . . \n\\right)   \n\\right)\\\\\n= \\sum_{k=1}^{K} p_k\\left(-\\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . .\n\\right)<=0 \\\\\n\\hspace{20pt} \\\\\n\\text{becasue }p_k, & q_k \\text{ are both non-negative}\\end{aligned}\n\n\n\n\nProgramming\n\n\n5.4 Performace comparision\n\n\nIn case of Naive bayes real valued feature has been used. I am changing\nthe code now, so I can not attach the new values, since it was informed\njust one day before the assignment submission. I will try my best to\nmodify the code and submit the electronic version compatible with binary\nfeature support. But I believe the accuracies will remain the same.\nPlease take this into consideration. The tables below contain the\nperformance of different methods.\n\n\n\n\n    K        Train accu.   Valid accu.   Test accu.\n\n\n\n[0.5ex] 1     77.7895       75.5784      79.4344\n        3          83.1579       80.4627      86.3753\n        5          86.6316       83.2905      90.7455\n        7          88.4211       84.0617      89.2031\n        9          88.6316       86.8895      89.4602\n       11          89.0526       86.3753      87.9177\n       13         188.4211       85.6041      87.9177\n       15          87.0526       82.7763      86.3753\n       17          85.8947       82.5193      86.1183\n       19          85.2632       82.2622      85.3470\n       21          85.3684       80.9769      84.8329\n       23          84.5263       82.5193      84.3188\n     [1ex]                                \n\n\n\n\n: Performance at kNN at different values of k\n\n\n\n\ntable:nonlin\n\n\ntable:nonlin\n\n\n\n\n\n\n MinLeaf     Train accu.   Valid accu.   Test accu.\n\n\n\n[0.5ex] 1     96.7368       93.3883      94.7636\n        2          96.7368       93.3883      94.7636\n        3          96.5263       93.9409      94.7636\n        4          96.5263       93.9409      94.7636\n        5          96.3158       94.1839      95.0642\n        6          96.2105       94.6859      94.8224\n        7          96.0000       94.9121      94.8797\n        8          95.8947       95.1871      95.3046\n        9          95.2632       94.6185      94.2199\n       10          94.7368       93.8334      94.2786\n     [1ex]                                \n\n\n\n\n: Decision Tree with different MinLeaf (Gini Index)\n\n\n\n\ntable:nonlin\n\n\ntable:nonlin\n\n\n\n\n\n\n MinLeaf     Train accu.   Valid accu.   Test accu.\n\n\n\n[0.5ex] 1     97.0526       93.3505      94.2163\n        2          97.0526       93.3505      94.2163\n        3          96.8421       93.9032      94.2163\n        4          96.8421       93.9032      94.2163\n        5          96.6316       94.1462      94.5168\n        6          96.5263       94.6482      94.2750\n        7          96.3158       94.8744      94.3323\n        8          95.8947       95.1871      95.3046\n        9          95.2632       94.6185      94.2199\n       10          94.7368       93.8334      94.2786\n     [1ex]                                \n\n\n\n\n: Decision Tree with different MinLeaf (Cross Entropy)\n\n\n\n\ntable:nonlin\n\n\ntable:nonlin\n\n\n\n\n\n\n      Method           Train accu.   Valid accu.   Test accu.\n\n\n\n[0.5ex] Naive Bayes      87.05         83.80        83.80\n       Logistic reg           83.89         81.49        85.35\n          [1ex]                                     \n\n\n\n\n: Performance of Naive Bayes and Logistic Reg.\n\n\n\n\ntable:nonlin\n\n\ntable:nonlin\n\n\n\n\n5.5 Decision Boundary\n\n\n\n\n\n\n\n\n\n\nAs we can see in the figure when the value of K increases, the decision\nboundary smoothen out. As we can see in case of K = 20, very less red\ndata points lying in the blue region and just one chunk of blue point\nlying on left bottom of the figure.",
            "title": "Homework 1"
        },
        {
            "location": "/solution_hw_1/#naive-bayes",
            "text": "",
            "title": "Naive Bayes"
        },
        {
            "location": "/solution_hw_1/#parametric-form-of-naive-bayes-with-gaussian-assumption",
            "text": "Feature vector  X \\in R^D X \\in R^D  and  Y Y  is a binary random vector.   Y \\sim Bern(\\pi)  Y \\sim Bern(\\pi)    X = \\{X_1, ..., X_D\\}  X = \\{X_1, ..., X_D\\}    P (X_j| Y = y_k ) \\sim N(\\mu_{jk}, \\sigma_j)  P (X_j| Y = y_k ) \\sim N(\\mu_{jk}, \\sigma_j)   Naive Bayes assumes the conditional independence of features given  Y Y   P(X_i = x_i, X_j = x_j | Y = y_k) = P (X_i = x_i | Y =y_k)*P(X_j = x_j| Y= y_k) \\space \\forall i \\neq j  P(X_i = x_i, X_j = x_j | Y = y_k) = P (X_i = x_i | Y =y_k)*P(X_j = x_j| Y= y_k) \\space \\forall i \\neq j   Here we have to show that the posterior probability can be written as\nthe posterior of logistic regression.Proceeding with above assumptions.   \\begin{aligned}\nP(Y = 1 | X ) = \\frac{P(X| Y = 1)*P(Y = 1)}{P(X)}\\end{aligned}  \\begin{aligned}\nP(Y = 1 | X ) = \\frac{P(X| Y = 1)*P(Y = 1)}{P(X)}\\end{aligned}    \\begin{aligned}\nP(X) = P(X|Y = 0)*P(Y = 0) + P (X| Y = 1)* P(Y = 1 )\\end{aligned}  \\begin{aligned}\nP(X) = P(X|Y = 0)*P(Y = 0) + P (X| Y = 1)* P(Y = 1 )\\end{aligned}   Using eq. (1.2) in (1.1) and bringing the numerator to denominator\nsimplifies eq. (1) to the following.   \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}{1 + \\frac{P(X| Y = 0)*P(Y = 0)}{P(X| Y = 1 )*P(Y = 1)}}\\end{aligned}  \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}{1 + \\frac{P(X| Y = 0)*P(Y = 0)}{P(X| Y = 1 )*P(Y = 1)}}\\end{aligned}    \\begin{aligned}\nP(X | Y = y_k) = \\prod_{i=1}^D P (X_i| Y = y_k)\\end{aligned}  \\begin{aligned}\nP(X | Y = y_k) = \\prod_{i=1}^D P (X_i| Y = y_k)\\end{aligned}    \\begin{aligned}\nP(X_i | Y = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_i}exp\\left(-\\frac{(X_i - \\mu_{ik})^2}{2\\sigma_{i}^2}\\right)\\end{aligned}  \\begin{aligned}\nP(X_i | Y = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_i}exp\\left(-\\frac{(X_i - \\mu_{ik})^2}{2\\sigma_{i}^2}\\right)\\end{aligned}    \\begin{aligned}\nP (Y = 1) = \\pi , P (Y = 0 ) = 1 -\\pi\\end{aligned}  \\begin{aligned}\nP (Y = 1) = \\pi , P (Y = 0 ) = 1 -\\pi\\end{aligned}   Using eq. (1.4),(1.5) and (1.6) in eq. (1.3) we get the simplified form\nas following   \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1 - \\pi}\n{\\pi} *\n\\frac{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}    \\right)     }\n{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}    \\right) } }\\end{aligned}  \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1 - \\pi}\n{\\pi} *\n\\frac{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}    \\right)     }\n{\\prod_{i = 1 }^{D} exp \\left(- \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}    \\right) } }\\end{aligned}   Solving further to simpler terms by assuming the following:   Z_{i0} = \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}  Z_{i0} = \\frac{(X_i - \\mu_{i0})^2}\n{2\\sigma_i^2}    Z_{i1} = \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}  Z_{i1} = \\frac{(X_i - \\mu_{i1})^2}\n{2\\sigma_i^2}    \\begin{aligned}\n Z_{i1} - Z_{i0}  = \\frac{(2X_i - (\\mu_{i0} + \\mu_{i1}) )*(\\mu_{i0} - \\mu_{i1})}{2\\sigma_i^2}\n \\end{aligned}  \\begin{aligned}\n Z_{i1} - Z_{i0}  = \\frac{(2X_i - (\\mu_{i0} + \\mu_{i1}) )*(\\mu_{i0} - \\mu_{i1})}{2\\sigma_i^2}\n \\end{aligned}    \\begin{aligned}\n= \\frac{X_i*(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}  - \\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}{2\\sigma_i^2}\\end{aligned}  \\begin{aligned}\n= \\frac{X_i*(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}  - \\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}{2\\sigma_i^2}\\end{aligned}   eq. (1.7) can be rewritten using simplified terms like  Z_{i1} - Z_{i0} Z_{i1} - Z_{i0} \nas following.   \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1-\\pi}\n{\\pi}*\\prod_{i=1}^{D}exp \\left( \\frac{-(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2} + \\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i   \\right)}\\end{aligned}  \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + \\frac{1-\\pi}\n{\\pi}*\\prod_{i=1}^{D}exp \\left( \\frac{-(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2} + \\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i   \\right)}\\end{aligned}   Product term in denominator of eq. (1.8) can be substituted with summand\ninside the exponential expression, and  \\frac{1-\\pi}{\\pi} \\frac{1-\\pi}{\\pi}  can be\nwritten as  exp\\left(-log\\frac{\\pi}{1 - \\pi}\\right). exp\\left(-log\\frac{\\pi}{1 - \\pi}\\right).  Doing above\nchanges to eq. (1.8) it reduces to the following form.   \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + exp \\left\\lbrace - \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i\n\\right\\rbrace}\\end{aligned}  \\begin{aligned}\nP(Y = 1 | X ) = \\frac{1}\n{1 + exp \\left\\lbrace - \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0} - \\mu_{i1})}{\\sigma_i^2}*X_i\n\\right\\rbrace}\\end{aligned}   We can see clearly in eq. (1.9) that the posterior probability is taking\nthe form of logistic regression. Comparing with the logistic regression\nexpression. We can write the parameters as follows:   \\begin{aligned}\n\\omega_0 = \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\\end{aligned}  \\begin{aligned}\n\\omega_0 = \\left(log\\frac{\\pi}{1 - \\pi}\n+ \\sum_{i = 1}^{D}\\frac{(\\mu_{i0}^2 - \\mu_{i1}^2)}\n{2\\sigma_i^2}\n\\right)\\end{aligned}    \\begin{aligned}\n\\textbf{w} = \\left[\\frac{(\\mu_{00} - \\mu_{01})}{\\sigma_1^2} , ... , \\frac{(\\mu_{D0} - \\mu_{D1})}{\\sigma_D^2}\\right]^T\\end{aligned}  \\begin{aligned}\n\\textbf{w} = \\left[\\frac{(\\mu_{00} - \\mu_{01})}{\\sigma_1^2} , ... , \\frac{(\\mu_{D0} - \\mu_{D1})}{\\sigma_D^2}\\right]^T\\end{aligned}",
            "title": "Parametric form of Naive Bayes with Gaussian Assumption"
        },
        {
            "location": "/solution_hw_1/#parametric-estimation-for-naive-bayes-with-gaussian-assumption",
            "text": "We have training set of size  N N  of the form (\\textbf{x}_\\textbf{i}, y_i) (\\textbf{x}_\\textbf{i}, y_i) , where   \\begin{aligned}\n\\textbf{x}_\\textbf{i} = (x_{i1}, ..., x_{iD})^T, y_i \\in \\{0,1\\}\\end{aligned}  \\begin{aligned}\n\\textbf{x}_\\textbf{i} = (x_{i1}, ..., x_{iD})^T, y_i \\in \\{0,1\\}\\end{aligned}   Since we have to estimate the distribution parameters such as \\pi_i, \\mu_{jk}, \\pi_i, \\mu_{jk},  and  \\sigma_j \\sigma_j . We can do this by writing log\nlikelihood and differentiating w.r.t corresponding parameters and set to\nzero to get the values. Following derivation are for the log likelihood\nand parameter estimation.  Joint probability can be written as   \\begin{aligned}\nP(X, Y ) = \\prod_{i = 1 }^{N} P (X_i, Y_i)= \\prod_{i = 1 }^{N} P(X_i | Y_i = y_k)*P (Y_i = y_k)\\end{aligned}  \\begin{aligned}\nP(X, Y ) = \\prod_{i = 1 }^{N} P (X_i, Y_i)= \\prod_{i = 1 }^{N} P(X_i | Y_i = y_k)*P (Y_i = y_k)\\end{aligned}    \\begin{aligned}\n= \\prod_{i = 1}^{N}P(Y_i = y_k)\\prod_{j = 1}^{D}P(X_{ij} = x_{ij} | Y_i = y_k)\\end{aligned}  \\begin{aligned}\n= \\prod_{i = 1}^{N}P(Y_i = y_k)\\prod_{j = 1}^{D}P(X_{ij} = x_{ij} | Y_i = y_k)\\end{aligned}   In above deduction we have used the naive bayes assumption. Now we know\nthe following:   \\begin{aligned}\nP(Y_i = y_k) = \\pi^{y_k}*(1-\\pi)^{(1-y_k)}\\end{aligned}  \\begin{aligned}\nP(Y_i = y_k) = \\pi^{y_k}*(1-\\pi)^{(1-y_k)}\\end{aligned}    \\begin{aligned}\nP(X_{ij} = x_{ij} | Y_i = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_j}exp\\left(-\\frac{(x_{ij} - \\mu_{jk})^2}{2\\sigma_{j}^2}\\right)\\end{aligned}  \\begin{aligned}\nP(X_{ij} = x_{ij} | Y_i = y_k) = \\frac{1}{(2\\pi)^{1/2}\\sigma_j}exp\\left(-\\frac{(x_{ij} - \\mu_{jk})^2}{2\\sigma_{j}^2}\\right)\\end{aligned}   Since we know that log likelihood is the log of joint pdf. We can take\nthe log on both side of eq. (1.10) to get the log likelihood.   \\begin{aligned}\nl(\\theta | X, Y) = logP(X,Y) = \\sum_{i = 1}^{N}\\left( log P(Y_i = y_k) + \\sum_{j = 1}^{D} log P (X_{ij} = x_{ij} | Y_i = y_k)\n\\right)  \\end{aligned}  \\begin{aligned}\nl(\\theta | X, Y) = logP(X,Y) = \\sum_{i = 1}^{N}\\left( log P(Y_i = y_k) + \\sum_{j = 1}^{D} log P (X_{ij} = x_{ij} | Y_i = y_k)\n\\right)  \\end{aligned}    \\begin{aligned}\n= \\sum_{i = 1}^{N} \\left( y_klog\\pi + (1-y_k)log(1 - \\pi) + \\sum_{j = 1}^{D} \\left( -log ( (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{jk})^2}\n{2\\sigma_j^2}\n\\right)\n\\right)\\end{aligned}  \\begin{aligned}\n= \\sum_{i = 1}^{N} \\left( y_klog\\pi + (1-y_k)log(1 - \\pi) + \\sum_{j = 1}^{D} \\left( -log ( (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{jk})^2}\n{2\\sigma_j^2}\n\\right)\n\\right)\\end{aligned}   Suppose there are m data points with label 1 and N-m with label 0, above\nequation can be rewritten as following:   \\begin{aligned}\nl(\\theta | X, Y) = \\sum_{i:Y_i = y_k = 1}y_klog\\pi  + \\sum_{i:Y_i = y_k = 0}(1-y_k)log(1-\\pi) \\\\ + \\sum_{i:Y_i = y_k = 1}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j1})^2}{2\\sigma} \n\\right) \\\\ +  \\sum_{i:Y_i = y_k = 0}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j0})^2}{2\\sigma} \n\\right)\\end{aligned}  \\begin{aligned}\nl(\\theta | X, Y) = \\sum_{i:Y_i = y_k = 1}y_klog\\pi  + \\sum_{i:Y_i = y_k = 0}(1-y_k)log(1-\\pi) \\\\ + \\sum_{i:Y_i = y_k = 1}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j1})^2}{2\\sigma} \n\\right) \\\\ +  \\sum_{i:Y_i = y_k = 0}\\sum_{j=1}^{D}\\left( -log (2\\pi)^{1/2}\\sigma_j - \\frac{(x_{ij} - \\mu_{j0})^2}{2\\sigma} \n\\right)\\end{aligned}   Calculating MLE for  \\pi \\pi :   \\begin{aligned}\n\\hat{\\pi} = \\left\\lbrace \\pi: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = 0  \\right\\rbrace\\end{aligned}  \\begin{aligned}\n\\hat{\\pi} = \\left\\lbrace \\pi: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = 0  \\right\\rbrace\\end{aligned}    \\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = \\frac{m}{\\pi} - \\frac{(N - m)}{1 - \\pi} + 0 + 0  \\end{aligned}  \\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi} = \\frac{m}{\\pi} - \\frac{(N - m)}{1 - \\pi} + 0 + 0  \\end{aligned}   Equating the above equation to zero and solving for  \\pi \\pi   \\begin{aligned}\nm(1 - \\pi)  - (N-m)\\pi = 0 \n\\implies m - N\\pi = 0 \n\\implies \\pi = \\frac{m}{N} \\end{aligned}  \\begin{aligned}\nm(1 - \\pi)  - (N-m)\\pi = 0 \n\\implies m - N\\pi = 0 \n\\implies \\pi = \\frac{m}{N} \\end{aligned}   So the likelihood parameter estimation of  \\pi \\pi  is:   \\begin{aligned}\n\\hat{\\pi} = \\frac{m}{N} = \\frac{\\#label = 1 }{N}\\end{aligned}  \\begin{aligned}\n\\hat{\\pi} = \\frac{m}{N} = \\frac{\\#label = 1 }{N}\\end{aligned}   Likelihood for  \\mu_{jk} \\mu_{jk} :   \\begin{aligned}\n\\hat{\\mu}_{jk} = \\left\\lbrace \\mu_{jk}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\mu_{jk}} = 0  \\right\\rbrace\\end{aligned}  \\begin{aligned}\n\\hat{\\mu}_{jk} = \\left\\lbrace \\mu_{jk}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\mu_{jk}} = 0  \\right\\rbrace\\end{aligned}   We can do this in two parts, k = 0 and k = 1 for k = 0, we shall only\nhave the fourth term in partial differentiation, other term will give\nzeros.   \\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi}  = \\sum_{i:Y_i = y_k = 0}- \\frac{(x_{ij} - \\mu_{jo})}{\\sigma_j^2}*(-1) = 0 \\\\\n\\implies \\sum_{i:Y_i = y_k = 0}(x_{ij} - \\mu_{jo}) = 0 \\end{aligned}  \\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\pi}  = \\sum_{i:Y_i = y_k = 0}- \\frac{(x_{ij} - \\mu_{jo})}{\\sigma_j^2}*(-1) = 0 \\\\\n\\implies \\sum_{i:Y_i = y_k = 0}(x_{ij} - \\mu_{jo}) = 0 \\end{aligned}   From above assumption we know the count of zero labels are  N-m N-m  Solving\nabove equality gives us the following   \\begin{aligned}\n(N-m)*\\mu_{j0} = \\sum_{i:Y_i = y_k = 0} x_{ij}\\end{aligned}  \\begin{aligned}\n(N-m)*\\mu_{j0} = \\sum_{i:Y_i = y_k = 0} x_{ij}\\end{aligned}   which gives us   \\begin{aligned}\n\\hat{\\mu}_{j0} = \\frac{\\sum_{i:Y_i = y_k = 0} x_{ij}}{(N-m)}\\end{aligned}  \\begin{aligned}\n\\hat{\\mu}_{j0} = \\frac{\\sum_{i:Y_i = y_k = 0} x_{ij}}{(N-m)}\\end{aligned}   Similarly we get the estimate for  \\mu_{j1} \\mu_{j1}   \\begin{aligned}\n\\hat{\\mu}_{j1} = \\frac{\\sum_{i:Y_i = y_k = 1} x_{ij}}{(m)}\\end{aligned}  \\begin{aligned}\n\\hat{\\mu}_{j1} = \\frac{\\sum_{i:Y_i = y_k = 1} x_{ij}}{(m)}\\end{aligned}   Likelihood for  \\sigma_{j} \\sigma_{j} :   \\begin{aligned}\n\\hat{\\sigma}_{j} = \\left\\lbrace \\sigma_{j}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}} = 0  \\right\\rbrace\\end{aligned}  \\begin{aligned}\n\\hat{\\sigma}_{j} = \\left\\lbrace \\sigma_{j}: \\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}} = 0  \\right\\rbrace\\end{aligned}    \\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}}  = \\sum_{i:Y_i =y_k = 1} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j1})^2}{\\sigma_{j}^3}\n\\right)\\\\\n+ \\sum_{i:Y_i = y_k = 0} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j0})^2}{\\sigma_{j}^3}\n\\right)\\\\\n= - \\frac{N}{\\sigma_{j}} + \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{\\sigma_{j}^3}\\end{aligned}  \\begin{aligned}\n\\frac{\\partial l(\\theta|X,Y)}{\\partial\\sigma_{j}}  = \\sum_{i:Y_i =y_k = 1} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j1})^2}{\\sigma_{j}^3}\n\\right)\\\\\n+ \\sum_{i:Y_i = y_k = 0} \\left( -\\frac{1}{\\sigma_{j}} + \\frac{(x_{ij} - \\mu_{j0})^2}{\\sigma_{j}^3}\n\\right)\\\\\n= - \\frac{N}{\\sigma_{j}} + \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{\\sigma_{j}^3}\\end{aligned}   Equating it to zero will give the following:   \\begin{aligned}\n\\sigma_{j}^2 = \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}\\\\\n\\implies \\hat{\\sigma}_{j} = \\sqrt{\\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}}\\end{aligned}  \\begin{aligned}\n\\sigma_{j}^2 = \\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}\\\\\n\\implies \\hat{\\sigma}_{j} = \\sqrt{\\frac{\\sum_{i = 1 }^{N}\\left( y_k (x_{ij} - \\mu_{j1})^2 + (1 - y_k ) (x_{ij} - \\mu_{j0})^2\\right)}\n{N}}\\end{aligned}",
            "title": "Parametric estimation for Naive Bayes with Gaussian assumption"
        },
        {
            "location": "/solution_hw_1/#nearest-neighbor",
            "text": "",
            "title": "Nearest Neighbor"
        },
        {
            "location": "/solution_hw_1/#feature-weighting-in-low-dimension",
            "text": "Feature weighting is required in case of noise, because noise affect the\neuclidean distance measures which can lead to poor performance of KNN.\nThis is also known as Achilles\u2019 heel of KNN. In case of low dimension D = 3 D = 3  with discretized values of weights in each dimension. We can do\ngrid search to look for the optimal weights which can give the best\ntraining accuracy. The procedure explained below can be used to find the\noptimal weights for the features. Here we have following assumption   \\begin{aligned}\nX_i = \\left(x_{i1}, x_{i2}, x_{i3}\\right)^T\\\\\nW = \\left(w_1, w_2, w_3\\right)\\\\\nw_i \\in \\{w_{i1}, w_{i2}, .,.,., w_{ik}\\}\\end{aligned}  \\begin{aligned}\nX_i = \\left(x_{i1}, x_{i2}, x_{i3}\\right)^T\\\\\nW = \\left(w_1, w_2, w_3\\right)\\\\\nw_i \\in \\{w_{i1}, w_{i2}, .,.,., w_{ik}\\}\\end{aligned}   The weights has been discretized to  k k  values. We can just do grid\nsearch by using following pseudo code.  opt (W) = {}  for  w_1 = w_{11}:w_{1k} w_1 = w_{11}:w_{1k}  for  w_2 = w_{21}:w_{2k} w_2 = w_{21}:w_{2k}  for  w_3 = w_{31}:w_{3k} w_3 = w_{31}:w_{3k}  for  i = 1:N i = 1:N  for  j\\neq i = 1:N j\\neq i = 1:N  compute  d(X_i, X_j) d(X_i, X_j)  end  end  Compute the training accuracy and update opt(W) if accuracy is  better.  end  end  end  For this approach we can also use dynamic programming to reduce the\ncomputation, we can maintain the  N N x N N x D D  matrix with entries of\neuclidean distances of feature vectors. Afterwards we can use this\nmatrix as lookup table and just multiply with the weights to get the\nweighted feature distance. Using the Dynamic programming approach will\nlead to following complexity: Time complexity:   O(k^3)  O(k^3)   Space complexity:   O(N^2)  O(N^2)",
            "title": "Feature weighting in low dimension"
        },
        {
            "location": "/solution_hw_1/#feature-weighting-in-higher-dimensions",
            "text": "In higher dimension above approach of finding optimal weight will lead\nto exponential time complexity  O(k^D) O(k^D) . This is curse of\ndimensionality. As being instructed by TA that we do not have to use any\nstatistical approach to construct the method for assigning weights to\nfeatures (We have to design algorithm). If we present the weighted\ndistances calculation in matrix form, it will appear as follows:   \\begin{aligned}\n\\hat{Label}(X_1) = Label \\left(X_j : j = \\min_{j}\n\\begin{bmatrix}\nw_1 &  . &  w_D\n\\end{bmatrix}\n\\begin{bmatrix}\n(x_{11} - x_{21})^2 &  (x_{11} - x_{31})^2 &  . & (x_{11} - x_{N1})^2 \\\\\n(x_{12} - x_{22})^2  & (x_{12} - x_{32})^2 &  . & (x_{12} - x_{N2})^2 \\\\\n.  & . & .  & . & \\\\\n.  & . & .  & . & \\\\\n(x_{1D} - x_{2D})^2 & (x_{1D} - x_{3D})^2  &  . & (x_{1D} - x_{ND})^2\n\\end{bmatrix}\n\\right)\\end{aligned}  \\begin{aligned}\n\\hat{Label}(X_1) = Label \\left(X_j : j = \\min_{j}\n\\begin{bmatrix}\nw_1 &  . &  w_D\n\\end{bmatrix}\n\\begin{bmatrix}\n(x_{11} - x_{21})^2 &  (x_{11} - x_{31})^2 &  . & (x_{11} - x_{N1})^2 \\\\\n(x_{12} - x_{22})^2  & (x_{12} - x_{32})^2 &  . & (x_{12} - x_{N2})^2 \\\\\n.  & . & .  & . & \\\\\n.  & . & .  & . & \\\\\n(x_{1D} - x_{2D})^2 & (x_{1D} - x_{3D})^2  &  . & (x_{1D} - x_{ND})^2\n\\end{bmatrix}\n\\right)\\end{aligned}   We do above calculation for every data point. Since there are  k^D k^D \npossible matrices  [w_1 ... w_D ] [w_1 ... w_D ] , we can not calculate this in\npolynomial time. One way to select meaningful features from the haystack\nis to calculate the training accuracy on each individual feature by\nsetting other\u2019s weight to zero. we assign the weight to be training\naccuracy of that individual feature. We can decide how many feature we\nhave to take into consideration. This will result into the limited\nfeatures with weight assigned on each of them.  2 nd  method  Objective\nfunction for above problem will look like following:   \\begin{aligned}\nJ(W) = \\sum_{i=1}^{N}\\left( \\hat{Label}(X_i) - Label (X_i) \\right)\\end{aligned}  \\begin{aligned}\nJ(W) = \\sum_{i=1}^{N}\\left( \\hat{Label}(X_i) - Label (X_i) \\right)\\end{aligned}   The characteristic of above objective function is a curve in higher\ndimension with multiple local minimum. We can use the gradient descent\napproach to find the local minima\u2019s we can start with different set of\nrandom weight vectors and try to find the different minimum, select the\nbest one out of these and return those weight vectors as weighted\nfeature vector. This is a polynomial time algorithm, but of course this\nmay not give the optimal solution.",
            "title": "Feature weighting in higher dimensions"
        },
        {
            "location": "/solution_hw_1/#logistic-regression",
            "text": "",
            "title": "Logistic regression"
        },
        {
            "location": "/solution_hw_1/#negative-log-likelihood-or-loss-function",
            "text": "\\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right)\\end{aligned}  \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right)\\end{aligned}   We know that   \\begin{aligned}\nP (Y = 1 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})} = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}  \\begin{aligned}\nP (Y = 1 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})} = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}    \\begin{aligned}\nP (Y = 0 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) =  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}  \\begin{aligned}\nP (Y = 0 | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) =  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})\\\\\\end{aligned}    \\begin{aligned}\nP (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})^{y_i} (  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )^{1-y_i}\\\\\n\\log P (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} )  = y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )\\end{aligned}  \\begin{aligned}\nP (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} ) = \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})^{y_i} (  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )^{1-y_i}\\\\\n\\log P (Y = y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}} )  = y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) )\\end{aligned}   Writing the negative log likelihood in simpler form using above\nexpression   \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\log(P (Y = y_i| \\textbf{X} = \\textbf{x}_{\\textbf{i}}))\\end{aligned}  \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\log(P (Y = y_i| \\textbf{X} = \\textbf{x}_{\\textbf{i}}))\\end{aligned}    \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\left(y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) ) \n\\right)\\end{aligned}  \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = - \\sum_{i = 1 }^{n} \\left(y_i \\log \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) + (1-y_i)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}}) ) \n\\right)\\end{aligned}",
            "title": "Negative log likelihood or Loss function"
        },
        {
            "location": "/solution_hw_1/#proof-for-convexity-of-loss-function",
            "text": "To prove the convexity we are going to show that the hessian matrix will\nbe positive semidefinite. In order to make the derivation simpler we are\ngoing to use the property of convex functions. If  f(x) f(x)  and  g(x) g(x)  are\ntwo convex function then their sum  h(x) h(x)  is also going to be the convex\nfunction Proof: As we know from the property of convex function   f(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2)  f(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2)    g(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda g(x_1) + (1 - \\lambda)g(x_2)  g(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda g(x_1) + (1 - \\lambda)g(x_2)   Adding above two equations we get the following:   f(\\lambda x_1 + (1-\\lambda)x_2 ) + g(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2) + \\lambda g(x_1) + (1 - \\lambda)g(x_2)  f(\\lambda x_1 + (1-\\lambda)x_2 ) + g(\\lambda x_1 + (1-\\lambda)x_2 ) <= \\lambda f(x_1) + (1 - \\lambda)f(x_2) + \\lambda g(x_1) + (1 - \\lambda)g(x_2)    h(\\lambda x_1 + (1-\\lambda)x_2 )) <= \\lambda h(x_1) + (1 - \\lambda)h(x_2)  h(\\lambda x_1 + (1-\\lambda)x_2 )) <= \\lambda h(x_1) + (1 - \\lambda)h(x_2)   So  h(x) h(x)  is also convex. Multiplying by any positive constant preserves\nthe convexity. Considering just one term from loss function.   \\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\end{aligned}  \\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\end{aligned}    \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i)\\end{aligned}  \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i)\\end{aligned}   If we prove that $T(\\textbf{w,x},y) $ is convex then we can say that \\mathcal{L}(\\textbf{w}) \\mathcal{L}(\\textbf{w})  is convex (by above proved lemma).   \\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\\\\n= -y\\log \\left(\\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) - (1-y)\\log\\left(1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n=y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y)\\log\\left(\\frac{\\exp(-\\textbf{w}^{T}\\textbf{x})}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n= y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y) \\left( -\\textbf{w}^{T}\\textbf{x} - \\log\\left(  1 + \\exp(-\\textbf{w}^{T}\\textbf{x}\n\\right)\n\\right)\\\\\n=(1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)\\end{aligned}  \\begin{aligned}\nT(\\textbf{w,x},y) = - \\left(y \\log \\sigma(\\textbf{w}^{T}\\textbf{x}) + (1-y)\\log(  1 - \\sigma(\\textbf{w}^{T}\\textbf{x}) ) \n\\right)\\\\\n= -y\\log \\left(\\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) - (1-y)\\log\\left(1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n=y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y)\\log\\left(\\frac{\\exp(-\\textbf{w}^{T}\\textbf{x})}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right)\\\\\n= y\\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right) - (1-y) \\left( -\\textbf{w}^{T}\\textbf{x} - \\log\\left(  1 + \\exp(-\\textbf{w}^{T}\\textbf{x}\n\\right)\n\\right)\\\\\n=(1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)\\end{aligned}   Finally we get:   T(\\textbf{w,x},y) = (1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)  T(\\textbf{w,x},y) = (1-y) \\textbf{w}^{T}\\textbf{x} + \\log \\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)   We need to find the hessian (H) (H)  of this which is basically  D D x D D \nmatrix and the element  H(j,k) H(j,k)  is:   \\begin{aligned}\nH(j,k) = \\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k}\\end{aligned}  \\begin{aligned}\nH(j,k) = \\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k}\\end{aligned}   Now calculating the  H(j,k) H(j,k) . Calculating the first derivative.   \\begin{aligned}\n\\frac{\\partial T(\\textbf{w,x},y)}{\\partial w_j} = \\frac{-x_j * \\exp(-\\textbf{w}^{T}\\textbf{x})}{ 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})} + x_j(1-y)\\\\\n= -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) +x_j(1-y)\\end{aligned}  \\begin{aligned}\n\\frac{\\partial T(\\textbf{w,x},y)}{\\partial w_j} = \\frac{-x_j * \\exp(-\\textbf{w}^{T}\\textbf{x})}{ 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})} + x_j(1-y)\\\\\n= -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x})}\n\\right) +x_j(1-y)\\end{aligned}   Differentiating above w.r.t.  w_k w_k   \\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = 0 + x_j \\left[ \\frac{(-1)*\\exp(-\\textbf{w}^{T}\\textbf{x})*(-x_k) }{\\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)^2}\n\\right] + 0 \\\\\n= x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k\\end{aligned}  \\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = 0 + x_j \\left[ \\frac{(-1)*\\exp(-\\textbf{w}^{T}\\textbf{x})*(-x_k) }{\\left( 1 + \\exp(-\\textbf{w}^{T}\\textbf{x})\n\\right)^2}\n\\right] + 0 \\\\\n= x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k\\end{aligned}    \\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k \\end{aligned}  \\begin{aligned}\n\\frac{\\partial^2 T(\\textbf{w,x},y)}{\\partial w_j \\partial w_k} = x_j * \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x}))*x_k \\end{aligned}   Note:  \\sigma(x) >= 0 \\hspace{8pt} \\forall x \\sigma(x) >= 0 \\hspace{8pt} \\forall x  If we fill out the Hessian matrix it will look like following:   \\begin{aligned}\nH = \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x})) \\begin{bmatrix}\nx_1^2 & x_1x_2 &  . & .& . & x_1x_D\\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\nx_Dx_1 & x_Dx_2 & . & . & . & x_D^2\n\\end{bmatrix}\\end{aligned}  \\begin{aligned}\nH = \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x})) \\begin{bmatrix}\nx_1^2 & x_1x_2 &  . & .& . & x_1x_D\\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\n.  & . & . & . & . & . & \\\\\nx_Dx_1 & x_Dx_2 & . & . & . & x_D^2\n\\end{bmatrix}\\end{aligned}   Let K =  \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x})) K =  \\sigma(\\textbf{w}^{T}\\textbf{x})*(1-\\sigma(\\textbf{w}^{T}\\textbf{x})) \nwhich is always greater than or equal to zero, matrix in above\nexpression can be decomposed into  XX^T XX^T  where X is a column matrix. So H H  can be rewritten as   \\begin{aligned}\nH = K XX^T\\end{aligned}  \\begin{aligned}\nH = K XX^T\\end{aligned}   where   X = \\begin{bmatrix}\nx_1 & x_2 & . & . & .& . x_D\n\\end{bmatrix}^T  X = \\begin{bmatrix}\nx_1 & x_2 & . & . & .& . x_D\n\\end{bmatrix}^T   H H  is a positive semidefinite matrix because if we take any vector  V V \nand calculate  V^THV V^THV  then it is always $>= 0 $. Following is the proof.   \\begin{aligned}\nV^THV = V^T KXX^T V = K (X^TV)^T (X^TV) = K ||X^TV||^2 >=0 \\hspace{20pt} \\end{aligned}  \\begin{aligned}\nV^THV = V^T KXX^T V = K (X^TV)^T (X^TV) = K ||X^TV||^2 >=0 \\hspace{20pt} \\end{aligned}   Since the Hessian is a PSD we can say that function is convex. Referring\nto eq.(3.2) the loss function is just the linear combination of  T(.) T(.) .\nAs we proved in the lemma that sum of convex functions is a convex\nfunction. Hence it is proved that the loss function is convex.",
            "title": "Proof for convexity of loss function"
        },
        {
            "location": "/solution_hw_1/#magnitude-of-optimal-w",
            "text": "Considering the binary logistic regression and samples are linearly\nseparable.",
            "title": "Magnitude of optimal w"
        },
        {
            "location": "/solution_hw_1/#regularized-logistic-regression",
            "text": "Since optimal  \\textbf{w} \\longrightarrow \\infty \\textbf{w} \\longrightarrow \\infty , in order to handle\nthe numerical instability the regularization term is being added to the\nloss function, and the regularized linear regression looks like\nfollowing:   \\begin{aligned}\n\\mathcal{L} (\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right) + \\lambda||\\textbf{w}||_2^2\\end{aligned}  \\begin{aligned}\n\\mathcal{L} (\\textbf{w}) = -\\log\\left( \\prod_{1= 1}^{n}P (Y = Y_i | \\textbf{X} = \\textbf{x}_{\\textbf{i}})\n\\right) + \\lambda||\\textbf{w}||_2^2\\end{aligned}   Computing gradient w.r.t.  \\omega_i \\omega_i . Referring to eq. (3.2) and the\nfirst derivative of  T(\\textbf{w,x},y) T(\\textbf{w,x},y)   \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) +  \\lambda||\\textbf{w}||_2^2\\end{aligned}  \\begin{aligned}\n\\mathcal{L}(\\textbf{w}) = \\sum_{i = 1}^{n}T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) +  \\lambda||\\textbf{w}||_2^2\\end{aligned}    \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =  \\sum_{i = 1 }^{n} \\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j} + 2\\lambda \\omega_j\\end{aligned}  \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =  \\sum_{i = 1 }^{n} \\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j} + 2\\lambda \\omega_j\\end{aligned}   We have already calculated the term \\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j} \\frac{\\partial T(\\textbf{w,}\\textbf{x}_{\\textbf{i}},y_i) }{\\partial \\omega_j} \nin the process of proving the hessian matrix to be PSD. We can just\nplugin that term here. After plugging in the term we get the following :   \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right) +x_j(1-y_i)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}  \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( 1 - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right) +x_j(1-y_i)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}   Further simplifying above equation(  x_j x_j  cancels out ).   \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( y_i - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right)\n\\right)\n+ 2\\lambda\\omega_j \\\\\n= -\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}  \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  = \\sum_{i = 1 }^{n} \\left( -x_j\\left( y_i - \\frac{1}{1 + \\exp(-\\textbf{w}^{T}\\textbf{x}_{\\textbf{i}})}\n\\right)\n\\right)\n+ 2\\lambda\\omega_j \\\\\n= -\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}    \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =\n-\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}  \\begin{aligned}\n\\frac{\\partial \\mathcal{L}(\\textbf{w})}{\\partial \\omega_j}  =\n-\\sum_{i = 1 }^{n} \\left( x_j\\left( y_i - P(Y_i = 1 |X = \\textbf{x}_{\\textbf{i}} )\n\\right)\n\\right)\n+ 2\\lambda\\omega_j\\end{aligned}",
            "title": "Regularized logistic regression"
        },
        {
            "location": "/solution_hw_1/#unique-solution-of-the-regularized-loss-function",
            "text": "Since we have already proven that the loss function without\nregularization is convex and the regularization term is also convex\n(because  \\lambda > 0 \\lambda > 0  and  ||\\textbf{w}||^2 > 0 ||\\textbf{w}||^2 > 0 ) so the linear\ncombination will always be convex. There will be  \\textbf{w}^* \\textbf{w}^*  for\nwhich   \\begin{aligned}\n\\mathcal{L}(\\textbf{w}^*) <\\mathcal{L}(\\textbf{w}) \\hspace{10pt} \\forall \\textbf{w}\\neq \\textbf{w}^*\\in \\textbf{W}\\end{aligned}  \\begin{aligned}\n\\mathcal{L}(\\textbf{w}^*) <\\mathcal{L}(\\textbf{w}) \\hspace{10pt} \\forall \\textbf{w}\\neq \\textbf{w}^*\\in \\textbf{W}\\end{aligned}   We can start at any  \\textbf{w}_0 \\textbf{w}_0  and reach  \\textbf{w}^* \\textbf{w}^*  by using\ngradient descent approach.",
            "title": "Unique solution of the regularized loss function"
        },
        {
            "location": "/solution_hw_1/#decision-tree",
            "text": "",
            "title": "Decision Tree"
        },
        {
            "location": "/solution_hw_1/#building-a-decision-tree",
            "text": "Selection of predictor to form the decision tree  We shall be\nchoosing the predictor which can maximize the information gain.   \\begin{aligned}\nIG(Predictor) = H(Target) - H(Target|Predictor)\\\\\\end{aligned}  \\begin{aligned}\nIG(Predictor) = H(Target) - H(Target|Predictor)\\\\\\end{aligned}   Where  H(Target) H(Target)  is the entropy of target and  H(Target|Predictor) H(Target|Predictor)  is\nconditional entropy over predictor which is basically weighted sum of\nentropies of each branch after splitting using the predictor Here we\nhave   \\begin{aligned}\nPredictor \\in \\{Weather, Traffic\\}\n,\\hspace{10pt}Taget \\in \\{Accident\\hspace{3pt}rate\\}\\end{aligned}  \\begin{aligned}\nPredictor \\in \\{Weather, Traffic\\}\n,\\hspace{10pt}Taget \\in \\{Accident\\hspace{3pt}rate\\}\\end{aligned}    \\begin{aligned}\nIG(Weather) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Weather)\\\\\nIG(Traffic) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Traffic)\\end{aligned}  \\begin{aligned}\nIG(Weather) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Weather)\\\\\nIG(Traffic) = H(Accident\\hspace{3pt}rate ) - H(Accident\\hspace{3pt}rate|Traffic)\\end{aligned}   Looking at eq. (4.1) and (4.2) we can say that the predictor which gives\nminimum conditional entropy will lead to maximum information gain. So we\njust calculate the conditional entropy and decide the predictor to do\nthe splitting in order to form decision tree.  Case 1:  Choosing  Weather Weather  as root for sunny branch the uncertainty\nwill be following:   \\begin{aligned}\n-\\left(\\frac{23}{28}\\log_2\\frac{23}{28} + \\frac{5}{28}\\log_2\\frac{5}{28}\n\\right) = 0.6769\\end{aligned}  \\begin{aligned}\n-\\left(\\frac{23}{28}\\log_2\\frac{23}{28} + \\frac{5}{28}\\log_2\\frac{5}{28}\n\\right) = 0.6769\\end{aligned}   for rainy branch the uncertainty will be following:   \\begin{aligned}\n-\\left(\\frac{50}{72}\\log_2\\frac{50}{72} + \\frac{22}{72}\\log_2\\frac{22}{72}\n\\right) = 0.8880\\end{aligned}  \\begin{aligned}\n-\\left(\\frac{50}{72}\\log_2\\frac{50}{72} + \\frac{22}{72}\\log_2\\frac{22}{72}\n\\right) = 0.8880\\end{aligned}   the condition entropy would be the weighted average over the branches:   \\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{28}{100}*0.6769 + \\frac{72}{100}*0.8880 =  0.8289\\end{aligned}  \\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{28}{100}*0.6769 + \\frac{72}{100}*0.8880 =  0.8289\\end{aligned}   Case 2:  Choosing  Traffic Traffic  as root for heavy branch the uncertainty\nwill be following:   \\begin{aligned}\n-\\left(\\frac{73}{73}\\log_2\\frac{73}{73} + \\frac{0}{73}\\log_2\\frac{0}{73}\n\\right) = 0\\end{aligned}  \\begin{aligned}\n-\\left(\\frac{73}{73}\\log_2\\frac{73}{73} + \\frac{0}{73}\\log_2\\frac{0}{73}\n\\right) = 0\\end{aligned}   for light branch the uncertainty will be following:   \\begin{aligned}\n-\\left(\\frac{0}{27}\\log_2\\frac{0}{27} + \\frac{27}{27}\\log_2\\frac{27}{27}\n\\right) = 0\\end{aligned}  \\begin{aligned}\n-\\left(\\frac{0}{27}\\log_2\\frac{0}{27} + \\frac{27}{27}\\log_2\\frac{27}{27}\n\\right) = 0\\end{aligned}   the condition entropy would be the weighted average over the branches:   \\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{73}{100}*0 + \\frac{27}{100}*0 =  0\\end{aligned}  \\begin{aligned}\nH(Accident\\hspace{3pt}rate | Weather) = \\frac{73}{100}*0 + \\frac{27}{100}*0 =  0\\end{aligned}   So we choose the  Traffic Traffic  predictor as the root of decision tree\nbecause it will has the maximum information gain.",
            "title": "Building a decision tree"
        },
        {
            "location": "/solution_hw_1/#relationship-between-two-decision-trees",
            "text": "T1:  Given the data, the decision tree has been built on some\nparameter  \\theta \\theta .  T2:  The data has been normalized by subtracting\nthe mean and divided by variance. The tree has been built on this new\nnormalized data.",
            "title": "Relationship between two decision trees"
        },
        {
            "location": "/solution_hw_1/#comparison-of-gini-index-and-cross-entropy",
            "text": "We are given:   \\begin{aligned}\nGI = \\sum_{k=1}^{K} p_k(1-p_k) \\end{aligned}  \\begin{aligned}\nGI = \\sum_{k=1}^{K} p_k(1-p_k) \\end{aligned}    \\begin{aligned}\nCE = - \\sum_{k=1}^{K} p_k \\log p_k \\end{aligned}  \\begin{aligned}\nCE = - \\sum_{k=1}^{K} p_k \\log p_k \\end{aligned}    \\begin{aligned}\nGI - CE = \\sum_{k=1}^{K}p_k(1-p_k + \\log(p_k)) \\\\\n= \\sum_{k = 1}^{K} p_k(q_k + \\log(1-q_k))\\\\\n=\\sum_{k=1}^{K} p_k\\left(q_k + \\left( -q_k - \\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . . \n\\right)   \n\\right)\\\\\n= \\sum_{k=1}^{K} p_k\\left(-\\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . .\n\\right)<=0 \\\\\n\\hspace{20pt} \\\\\n\\text{becasue }p_k, & q_k \\text{ are both non-negative}\\end{aligned}  \\begin{aligned}\nGI - CE = \\sum_{k=1}^{K}p_k(1-p_k + \\log(p_k)) \\\\\n= \\sum_{k = 1}^{K} p_k(q_k + \\log(1-q_k))\\\\\n=\\sum_{k=1}^{K} p_k\\left(q_k + \\left( -q_k - \\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . . \n\\right)   \n\\right)\\\\\n= \\sum_{k=1}^{K} p_k\\left(-\\frac{q_k^2}{2} - \\frac{q_k^3}{3} . . .\n\\right)<=0 \\\\\n\\hspace{20pt} \\\\\n\\text{becasue }p_k, & q_k \\text{ are both non-negative}\\end{aligned}",
            "title": "Comparison of Gini index and Cross entropy"
        },
        {
            "location": "/solution_hw_1/#programming",
            "text": "",
            "title": "Programming"
        },
        {
            "location": "/solution_hw_1/#54-performace-comparision",
            "text": "In case of Naive bayes real valued feature has been used. I am changing\nthe code now, so I can not attach the new values, since it was informed\njust one day before the assignment submission. I will try my best to\nmodify the code and submit the electronic version compatible with binary\nfeature support. But I believe the accuracies will remain the same.\nPlease take this into consideration. The tables below contain the\nperformance of different methods.       K        Train accu.   Valid accu.   Test accu.  [0.5ex] 1     77.7895       75.5784      79.4344\n        3          83.1579       80.4627      86.3753\n        5          86.6316       83.2905      90.7455\n        7          88.4211       84.0617      89.2031\n        9          88.6316       86.8895      89.4602\n       11          89.0526       86.3753      87.9177\n       13         188.4211       85.6041      87.9177\n       15          87.0526       82.7763      86.3753\n       17          85.8947       82.5193      86.1183\n       19          85.2632       82.2622      85.3470\n       21          85.3684       80.9769      84.8329\n       23          84.5263       82.5193      84.3188\n     [1ex]                                   : Performance at kNN at different values of k   table:nonlin  table:nonlin     MinLeaf     Train accu.   Valid accu.   Test accu.  [0.5ex] 1     96.7368       93.3883      94.7636\n        2          96.7368       93.3883      94.7636\n        3          96.5263       93.9409      94.7636\n        4          96.5263       93.9409      94.7636\n        5          96.3158       94.1839      95.0642\n        6          96.2105       94.6859      94.8224\n        7          96.0000       94.9121      94.8797\n        8          95.8947       95.1871      95.3046\n        9          95.2632       94.6185      94.2199\n       10          94.7368       93.8334      94.2786\n     [1ex]                                   : Decision Tree with different MinLeaf (Gini Index)   table:nonlin  table:nonlin     MinLeaf     Train accu.   Valid accu.   Test accu.  [0.5ex] 1     97.0526       93.3505      94.2163\n        2          97.0526       93.3505      94.2163\n        3          96.8421       93.9032      94.2163\n        4          96.8421       93.9032      94.2163\n        5          96.6316       94.1462      94.5168\n        6          96.5263       94.6482      94.2750\n        7          96.3158       94.8744      94.3323\n        8          95.8947       95.1871      95.3046\n        9          95.2632       94.6185      94.2199\n       10          94.7368       93.8334      94.2786\n     [1ex]                                   : Decision Tree with different MinLeaf (Cross Entropy)   table:nonlin  table:nonlin          Method           Train accu.   Valid accu.   Test accu.  [0.5ex] Naive Bayes      87.05         83.80        83.80\n       Logistic reg           83.89         81.49        85.35\n          [1ex]                                        : Performance of Naive Bayes and Logistic Reg.   table:nonlin  table:nonlin",
            "title": "5.4 Performace comparision"
        },
        {
            "location": "/solution_hw_1/#55-decision-boundary",
            "text": "As we can see in the figure when the value of K increases, the decision\nboundary smoothen out. As we can see in case of K = 20, very less red\ndata points lying in the blue region and just one chunk of blue point\nlying on left bottom of the figure.",
            "title": "5.5 Decision Boundary"
        },
        {
            "location": "/solution_hw_2/",
            "text": "Linear Regression\n\n\nRegression with heterogeneous noise\n\n\n1.1.a Log-likelihood function of independent but not identically distributed data\n\n\nHere we are given the following:\n\n\n\n\n\\begin{aligned}\ny = \\textbf{x}^T\\boldsymbol{\\beta} + \\varepsilon\\end{aligned}\n\n\n\\begin{aligned}\ny = \\textbf{x}^T\\boldsymbol{\\beta} + \\varepsilon\\end{aligned}\n\n\n\n\nAnd each data point has different variance.\n\n\n\n\n\\begin{aligned}\n\\varepsilon_n \\sim N(0,\\sigma_n^2)\\end{aligned}\n\n\n\\begin{aligned}\n\\varepsilon_n \\sim N(0,\\sigma_n^2)\\end{aligned}\n\n\n\n\nSo here we say the following\n\n\n\n\n\\begin{aligned}\ny_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} \\sim N(0,\\sigma_i^2)\\end{aligned}\n\n\n\\begin{aligned}\ny_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} \\sim N(0,\\sigma_i^2)\\end{aligned}\n\n\n\n\nWriting the log likelihood for the data points\n\n\n\n\n\\begin{split}\n\\ell (\\boldsymbol{\\beta}) & = \\log (P(Y| X,\\boldsymbol{\\beta}))\\\\\n              & = \\log\\left(\\prod_{i = 1 }^{N} \\frac{1}{\\sqrt{2\\pi} \\sigma_i} \\exp\\left( \\frac{- (y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\n              \\right)\\\\\n              & = \\sum_{i = 1}^{N}\\left(\\log\\left(\\frac{1}{\\sqrt{2\\pi} \\sigma_i}\n              \\right) - \\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\\\\\n              & = -\\frac{N}{2}\\log 2\\pi - \\sum_{i = 1}^{N}\\log(\\sigma_i) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n\\end{split}\n\n\n\\begin{split}\n\\ell (\\boldsymbol{\\beta}) & = \\log (P(Y| X,\\boldsymbol{\\beta}))\\\\\n              & = \\log\\left(\\prod_{i = 1 }^{N} \\frac{1}{\\sqrt{2\\pi} \\sigma_i} \\exp\\left( \\frac{- (y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\n              \\right)\\\\\n              & = \\sum_{i = 1}^{N}\\left(\\log\\left(\\frac{1}{\\sqrt{2\\pi} \\sigma_i}\n              \\right) - \\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\\\\\n              & = -\\frac{N}{2}\\log 2\\pi - \\sum_{i = 1}^{N}\\log(\\sigma_i) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n\\end{split}\n\n\n\n\n1.1.b Maximum likelihood derivation for \n\\boldsymbol{\\beta}\n\\boldsymbol{\\beta}\n\n\nDifferentiating above equation w.r.t. \n\\beta_j\n\\beta_j\n we get the following:\n\n\n\n\n\\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial \\beta_j} & = -0 - 0 - \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ij})}{2\\sigma_i^2}\n\\end{split}\n\n\n\\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial \\beta_j} & = -0 - 0 - \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ij})}{2\\sigma_i^2}\n\\end{split}\n\n\n\n\nEquating above equation to 0 we get:\n\n\n\n\n\\begin{split}\n\\sum_{i = 1}^{N} \\frac{(y_i -\\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(x_{ij})}{\\sigma_i^2} & = 0\\\\\n\\end{split}\n\n\n\\begin{split}\n\\sum_{i = 1}^{N} \\frac{(y_i -\\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(x_{ij})}{\\sigma_i^2} & = 0\\\\\n\\end{split}\n\n\n\n\nIn matrix form, above equation can be written as:\n\n\n\n\n\\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{n1}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = 0 \n\\end{split}\n\n\n\\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{n1}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = 0 \n\\end{split}\n\n\n\n\nSimilarly for other \n\\beta\n\\beta\n\u2019s we get the same format. Putting all of\nthem in one matrix we will get the following.\n\n\n\n\n\\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{N1}\\\\\nx_{12} & x_{22} &  . & .& . & x_{N2}\\\\\n. & . & . & . & . & . & . \\\\\n. & . & . & . & . & . & . \\\\\nx_{1p} & x_{22} &  . & .& . & x_{Np}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = \n\\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0 \n\\end{bmatrix}\n\\end{split}\n\n\n\\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{N1}\\\\\nx_{12} & x_{22} &  . & .& . & x_{N2}\\\\\n. & . & . & . & . & . & . \\\\\n. & . & . & . & . & . & . \\\\\nx_{1p} & x_{22} &  . & .& . & x_{Np}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = \n\\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0 \n\\end{bmatrix}\n\\end{split}\n\n\n\n\nDenoting the left \nP\nP\nx\nN\nN\n matrix as \nA\nA\n. Putting Y term on RHS we\nget the following:\n\n\n\n\n\\begin{split}\nA \\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = A \\begin{bmatrix}\n\\frac{y_1}{\\sigma_1^2}\\\\\n\\frac{y_2}{\\sigma_2^2}\\\\\n.\\\\\n.\\\\\n\\frac{y_N}{\\sigma_N^2}\n\\end{bmatrix}\n\\end{split}\n\n\n\\begin{split}\nA \\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = A \\begin{bmatrix}\n\\frac{y_1}{\\sigma_1^2}\\\\\n\\frac{y_2}{\\sigma_2^2}\\\\\n.\\\\\n.\\\\\n\\frac{y_N}{\\sigma_N^2}\n\\end{bmatrix}\n\\end{split}\n\n\n\n\nAbove equation can again be decomposed into simpler form by expanding\nevery row entry of matrix column matrix in L.H.S.\n\n\n\n\n\\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{x_{11}}{\\sigma_1^2} & \\frac{x_{12}}{\\sigma_1^2} & . & . & \\frac{x_{1p}}{\\sigma_1^2}\\\\ \n\\frac{x_{21}}{\\sigma_2^2} & \\frac{x_{22}}{\\sigma_2^2} & . & . & \\frac{x_{2p}}{\\sigma_2^2}\\\\ \n. & . & . & . & . \\\\\n\\frac{x_{N1}}{\\sigma_N^2} & \\frac{x_{N2}}{\\sigma_N^2} & . & . & \\frac{x_{Np}}{\\sigma_N^2}\\\\   \n\\end{bmatrix} \\begin{bmatrix}\n\\beta_1\\\\\n\\beta_2\\\\\n.\\\\\n.\\\\\n\\beta_p \n\\end{bmatrix}\n\n\n\\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{x_{11}}{\\sigma_1^2} & \\frac{x_{12}}{\\sigma_1^2} & . & . & \\frac{x_{1p}}{\\sigma_1^2}\\\\ \n\\frac{x_{21}}{\\sigma_2^2} & \\frac{x_{22}}{\\sigma_2^2} & . & . & \\frac{x_{2p}}{\\sigma_2^2}\\\\ \n. & . & . & . & . \\\\\n\\frac{x_{N1}}{\\sigma_N^2} & \\frac{x_{N2}}{\\sigma_N^2} & . & . & \\frac{x_{Np}}{\\sigma_N^2}\\\\   \n\\end{bmatrix} \\begin{bmatrix}\n\\beta_1\\\\\n\\beta_2\\\\\n.\\\\\n.\\\\\n\\beta_p \n\\end{bmatrix}\n\n\n\n\nAssuming \nB\nB\n to be the \nN\nN\nx\nP\nP\n of R.H.S of above equation. Now we\ncan write eq. (1.3) as\n\n\n\n\n\\boldsymbol{AB}\\boldsymbol{\\beta} =\\boldsymbol{AY_{\\sigma}}\n\n\n\\boldsymbol{AB}\\boldsymbol{\\beta} =\\boldsymbol{AY_{\\sigma}}\n\n\n\n\n\\boldsymbol{AB}\n\\boldsymbol{AB}\n will be a \nP\nP\nx\nP\nP\n matrix, and if it is invertible\nthen we can write the solution for \n\\boldsymbol{\\beta}\n\\boldsymbol{\\beta}\n as following:\n\n\n\n\n\\begin{split}\n\\boldsymbol{\\beta} = \\boldsymbol{(AB)^{-1}}\\boldsymbol{AY_{\\sigma}}\n\\end{split}\n\n\n\\begin{split}\n\\boldsymbol{\\beta} = \\boldsymbol{(AB)^{-1}}\\boldsymbol{AY_{\\sigma}}\n\\end{split}\n\n\n\n\nSmooth co-efficients\n\n\n1.2.a\n\n\nTo apply natural ordering we have to add extra regularization term in\nthe residual square of sum term. Without natural ordering\n\n\\boldsymbol{RSS(\\beta)}\n\\boldsymbol{RSS(\\beta)}\n looks like following\n\n\n\n\n\\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2\n\\end{split}\n\n\n\\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2\n\\end{split}\n\n\n\n\nAdding additional constrain of natural ordering\n\n\n\n\n\\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2 + \\frac{1}{2}\\gamma\\sum_{i=1}^{p-1} \\left( \\beta_i - \\beta_{i+1}\n\\right)^2\n\\end{split}\n\n\n\\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2 + \\frac{1}{2}\\gamma\\sum_{i=1}^{p-1} \\left( \\beta_i - \\beta_{i+1}\n\\right)^2\n\\end{split}\n\n\n\n\n1.2.b\n\n\nTaking the first derivative and equating it to zero.Note: The derivative\nw.r.t \n\\beta_1\n\\beta_1\n and \n\\beta_p\n\\beta_p\n will be different from the rest \n\\beta's\n\\beta's\n\n\n\n\n\\begin{split}\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_1} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i1})}{2\\sigma^2} + \\lambda \\beta_1 + \\gamma\\left(\\beta_1 - \\beta_2\n\\right) = 0\\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_2} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i2})}{2\\sigma^2} + \\lambda \\beta_2 - \\gamma\\left(\\beta_1 + \\beta_3\n\\right) = 0 \\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_3} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i3})}{2\\sigma^2} + \\lambda \\beta_3 - \\gamma\\left(\\beta_2 + \\beta_4\n\\right) = 0 \\\\\n... \\\\\n...\\\\ \n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_p} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ip})}{2\\sigma^2} + \\lambda \\beta_p + \\gamma\\left(\\beta_p + \\beta_{p-1}\n\\right) = 0 \n\\end{split}\n\n\n\\begin{split}\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_1} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i1})}{2\\sigma^2} + \\lambda \\beta_1 + \\gamma\\left(\\beta_1 - \\beta_2\n\\right) = 0\\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_2} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i2})}{2\\sigma^2} + \\lambda \\beta_2 - \\gamma\\left(\\beta_1 + \\beta_3\n\\right) = 0 \\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_3} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i3})}{2\\sigma^2} + \\lambda \\beta_3 - \\gamma\\left(\\beta_2 + \\beta_4\n\\right) = 0 \\\\\n... \\\\\n...\\\\ \n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_p} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ip})}{2\\sigma^2} + \\lambda \\beta_p + \\gamma\\left(\\beta_p + \\beta_{p-1}\n\\right) = 0 \n\\end{split}\n\n\n\n\nWriting above system of linear equation in matrix form.\n\n\n\n\n\\begin{split}\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma\\begin{bmatrix}\n\\beta_2 - \\beta_1\\\\\n\\beta_1 + \\beta_3\\\\\n.\\\\\n.\\\\\n\\beta_{p-1} - \\beta_p\n\\end{bmatrix} &  = \\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0\n\\end{bmatrix}\\\\\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma \\begin{bmatrix}\n-1 & 1 & 0 & 0 & . & . & 0 \\\\\n1 & 0 & 1 & 0 & . & . & 0 \\\\\n0 & 1 & 0 & 1 & . & . & 0 \\\\\n. & . & . & . & . & .& . \\\\\n. & . & . & . & . & .& . \\\\\n0 & 0 & 0 & 0 & . & 1 & -1 \\\\\n\\end{bmatrix}\\boldsymbol{\\beta} = \\boldsymbol{0}\n\\end{split}\n\n\n\\begin{split}\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma\\begin{bmatrix}\n\\beta_2 - \\beta_1\\\\\n\\beta_1 + \\beta_3\\\\\n.\\\\\n.\\\\\n\\beta_{p-1} - \\beta_p\n\\end{bmatrix} &  = \\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0\n\\end{bmatrix}\\\\\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma \\begin{bmatrix}\n-1 & 1 & 0 & 0 & . & . & 0 \\\\\n1 & 0 & 1 & 0 & . & . & 0 \\\\\n0 & 1 & 0 & 1 & . & . & 0 \\\\\n. & . & . & . & . & .& . \\\\\n. & . & . & . & . & .& . \\\\\n0 & 0 & 0 & 0 & . & 1 & -1 \\\\\n\\end{bmatrix}\\boldsymbol{\\beta} = \\boldsymbol{0}\n\\end{split}\n\n\n\n\nSimplifying above equation will lead to the following:\n\n\n\n\n\\begin{split}\nAA^T\\boldsymbol{\\beta} + \\lambda\\boldsymbol{\\beta} - \\gamma K \\boldsymbol{\\beta} & = AY\\\\\n\\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)\\boldsymbol{\\beta} & = AY \\\\\n\\implies \\boldsymbol{\\beta} & = \\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)^ {-1} AY \n\\end{split}\n\n\n\\begin{split}\nAA^T\\boldsymbol{\\beta} + \\lambda\\boldsymbol{\\beta} - \\gamma K \\boldsymbol{\\beta} & = AY\\\\\n\\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)\\boldsymbol{\\beta} & = AY \\\\\n\\implies \\boldsymbol{\\beta} & = \\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)^ {-1} AY \n\\end{split}\n\n\n\n\nLinearly constrained linear regression\n\n\nHere we are given the following:\n\n\n\n\ny = \\boldsymbol{x^T\\beta} + \\varepsilon\n\n\ny = \\boldsymbol{x^T\\beta} + \\varepsilon\n\n\n\n\nand the parameters have additional linear constrain as:\n\n\n\n\nA\\boldsymbol{\\beta} = \\boldsymbol{b}\n\n\nA\\boldsymbol{\\beta} = \\boldsymbol{b}\n\n\n\n\nThe above equation has non-empty solution.Writing the log likelihood\nequation by referring (1.1) with new symbol of\n\n\\boldsymbol{\\beta} =\\boldsymbol{\\beta}^\\star\n\\boldsymbol{\\beta} =\\boldsymbol{\\beta}^\\star\n\n\n\n\n\\begin{split}\n \\ell (\\boldsymbol{\\beta}) & =  -\\frac{N}{2}\\log 2\\pi - N\\log(\\sigma) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & =  -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^2}\n\\end{split}\n\n\n\\begin{split}\n \\ell (\\boldsymbol{\\beta}) & =  -\\frac{N}{2}\\log 2\\pi - N\\log(\\sigma) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & =  -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^2}\n\\end{split}\n\n\n\n\nWhere\n\n\n\n\n\\begin{split}\nY = \\begin{bmatrix}\ny_1 & y_2 & . &. &. & y_N\n\\end{bmatrix}^T\n\\boldsymbol{X} = \\begin{bmatrix}\nx_{11} & x_{12} & x_{13} & . & . & . & x_{1P}\\\\\nx_{21} & x_{22} & x_{23} & . & . & . & x_{2P}\\\\\n. & . & . & . & . & . & .\\\\\n. & . & . & . & . & . & .\\\\\nx_{N1} & x_{N2} & x_{N3} & . & . & . & x_{NP}\n\\end{bmatrix}\n\\end{split}\n\n\n\\begin{split}\nY = \\begin{bmatrix}\ny_1 & y_2 & . &. &. & y_N\n\\end{bmatrix}^T\n\\boldsymbol{X} = \\begin{bmatrix}\nx_{11} & x_{12} & x_{13} & . & . & . & x_{1P}\\\\\nx_{21} & x_{22} & x_{23} & . & . & . & x_{2P}\\\\\n. & . & . & . & . & . & .\\\\\n. & . & . & . & . & . & .\\\\\nx_{N1} & x_{N2} & x_{N3} & . & . & . & x_{NP}\n\\end{bmatrix}\n\\end{split}\n\n\n\n\nThe idea here is to use Lagrangian multiplier in order to address the\nlinear constrain. Here we can see that the variance does not have any\nconstraint. We can get estimate of variance, and then plug that into\nlikelihood, thereafter we can apply Lagrangian multiplier.First getting\nthe estimate for variance:\n\n\n\n\n\\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial\\sigma^2} & = -\\frac{N}{2\\sigma^2} -  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2}*\\left(\\frac{-1}{\\sigma^4}\n\\right)\\\\\n& = -\\frac{N}{2\\sigma^2} + \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^4}\n\\end{split}\n\n\n\\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial\\sigma^2} & = -\\frac{N}{2\\sigma^2} -  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2}*\\left(\\frac{-1}{\\sigma^4}\n\\right)\\\\\n& = -\\frac{N}{2\\sigma^2} + \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^4}\n\\end{split}\n\n\n\n\nequating above equation to zero will give us the estimate of \n\\sigma^2\n\\sigma^2\n\nas a function of constrained \n\\boldsymbol{\\beta^\\star}\n\\boldsymbol{\\beta^\\star}\n\n\n\n\n\\sigma ^2 =  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\n\n\n\\sigma ^2 =  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\n\n\n\n\nPutting the value of \n\\sigma^2\n\\sigma^2\n in eq. (1.4)\n\n\n\n\n\\begin{split}\n \\ell (\\boldsymbol{\\beta}) & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2 \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}} \\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{N}{2}\n\\end{split}\n\n\n\\begin{split}\n \\ell (\\boldsymbol{\\beta}) & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2 \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}} \\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{N}{2}\n\\end{split}\n\n\n\n\nNow we have to maximize with the linear constrain on parameter. In other\nterms we just have to minimize the term inside log in above equation. We\nhave to do the following. Minimize\n\n\n\n\n\\begin{split}\n&(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})\\\\\n& A\\boldsymbol{\\beta^\\star} = \\boldsymbol{b}\n\\end{split}\n\n\n\\begin{split}\n&(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})\\\\\n& A\\boldsymbol{\\beta^\\star} = \\boldsymbol{b}\n\\end{split}\n\n\n\n\nWriting the Lagrangian multiplier for above problem\n\n\n\n\n\\begin{split}\nJ & = (Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star}) + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - Y^T\\boldsymbol{X\\beta^\\star} - \\boldsymbol{\\beta^{\\star T} X^T}Y + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - 2Y^T\\boldsymbol{X\\beta^\\star}  + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} +\\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\vspace{5pt}\\\\\n  & \\hspace{20pt}\\text{because both terms are essentially the same}\n\\end{split}\n\n\n\\begin{split}\nJ & = (Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star}) + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - Y^T\\boldsymbol{X\\beta^\\star} - \\boldsymbol{\\beta^{\\star T} X^T}Y + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - 2Y^T\\boldsymbol{X\\beta^\\star}  + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} +\\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\vspace{5pt}\\\\\n  & \\hspace{20pt}\\text{because both terms are essentially the same}\n\\end{split}\n\n\n\n\nDifferentiating w.r.t to \n\\boldsymbol{\\beta^\\star}\n\\boldsymbol{\\beta^\\star}\n\n\n\n\n\\begin{split}\n\\frac{\\partial J}{\\partial \\beta^\\star}  & = -2Y^T\\boldsymbol{X} + 2\\boldsymbol{\\beta^{\\star T}X^TX} + \\lambda A  = 0 \\\\\n\\end{split}\n\n\n\\begin{split}\n\\frac{\\partial J}{\\partial \\beta^\\star}  & = -2Y^T\\boldsymbol{X} + 2\\boldsymbol{\\beta^{\\star T}X^TX} + \\lambda A  = 0 \\\\\n\\end{split}\n\n\n\n\nTo make it easier for calculation, taking transpose on both side.\n\n\n\n\n\\begin{split}\n-2\\boldsymbol{X^T}Y + 2\\boldsymbol{X^TX\\beta^\\star} + \\lambda A^T & = 0 \\\\\n\\lambda A^T & = 2\\left(\\boldsymbol{X^T}Y - \\boldsymbol{X^TX\\beta^\\star} \\right)\n\\end{split}\n\n\n\\begin{split}\n-2\\boldsymbol{X^T}Y + 2\\boldsymbol{X^TX\\beta^\\star} + \\lambda A^T & = 0 \\\\\n\\lambda A^T & = 2\\left(\\boldsymbol{X^T}Y - \\boldsymbol{X^TX\\beta^\\star} \\right)\n\\end{split}\n\n\n\n\nMultiplying with \nA\\left(\\boldsymbol{X^TX}\\right)^{-1}\nA\\left(\\boldsymbol{X^TX}\\right)^{-1}\n\n\n\n\n\\begin{split}\n\\lambda A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T & = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - A\\boldsymbol{\\beta^\\star}\n\\right)\\\\\n& = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\lambda & = 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right) \n\\end{split}\n\n\n\\begin{split}\n\\lambda A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T & = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - A\\boldsymbol{\\beta^\\star}\n\\right)\\\\\n& = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\lambda & = 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right) \n\\end{split}\n\n\n\n\nsimplifying first term of eq. (1.6) for \n\\boldsymbol{\\beta^\\star}\n\\boldsymbol{\\beta^\\star}\n\n\n\n\n\\begin{split}\n2\\boldsymbol{X^TX\\beta^\\star} & = 2\\boldsymbol{X^T}Y - \\lambda A^T\\\\\n& = 2\\boldsymbol{X^T}Y  - 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\boldsymbol{\\beta^\\star} & = \\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\left(\\boldsymbol{X^TX}\\right)^{-1} \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\n\\end{split}\n\n\n\\begin{split}\n2\\boldsymbol{X^TX\\beta^\\star} & = 2\\boldsymbol{X^T}Y - \\lambda A^T\\\\\n& = 2\\boldsymbol{X^T}Y  - 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\boldsymbol{\\beta^\\star} & = \\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\left(\\boldsymbol{X^TX}\\right)^{-1} \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\n\\end{split}\n\n\n\n\nOnline learning\n\n\nHere the objective function is to minimize the L2 norm of the difference\nof the update. For perceptron to classify the current input following\ncondition must satisfy:\n\n\n\n\n\\begin{split}\ny_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n} > 0\n\\end{split}\n\n\n\\begin{split}\ny_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n} > 0\n\\end{split}\n\n\n\n\nwe have to minimize the following with above mentioned constraint.\n\n\n\n\n\\begin{split}\n1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2\n\\end{split}\n\n\n\\begin{split}\n1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2\n\\end{split}\n\n\n\n\nMinimizing L2 sqaured norm is as good as minimizing L2 norm. Writing\nexpression in Lagrangian format\n\n\n\n\n\\begin{split}\n\\boldsymbol{L} = 1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2 + \\lambda * (y_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n}  )\n\\end{split}\n\n\n\\begin{split}\n\\boldsymbol{L} = 1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2 + \\lambda * (y_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n}  )\n\\end{split}\n\n\n\n\ndifferentiating w.r.t. to \n\\boldsymbol{w_{i+1}}\n\\boldsymbol{w_{i+1}}\n and equating it to\nzero.\n\n\n\n\n\\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\boldsymbol{w_{i+1}}} & = 1/2 * \\left(2*\\boldsymbol{w_{i+1}} - 2*\\boldsymbol{w_i} + *\\lambda*y_n * \\boldsymbol{x_n}\n\\right) = 0 \\\\\n\\boldsymbol{w_{i+1}} & = \\boldsymbol{w_i} -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}}{2}\n\\end{split}\n\n\n\\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\boldsymbol{w_{i+1}}} & = 1/2 * \\left(2*\\boldsymbol{w_{i+1}} - 2*\\boldsymbol{w_i} + *\\lambda*y_n * \\boldsymbol{x_n}\n\\right) = 0 \\\\\n\\boldsymbol{w_{i+1}} & = \\boldsymbol{w_i} -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}}{2}\n\\end{split}\n\n\n\n\nDifferential \nL\nL\n w.r.t \n\\lambda\n\\lambda\n leads to the following\n\n\n\n\n\\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\lambda} & = y_n\\boldsymbol{w_{i+1}}^T \\boldsymbol{x_n}  = 0 \\\\\n\\implies y_n\\left( \\boldsymbol{w_i}^T -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}^T}{2}\n\\right) * \\boldsymbol{x_n} & = 0 \\\\\n\\implies \\lambda = \\frac{2*\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\end{split}\n\n\n\\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\lambda} & = y_n\\boldsymbol{w_{i+1}}^T \\boldsymbol{x_n}  = 0 \\\\\n\\implies y_n\\left( \\boldsymbol{w_i}^T -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}^T}{2}\n\\right) * \\boldsymbol{x_n} & = 0 \\\\\n\\implies \\lambda = \\frac{2*\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\end{split}\n\n\n\n\n\n\n\\begin{split}\n\\boldsymbol{w_{i+1}} = \\boldsymbol{w_i} - \\left(\\frac{\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\right)* y_n*\\boldsymbol{x_n}\n\\end{split}\n\n\n\\begin{split}\n\\boldsymbol{w_{i+1}} = \\boldsymbol{w_i} - \\left(\\frac{\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\right)* y_n*\\boldsymbol{x_n}\n\\end{split}\n\n\n\n\nKernels\n\n\n3.a\n\n\n\n\n\\begin{aligned}\nK_3 & =  a_1K_1 + a_2K_2\\\\\n&  a_1\\geq 0 , a_2 \\geq 0\\end{aligned}\n\n\n\\begin{aligned}\nK_3 & =  a_1K_1 + a_2K_2\\\\\n&  a_1\\geq 0 , a_2 \\geq 0\\end{aligned}\n\n\n\n\nSince \nK_1\nK_1\n and \nK_2\nK_2\n are positive semidefinite matrix. So for any\nvector\nX\nX\n, we h ave the following inequality\n\n\n\n\n\\begin{split}\nX^TK_1X \\geq 0,\\space\nX^TK_2X \\geq 0 \n\\end{split}\n\n\n\\begin{split}\nX^TK_1X \\geq 0,\\space\nX^TK_2X \\geq 0 \n\\end{split}\n\n\n\n\nTaking any vector X and evaluating \nX^TK_3X\nX^TK_3X\n\n\n\n\n\\begin{split}\nX^TK_3X & = X^T (a_1K_1 + a_2K_2)X\\\\\n& = X^Ta_1K_1X + X^Ta_aK_2X\\\\\n& = a_1X^TK_1X + a_2X^TK_2X \\\\\n&\\geq 0 \n\\end{split}\n\n\n\\begin{split}\nX^TK_3X & = X^T (a_1K_1 + a_2K_2)X\\\\\n& = X^Ta_1K_1X + X^Ta_aK_2X\\\\\n& = a_1X^TK_1X + a_2X^TK_2X \\\\\n&\\geq 0 \n\\end{split}\n\n\n\n\n3.b\n\n\nK_4\nK_4\n has been defined by kernel function \nk_4(x_1,x_2) = f(x_1)f(x_2)\nk_4(x_1,x_2) = f(x_1)f(x_2)\n\n, the matrix representation will look like following:\n\n\n\n\n\\begin{split}\nK_4 & = \\begin{bmatrix}\nk_4(x_1,x_1) & k_4(x_1,x_2) &  . & .& . & k_4(x_1, x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & . \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)f(x_1) & f(x_1)f(x_2) &  . & .& . & f(x_1)f(x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)\\\\\nf(x_2)\\\\\n.  \\\\\n.  \\\\\nf(x_N)\n\\end{bmatrix} \\begin{bmatrix}\nf(x_1) & f(x_2) & . & . & f(x_N)\n\\end{bmatrix}\\\\\n& = \\boldsymbol{FF^T}\n\\end{split}\n\n\n\\begin{split}\nK_4 & = \\begin{bmatrix}\nk_4(x_1,x_1) & k_4(x_1,x_2) &  . & .& . & k_4(x_1, x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & . \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)f(x_1) & f(x_1)f(x_2) &  . & .& . & f(x_1)f(x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)\\\\\nf(x_2)\\\\\n.  \\\\\n.  \\\\\nf(x_N)\n\\end{bmatrix} \\begin{bmatrix}\nf(x_1) & f(x_2) & . & . & f(x_N)\n\\end{bmatrix}\\\\\n& = \\boldsymbol{FF^T}\n\\end{split}\n\n\n\n\nNow taking any vector \nX\nX\n and evaluating \nX^TK_4X\nX^TK_4X\n\n\n\n\n\\begin{split}\nX^TK_4X & = X^T\\boldsymbol{FF^T}X \\\\\n& = (\\boldsymbol{F^T}X)^T \\boldsymbol{F^T}X\\\\\n& = ||\\boldsymbol{F^T}X||^2\\\\\n& \\geq 0\n\\end{split}\n\n\n\\begin{split}\nX^TK_4X & = X^T\\boldsymbol{FF^T}X \\\\\n& = (\\boldsymbol{F^T}X)^T \\boldsymbol{F^T}X\\\\\n& = ||\\boldsymbol{F^T}X||^2\\\\\n& \\geq 0\n\\end{split}\n\n\n\n\nTherefore \nK_4\nK_4\n is also a positive semidefinite matrix.\n\n\n3.c\n\n\nK_5\nK_5\n has been defined by kernel function\n\nk_5(x_1,x_2) = k_1(x_1, x_2)k_2(x_1,x_2)\nk_5(x_1,x_2) = k_1(x_1, x_2)k_2(x_1,x_2)\n , the matrix representation\nwill look like following:\n\n\n\n\n\\begin{split}\nK_5 & = \\begin{bmatrix}\nk_5(x_1,x_1) & k_5(x_1,x_2) &  . & .& . & k_5(x_1, x_N)\\\\\nk_5(x_2,x_1) & k_5(x_2,x_2) &  . & .& . & k_5(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_5(x_N,x_1) & k_5(x_N,x_2) &  . & .& . & k_5(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nk_1(x_1,x_1)k_2(x_1,x_1) & k_1(x_1,x_2)k_2(x_1,x_2) &  . & .& . & k_1(x_1,x_N)k_2(x_1,x_N)\\\\\nk_1(x_2,x_1)k_2(x_2,x_1) & k_1(x_2,x_2)k_2(x_2,x_2) &  . & .& . & k_1(x_2, x_N)k_2(x_2,x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_1(x_N,x_1)k_2(x_N,x_1) & k_1(x_N,x_2)k_2(x_N,x_2) &  . & .& . & k_1(x_N, x_N)k_2(x_N,x_N)\n\\end{bmatrix}\n\\end{split}\n\n\n\\begin{split}\nK_5 & = \\begin{bmatrix}\nk_5(x_1,x_1) & k_5(x_1,x_2) &  . & .& . & k_5(x_1, x_N)\\\\\nk_5(x_2,x_1) & k_5(x_2,x_2) &  . & .& . & k_5(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_5(x_N,x_1) & k_5(x_N,x_2) &  . & .& . & k_5(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nk_1(x_1,x_1)k_2(x_1,x_1) & k_1(x_1,x_2)k_2(x_1,x_2) &  . & .& . & k_1(x_1,x_N)k_2(x_1,x_N)\\\\\nk_1(x_2,x_1)k_2(x_2,x_1) & k_1(x_2,x_2)k_2(x_2,x_2) &  . & .& . & k_1(x_2, x_N)k_2(x_2,x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_1(x_N,x_1)k_2(x_N,x_1) & k_1(x_N,x_2)k_2(x_N,x_2) &  . & .& . & k_1(x_N, x_N)k_2(x_N,x_N)\n\\end{bmatrix}\n\\end{split}\n\n\n\n\nReferring to Wikipedia web resource about Hadamard product, Schur\nproduct theorem it can be proved that the above kernel function is PSD\n(by the help of Wick\u2019s theorem). Since \nk_1\nk_1\n and \nk_2\nk_2\n are kernel\nfunction (so the matrix will be PSD). and their entrywise multiplication\n(Hadamard product) is the above resulting matrix. So it will be a PSD.\n\n\nBias Variance Tradeoff\n\n\nProgramming\n\n\nData preparation\n\n\nFeature representation\n\n\n(1)\n\n\nTop 3 most frequent words found in spam/ham data set are as following\n\n\n\n\nenron    600\n\n    will    351\n\n   please   291  \n\n\n\n\nIn ionosphere data I have used 1 for label \u201cg\u201d and 0 for label \u201cb\u201d.\nInitialization and extreme conditions has been considered during\nimplementation.\n\n\nBatch Gradient descent\n\n\n(2)\n\n\nUpdating equation of \n\\boldsymbol{w}\n\\boldsymbol{w}\n and b. Here \n\\boldsymbol{x}\n\\boldsymbol{x}\n is\n\nN\nN\nx\nP\nP\n vector where \nN\nN\n is number of data points, and \nP\nP\n is feature\ndimension. \ny\ny\n is \nN\nN\nx\n1\n1\n vector. \n\\boldsymbol{w}\n\\boldsymbol{w}\n is \nP\nP\nx\n1\n1\n vector and\n\n\\boldsymbol{b}_t\n\\boldsymbol{b}_t\n is a \nN\nN\nx\n1\n1\n vector with each row having same values\nwhich is equal to bias. Without regularization:\n\n\n\n\n\\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}\n\n\n\\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}\n\n\n\n\nWith Regularization:\n\n\n\n\n\\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n+ 2*\\lambda*\\boldsymbol{w}_t\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}\n\n\n\\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n+ 2*\\lambda*\\boldsymbol{w}_t\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}\n\n\n\n\n(3)a\n\n\n\n\nfig:example\n\n\nfig:example\n\n\n\n\n(3)b\n\n\nL2\nL2\n norm of \n\\boldsymbol{w}\n\\boldsymbol{w}\n after 50 iterations for each step size\n\n\\eta_i\n\\eta_i\n\n\n\n\n\n\n(4)a\n\n\n\n\nfig:example\n\n\nfig:example\n\n\n\n\n(4)b\n\n\n\n\n\n\n(4)c\n\n\n\n\nfig:example\n\n\nfig:example\n\n\n\n\n(5)\n\n\nNote: Here we add one column (with all entries = 1 ) in the beginning of\ninput data matrix and the seed intercept \nb\nb\n as row 1 in the weight\nvector to inculcate the bias. \nWithout Regularization:\n (Using the\nnotations and assumptions of (2)) Here I am using the derivation of\nHessian directly because it was already described in assignment #1.\nHere \nH_b\nH_b\n is used for second derivative w.r.t. bias.\n\n\n\n\n\\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n \\right)\n \\right) \\\\\n H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n  \\right) \\\\\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\nb_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}\n\n\n\\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n \\right)\n \\right) \\\\\n H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n  \\right) \\\\\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\nb_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}\n\n\n\n\n**With Regularization** In this case we shall add \n2*\\lambda\n2*\\lambda\n to\ndiagonal entries of the hessian matrx that we found in case of without\nregularization(because for \ni\\neq j\ni\\neq j\n the second derivative will be zero\nfor regularized term). And in the first derivative we shall have\n\n2*\\lambda*\\boldsymbol{w}\n2*\\lambda*\\boldsymbol{w}\n added to the weight vector. The bias is not\naffected by regularization.\n\n\n\n\n\\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x} + 2*\\lambda*\\boldsymbol{I}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n  \\right)\n  \\right) \\\\\n  H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n   \\right) \\\\\n \\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\n b_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}\n\n\n\\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x} + 2*\\lambda*\\boldsymbol{I}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n  \\right)\n  \\right) \\\\\n  H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n   \\right) \\\\\n \\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\n b_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}\n\n\n\n\n(6)a\n\n\n\n\nfig:example\n\n\nfig:example\n\n\n\n\n(6)b\n\n\nL2 norm of w without regularization:\n\n\n\n\n\n\n(6)c\n\n\nCross entropy of test data using newtons method (showed upto steps where\nit converges)\n\n\n\n\n\n\n(7)a\n\n\n\n\nfig:example\n\n\nfig:example\n\n\n\n\n(7)b\n\n\nL2 norm of vector \n\\boldsymbol{w}\n\\boldsymbol{w}\n\n\n\n\n\n\n(8)\n\n\nIn (3)a we see that with increase in step size overdamped situation is\nfound. Even with the regularization (in 4(a)) we see the spikes. The\nbehavior with higher values of \n\\lambda\n\\lambda\n in training and testing cross\nentropies with different step sizes. At higher values of step size and\nhigh values of lambda we expect to see the high value of CE which can be\nseen in the plots. In newton method we can see very sharp convergence\nwithin 5 steps, but we do see the trade off in time complexity w.r.t\ngradient descent method. It has not been reported but I did see giving\ngood values of weight vector newton method converges very fast",
            "title": "Homework 2"
        },
        {
            "location": "/solution_hw_2/#linear-regression",
            "text": "",
            "title": "Linear Regression"
        },
        {
            "location": "/solution_hw_2/#regression-with-heterogeneous-noise",
            "text": "",
            "title": "Regression with heterogeneous noise"
        },
        {
            "location": "/solution_hw_2/#11a-log-likelihood-function-of-independent-but-not-identically-distributed-data",
            "text": "Here we are given the following:   \\begin{aligned}\ny = \\textbf{x}^T\\boldsymbol{\\beta} + \\varepsilon\\end{aligned}  \\begin{aligned}\ny = \\textbf{x}^T\\boldsymbol{\\beta} + \\varepsilon\\end{aligned}   And each data point has different variance.   \\begin{aligned}\n\\varepsilon_n \\sim N(0,\\sigma_n^2)\\end{aligned}  \\begin{aligned}\n\\varepsilon_n \\sim N(0,\\sigma_n^2)\\end{aligned}   So here we say the following   \\begin{aligned}\ny_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} \\sim N(0,\\sigma_i^2)\\end{aligned}  \\begin{aligned}\ny_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} \\sim N(0,\\sigma_i^2)\\end{aligned}   Writing the log likelihood for the data points   \\begin{split}\n\\ell (\\boldsymbol{\\beta}) & = \\log (P(Y| X,\\boldsymbol{\\beta}))\\\\\n              & = \\log\\left(\\prod_{i = 1 }^{N} \\frac{1}{\\sqrt{2\\pi} \\sigma_i} \\exp\\left( \\frac{- (y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\n              \\right)\\\\\n              & = \\sum_{i = 1}^{N}\\left(\\log\\left(\\frac{1}{\\sqrt{2\\pi} \\sigma_i}\n              \\right) - \\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\\\\\n              & = -\\frac{N}{2}\\log 2\\pi - \\sum_{i = 1}^{N}\\log(\\sigma_i) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n\\end{split}  \\begin{split}\n\\ell (\\boldsymbol{\\beta}) & = \\log (P(Y| X,\\boldsymbol{\\beta}))\\\\\n              & = \\log\\left(\\prod_{i = 1 }^{N} \\frac{1}{\\sqrt{2\\pi} \\sigma_i} \\exp\\left( \\frac{- (y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\n              \\right)\\\\\n              & = \\sum_{i = 1}^{N}\\left(\\log\\left(\\frac{1}{\\sqrt{2\\pi} \\sigma_i}\n              \\right) - \\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n              \\right)\\\\\n              & = -\\frac{N}{2}\\log 2\\pi - \\sum_{i = 1}^{N}\\log(\\sigma_i) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta} )^2}{2\\sigma_i^2}\n\\end{split}",
            "title": "1.1.a Log-likelihood function of independent but not identically distributed data"
        },
        {
            "location": "/solution_hw_2/#11b-maximum-likelihood-derivation-for-boldsymbolbetaboldsymbolbeta",
            "text": "Differentiating above equation w.r.t.  \\beta_j \\beta_j  we get the following:   \\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial \\beta_j} & = -0 - 0 - \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ij})}{2\\sigma_i^2}\n\\end{split}  \\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial \\beta_j} & = -0 - 0 - \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ij})}{2\\sigma_i^2}\n\\end{split}   Equating above equation to 0 we get:   \\begin{split}\n\\sum_{i = 1}^{N} \\frac{(y_i -\\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(x_{ij})}{\\sigma_i^2} & = 0\\\\\n\\end{split}  \\begin{split}\n\\sum_{i = 1}^{N} \\frac{(y_i -\\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(x_{ij})}{\\sigma_i^2} & = 0\\\\\n\\end{split}   In matrix form, above equation can be written as:   \\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{n1}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = 0 \n\\end{split}  \\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{n1}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = 0 \n\\end{split}   Similarly for other  \\beta \\beta \u2019s we get the same format. Putting all of\nthem in one matrix we will get the following.   \\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{N1}\\\\\nx_{12} & x_{22} &  . & .& . & x_{N2}\\\\\n. & . & . & . & . & . & . \\\\\n. & . & . & . & . & . & . \\\\\nx_{1p} & x_{22} &  . & .& . & x_{Np}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = \n\\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0 \n\\end{bmatrix}\n\\end{split}  \\begin{split}\n\\begin{bmatrix}\nx_{11} & x_{21} &  . & .& . & x_{N1}\\\\\nx_{12} & x_{22} &  . & .& . & x_{N2}\\\\\n. & . & . & . & . & . & . \\\\\n. & . & . & . & . & . & . \\\\\nx_{1p} & x_{22} &  . & .& . & x_{Np}\n\\end{bmatrix} \n\\begin{bmatrix}\n\\frac{y_1 - \\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{y_2 - \\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{y_N - \\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = \n\\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0 \n\\end{bmatrix}\n\\end{split}   Denoting the left  P P x N N  matrix as  A A . Putting Y term on RHS we\nget the following:   \\begin{split}\nA \\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = A \\begin{bmatrix}\n\\frac{y_1}{\\sigma_1^2}\\\\\n\\frac{y_2}{\\sigma_2^2}\\\\\n.\\\\\n.\\\\\n\\frac{y_N}{\\sigma_N^2}\n\\end{bmatrix}\n\\end{split}  \\begin{split}\nA \\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix}  = A \\begin{bmatrix}\n\\frac{y_1}{\\sigma_1^2}\\\\\n\\frac{y_2}{\\sigma_2^2}\\\\\n.\\\\\n.\\\\\n\\frac{y_N}{\\sigma_N^2}\n\\end{bmatrix}\n\\end{split}   Above equation can again be decomposed into simpler form by expanding\nevery row entry of matrix column matrix in L.H.S.   \\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{x_{11}}{\\sigma_1^2} & \\frac{x_{12}}{\\sigma_1^2} & . & . & \\frac{x_{1p}}{\\sigma_1^2}\\\\ \n\\frac{x_{21}}{\\sigma_2^2} & \\frac{x_{22}}{\\sigma_2^2} & . & . & \\frac{x_{2p}}{\\sigma_2^2}\\\\ \n. & . & . & . & . \\\\\n\\frac{x_{N1}}{\\sigma_N^2} & \\frac{x_{N2}}{\\sigma_N^2} & . & . & \\frac{x_{Np}}{\\sigma_N^2}\\\\   \n\\end{bmatrix} \\begin{bmatrix}\n\\beta_1\\\\\n\\beta_2\\\\\n.\\\\\n.\\\\\n\\beta_p \n\\end{bmatrix}  \\begin{bmatrix}\n\\frac{\\textbf{x}_\\textbf{1}^T\\boldsymbol{\\beta} }{\\sigma_1^2} \\\\\n\\frac{\\textbf{x}_\\textbf{2}^T\\boldsymbol{\\beta} }{\\sigma_2^2} \\\\\n.\\\\\n.\\\\\n\\frac{\\textbf{x}_\\textbf{N}^T\\boldsymbol{\\beta} }{\\sigma_N^2} \n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{x_{11}}{\\sigma_1^2} & \\frac{x_{12}}{\\sigma_1^2} & . & . & \\frac{x_{1p}}{\\sigma_1^2}\\\\ \n\\frac{x_{21}}{\\sigma_2^2} & \\frac{x_{22}}{\\sigma_2^2} & . & . & \\frac{x_{2p}}{\\sigma_2^2}\\\\ \n. & . & . & . & . \\\\\n\\frac{x_{N1}}{\\sigma_N^2} & \\frac{x_{N2}}{\\sigma_N^2} & . & . & \\frac{x_{Np}}{\\sigma_N^2}\\\\   \n\\end{bmatrix} \\begin{bmatrix}\n\\beta_1\\\\\n\\beta_2\\\\\n.\\\\\n.\\\\\n\\beta_p \n\\end{bmatrix}   Assuming  B B  to be the  N N x P P  of R.H.S of above equation. Now we\ncan write eq. (1.3) as   \\boldsymbol{AB}\\boldsymbol{\\beta} =\\boldsymbol{AY_{\\sigma}}  \\boldsymbol{AB}\\boldsymbol{\\beta} =\\boldsymbol{AY_{\\sigma}}   \\boldsymbol{AB} \\boldsymbol{AB}  will be a  P P x P P  matrix, and if it is invertible\nthen we can write the solution for  \\boldsymbol{\\beta} \\boldsymbol{\\beta}  as following:   \\begin{split}\n\\boldsymbol{\\beta} = \\boldsymbol{(AB)^{-1}}\\boldsymbol{AY_{\\sigma}}\n\\end{split}  \\begin{split}\n\\boldsymbol{\\beta} = \\boldsymbol{(AB)^{-1}}\\boldsymbol{AY_{\\sigma}}\n\\end{split}",
            "title": "1.1.b Maximum likelihood derivation for \\boldsymbol{\\beta}\\boldsymbol{\\beta}"
        },
        {
            "location": "/solution_hw_2/#smooth-co-efficients",
            "text": "",
            "title": "Smooth co-efficients"
        },
        {
            "location": "/solution_hw_2/#12a",
            "text": "To apply natural ordering we have to add extra regularization term in\nthe residual square of sum term. Without natural ordering \\boldsymbol{RSS(\\beta)} \\boldsymbol{RSS(\\beta)}  looks like following   \\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2\n\\end{split}  \\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2\n\\end{split}   Adding additional constrain of natural ordering   \\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2 + \\frac{1}{2}\\gamma\\sum_{i=1}^{p-1} \\left( \\beta_i - \\beta_{i+1}\n\\right)^2\n\\end{split}  \\begin{split}\n\\boldsymbol{RSS(\\beta)} = \\sum_{i =1 }^{n} \\frac{(y_i - \\boldsymbol{x_i^T\\beta})}{\\sigma^2} + \\frac{1}{2}\\lambda||\\boldsymbol{\\beta}||^2 + \\frac{1}{2}\\gamma\\sum_{i=1}^{p-1} \\left( \\beta_i - \\beta_{i+1}\n\\right)^2\n\\end{split}",
            "title": "1.2.a"
        },
        {
            "location": "/solution_hw_2/#12b",
            "text": "Taking the first derivative and equating it to zero.Note: The derivative\nw.r.t  \\beta_1 \\beta_1  and  \\beta_p \\beta_p  will be different from the rest  \\beta's \\beta's   \\begin{split}\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_1} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i1})}{2\\sigma^2} + \\lambda \\beta_1 + \\gamma\\left(\\beta_1 - \\beta_2\n\\right) = 0\\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_2} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i2})}{2\\sigma^2} + \\lambda \\beta_2 - \\gamma\\left(\\beta_1 + \\beta_3\n\\right) = 0 \\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_3} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i3})}{2\\sigma^2} + \\lambda \\beta_3 - \\gamma\\left(\\beta_2 + \\beta_4\n\\right) = 0 \\\\\n... \\\\\n...\\\\ \n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_p} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ip})}{2\\sigma^2} + \\lambda \\beta_p + \\gamma\\left(\\beta_p + \\beta_{p-1}\n\\right) = 0 \n\\end{split}  \\begin{split}\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_1} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i1})}{2\\sigma^2} + \\lambda \\beta_1 + \\gamma\\left(\\beta_1 - \\beta_2\n\\right) = 0\\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_2} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i2})}{2\\sigma^2} + \\lambda \\beta_2 - \\gamma\\left(\\beta_1 + \\beta_3\n\\right) = 0 \\\\\n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_3} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{i3})}{2\\sigma^2} + \\lambda \\beta_3 - \\gamma\\left(\\beta_2 + \\beta_4\n\\right) = 0 \\\\\n... \\\\\n...\\\\ \n\\frac{\\partial \\boldsymbol{RSS(\\beta)} }{\\partial \\beta_p} & = \\sum_{i = 1}^{N}\\frac{2*(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta})*(-x_{ip})}{2\\sigma^2} + \\lambda \\beta_p + \\gamma\\left(\\beta_p + \\beta_{p-1}\n\\right) = 0 \n\\end{split}   Writing above system of linear equation in matrix form.   \\begin{split}\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma\\begin{bmatrix}\n\\beta_2 - \\beta_1\\\\\n\\beta_1 + \\beta_3\\\\\n.\\\\\n.\\\\\n\\beta_{p-1} - \\beta_p\n\\end{bmatrix} &  = \\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0\n\\end{bmatrix}\\\\\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma \\begin{bmatrix}\n-1 & 1 & 0 & 0 & . & . & 0 \\\\\n1 & 0 & 1 & 0 & . & . & 0 \\\\\n0 & 1 & 0 & 1 & . & . & 0 \\\\\n. & . & . & . & . & .& . \\\\\n. & . & . & . & . & .& . \\\\\n0 & 0 & 0 & 0 & . & 1 & -1 \\\\\n\\end{bmatrix}\\boldsymbol{\\beta} = \\boldsymbol{0}\n\\end{split}  \\begin{split}\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma\\begin{bmatrix}\n\\beta_2 - \\beta_1\\\\\n\\beta_1 + \\beta_3\\\\\n.\\\\\n.\\\\\n\\beta_{p-1} - \\beta_p\n\\end{bmatrix} &  = \\begin{bmatrix}\n0\\\\\n0\\\\\n.\\\\\n.\\\\\n0\n\\end{bmatrix}\\\\\n-A \\left(Y - A^T\\boldsymbol{\\beta}\\right) + \\lambda\\boldsymbol{\\beta} - \\gamma \\begin{bmatrix}\n-1 & 1 & 0 & 0 & . & . & 0 \\\\\n1 & 0 & 1 & 0 & . & . & 0 \\\\\n0 & 1 & 0 & 1 & . & . & 0 \\\\\n. & . & . & . & . & .& . \\\\\n. & . & . & . & . & .& . \\\\\n0 & 0 & 0 & 0 & . & 1 & -1 \\\\\n\\end{bmatrix}\\boldsymbol{\\beta} = \\boldsymbol{0}\n\\end{split}   Simplifying above equation will lead to the following:   \\begin{split}\nAA^T\\boldsymbol{\\beta} + \\lambda\\boldsymbol{\\beta} - \\gamma K \\boldsymbol{\\beta} & = AY\\\\\n\\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)\\boldsymbol{\\beta} & = AY \\\\\n\\implies \\boldsymbol{\\beta} & = \\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)^ {-1} AY \n\\end{split}  \\begin{split}\nAA^T\\boldsymbol{\\beta} + \\lambda\\boldsymbol{\\beta} - \\gamma K \\boldsymbol{\\beta} & = AY\\\\\n\\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)\\boldsymbol{\\beta} & = AY \\\\\n\\implies \\boldsymbol{\\beta} & = \\left( AA^T + \\lambda\\boldsymbol{I} - \\gamma K \n\\right)^ {-1} AY \n\\end{split}",
            "title": "1.2.b"
        },
        {
            "location": "/solution_hw_2/#linearly-constrained-linear-regression",
            "text": "Here we are given the following:   y = \\boldsymbol{x^T\\beta} + \\varepsilon  y = \\boldsymbol{x^T\\beta} + \\varepsilon   and the parameters have additional linear constrain as:   A\\boldsymbol{\\beta} = \\boldsymbol{b}  A\\boldsymbol{\\beta} = \\boldsymbol{b}   The above equation has non-empty solution.Writing the log likelihood\nequation by referring (1.1) with new symbol of \\boldsymbol{\\beta} =\\boldsymbol{\\beta}^\\star \\boldsymbol{\\beta} =\\boldsymbol{\\beta}^\\star   \\begin{split}\n \\ell (\\boldsymbol{\\beta}) & =  -\\frac{N}{2}\\log 2\\pi - N\\log(\\sigma) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & =  -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^2}\n\\end{split}  \\begin{split}\n \\ell (\\boldsymbol{\\beta}) & =  -\\frac{N}{2}\\log 2\\pi - N\\log(\\sigma) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) -  \\sum_{i = 1}^{N}\\frac{(y_i - \\textbf{x}_\\textbf{i}^T\\boldsymbol{\\beta^\\star} )^2}{2\\sigma^2}\\\\\n & =  -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log(\\sigma^2) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^2}\n\\end{split}   Where   \\begin{split}\nY = \\begin{bmatrix}\ny_1 & y_2 & . &. &. & y_N\n\\end{bmatrix}^T\n\\boldsymbol{X} = \\begin{bmatrix}\nx_{11} & x_{12} & x_{13} & . & . & . & x_{1P}\\\\\nx_{21} & x_{22} & x_{23} & . & . & . & x_{2P}\\\\\n. & . & . & . & . & . & .\\\\\n. & . & . & . & . & . & .\\\\\nx_{N1} & x_{N2} & x_{N3} & . & . & . & x_{NP}\n\\end{bmatrix}\n\\end{split}  \\begin{split}\nY = \\begin{bmatrix}\ny_1 & y_2 & . &. &. & y_N\n\\end{bmatrix}^T\n\\boldsymbol{X} = \\begin{bmatrix}\nx_{11} & x_{12} & x_{13} & . & . & . & x_{1P}\\\\\nx_{21} & x_{22} & x_{23} & . & . & . & x_{2P}\\\\\n. & . & . & . & . & . & .\\\\\n. & . & . & . & . & . & .\\\\\nx_{N1} & x_{N2} & x_{N3} & . & . & . & x_{NP}\n\\end{bmatrix}\n\\end{split}   The idea here is to use Lagrangian multiplier in order to address the\nlinear constrain. Here we can see that the variance does not have any\nconstraint. We can get estimate of variance, and then plug that into\nlikelihood, thereafter we can apply Lagrangian multiplier.First getting\nthe estimate for variance:   \\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial\\sigma^2} & = -\\frac{N}{2\\sigma^2} -  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2}*\\left(\\frac{-1}{\\sigma^4}\n\\right)\\\\\n& = -\\frac{N}{2\\sigma^2} + \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^4}\n\\end{split}  \\begin{split}\n\\frac{\\partial\\ell(\\boldsymbol{\\beta})}{\\partial\\sigma^2} & = -\\frac{N}{2\\sigma^2} -  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2}*\\left(\\frac{-1}{\\sigma^4}\n\\right)\\\\\n& = -\\frac{N}{2\\sigma^2} + \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2\\sigma^4}\n\\end{split}   equating above equation to zero will give us the estimate of  \\sigma^2 \\sigma^2 \nas a function of constrained  \\boldsymbol{\\beta^\\star} \\boldsymbol{\\beta^\\star}   \\sigma ^2 =  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}  \\sigma ^2 =  \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}   Putting the value of  \\sigma^2 \\sigma^2  in eq. (1.4)   \\begin{split}\n \\ell (\\boldsymbol{\\beta}) & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2 \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}} \\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{N}{2}\n\\end{split}  \\begin{split}\n \\ell (\\boldsymbol{\\beta}) & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{2 \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}} \\\\\n & = -\\frac{N}{2}\\log 2\\pi - \\frac{N}{2}\\log\\left( \\frac{(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})}{N}\\right) - \\frac{N}{2}\n\\end{split}   Now we have to maximize with the linear constrain on parameter. In other\nterms we just have to minimize the term inside log in above equation. We\nhave to do the following. Minimize   \\begin{split}\n&(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})\\\\\n& A\\boldsymbol{\\beta^\\star} = \\boldsymbol{b}\n\\end{split}  \\begin{split}\n&(Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star})\\\\\n& A\\boldsymbol{\\beta^\\star} = \\boldsymbol{b}\n\\end{split}   Writing the Lagrangian multiplier for above problem   \\begin{split}\nJ & = (Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star}) + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - Y^T\\boldsymbol{X\\beta^\\star} - \\boldsymbol{\\beta^{\\star T} X^T}Y + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - 2Y^T\\boldsymbol{X\\beta^\\star}  + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} +\\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\vspace{5pt}\\\\\n  & \\hspace{20pt}\\text{because both terms are essentially the same}\n\\end{split}  \\begin{split}\nJ & = (Y - \\boldsymbol{X\\beta^\\star})^T(Y - \\boldsymbol{X\\beta^\\star}) + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - Y^T\\boldsymbol{X\\beta^\\star} - \\boldsymbol{\\beta^{\\star T} X^T}Y + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} + \\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\\\\n  & = Y^TY - 2Y^T\\boldsymbol{X\\beta^\\star}  + \\boldsymbol{\\beta^{\\star T} X^TX\\beta^\\star} +\\lambda ( A\\boldsymbol{\\beta^\\star} -\\boldsymbol{b} )\\vspace{5pt}\\\\\n  & \\hspace{20pt}\\text{because both terms are essentially the same}\n\\end{split}   Differentiating w.r.t to  \\boldsymbol{\\beta^\\star} \\boldsymbol{\\beta^\\star}   \\begin{split}\n\\frac{\\partial J}{\\partial \\beta^\\star}  & = -2Y^T\\boldsymbol{X} + 2\\boldsymbol{\\beta^{\\star T}X^TX} + \\lambda A  = 0 \\\\\n\\end{split}  \\begin{split}\n\\frac{\\partial J}{\\partial \\beta^\\star}  & = -2Y^T\\boldsymbol{X} + 2\\boldsymbol{\\beta^{\\star T}X^TX} + \\lambda A  = 0 \\\\\n\\end{split}   To make it easier for calculation, taking transpose on both side.   \\begin{split}\n-2\\boldsymbol{X^T}Y + 2\\boldsymbol{X^TX\\beta^\\star} + \\lambda A^T & = 0 \\\\\n\\lambda A^T & = 2\\left(\\boldsymbol{X^T}Y - \\boldsymbol{X^TX\\beta^\\star} \\right)\n\\end{split}  \\begin{split}\n-2\\boldsymbol{X^T}Y + 2\\boldsymbol{X^TX\\beta^\\star} + \\lambda A^T & = 0 \\\\\n\\lambda A^T & = 2\\left(\\boldsymbol{X^T}Y - \\boldsymbol{X^TX\\beta^\\star} \\right)\n\\end{split}   Multiplying with  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A\\left(\\boldsymbol{X^TX}\\right)^{-1}   \\begin{split}\n\\lambda A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T & = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - A\\boldsymbol{\\beta^\\star}\n\\right)\\\\\n& = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\lambda & = 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right) \n\\end{split}  \\begin{split}\n\\lambda A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T & = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - A\\boldsymbol{\\beta^\\star}\n\\right)\\\\\n& = 2 \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\lambda & = 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right) \n\\end{split}   simplifying first term of eq. (1.6) for  \\boldsymbol{\\beta^\\star} \\boldsymbol{\\beta^\\star}   \\begin{split}\n2\\boldsymbol{X^TX\\beta^\\star} & = 2\\boldsymbol{X^T}Y - \\lambda A^T\\\\\n& = 2\\boldsymbol{X^T}Y  - 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\boldsymbol{\\beta^\\star} & = \\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\left(\\boldsymbol{X^TX}\\right)^{-1} \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\n\\end{split}  \\begin{split}\n2\\boldsymbol{X^TX\\beta^\\star} & = 2\\boldsymbol{X^T}Y - \\lambda A^T\\\\\n& = 2\\boldsymbol{X^T}Y  - 2 \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\\\\\n\\implies\n\\boldsymbol{\\beta^\\star} & = \\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\left(\\boldsymbol{X^TX}\\right)^{-1} \\left(  A\\left(\\boldsymbol{X^TX}\\right)^{-1} A^T\n\\right)^ {-1} \\left( A\\left(\\boldsymbol{X^TX}\\right)^{-1}\\boldsymbol{X^T}Y - \\boldsymbol{b}\n\\right)\n\\end{split}",
            "title": "Linearly constrained linear regression"
        },
        {
            "location": "/solution_hw_2/#online-learning",
            "text": "Here the objective function is to minimize the L2 norm of the difference\nof the update. For perceptron to classify the current input following\ncondition must satisfy:   \\begin{split}\ny_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n} > 0\n\\end{split}  \\begin{split}\ny_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n} > 0\n\\end{split}   we have to minimize the following with above mentioned constraint.   \\begin{split}\n1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2\n\\end{split}  \\begin{split}\n1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2\n\\end{split}   Minimizing L2 sqaured norm is as good as minimizing L2 norm. Writing\nexpression in Lagrangian format   \\begin{split}\n\\boldsymbol{L} = 1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2 + \\lambda * (y_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n}  )\n\\end{split}  \\begin{split}\n\\boldsymbol{L} = 1/2*||\\boldsymbol{w_{i+1}} - \\boldsymbol{w_i}||_2^2 + \\lambda * (y_n\\boldsymbol{w_{i+1}}^T\\boldsymbol{x_n}  )\n\\end{split}   differentiating w.r.t. to  \\boldsymbol{w_{i+1}} \\boldsymbol{w_{i+1}}  and equating it to\nzero.   \\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\boldsymbol{w_{i+1}}} & = 1/2 * \\left(2*\\boldsymbol{w_{i+1}} - 2*\\boldsymbol{w_i} + *\\lambda*y_n * \\boldsymbol{x_n}\n\\right) = 0 \\\\\n\\boldsymbol{w_{i+1}} & = \\boldsymbol{w_i} -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}}{2}\n\\end{split}  \\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\boldsymbol{w_{i+1}}} & = 1/2 * \\left(2*\\boldsymbol{w_{i+1}} - 2*\\boldsymbol{w_i} + *\\lambda*y_n * \\boldsymbol{x_n}\n\\right) = 0 \\\\\n\\boldsymbol{w_{i+1}} & = \\boldsymbol{w_i} -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}}{2}\n\\end{split}   Differential  L L  w.r.t  \\lambda \\lambda  leads to the following   \\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\lambda} & = y_n\\boldsymbol{w_{i+1}}^T \\boldsymbol{x_n}  = 0 \\\\\n\\implies y_n\\left( \\boldsymbol{w_i}^T -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}^T}{2}\n\\right) * \\boldsymbol{x_n} & = 0 \\\\\n\\implies \\lambda = \\frac{2*\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\end{split}  \\begin{split}\n\\frac{\\partial \\boldsymbol{L}}{\\partial \\lambda} & = y_n\\boldsymbol{w_{i+1}}^T \\boldsymbol{x_n}  = 0 \\\\\n\\implies y_n\\left( \\boldsymbol{w_i}^T -  \\frac{\\lambda*y_n*\\boldsymbol{x_n}^T}{2}\n\\right) * \\boldsymbol{x_n} & = 0 \\\\\n\\implies \\lambda = \\frac{2*\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\end{split}    \\begin{split}\n\\boldsymbol{w_{i+1}} = \\boldsymbol{w_i} - \\left(\\frac{\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\right)* y_n*\\boldsymbol{x_n}\n\\end{split}  \\begin{split}\n\\boldsymbol{w_{i+1}} = \\boldsymbol{w_i} - \\left(\\frac{\\boldsymbol{w_i}^T\\boldsymbol{x_n}}{y_n||\\boldsymbol{x_n}||^2}\n\\right)* y_n*\\boldsymbol{x_n}\n\\end{split}",
            "title": "Online learning"
        },
        {
            "location": "/solution_hw_2/#kernels",
            "text": "",
            "title": "Kernels"
        },
        {
            "location": "/solution_hw_2/#3a",
            "text": "\\begin{aligned}\nK_3 & =  a_1K_1 + a_2K_2\\\\\n&  a_1\\geq 0 , a_2 \\geq 0\\end{aligned}  \\begin{aligned}\nK_3 & =  a_1K_1 + a_2K_2\\\\\n&  a_1\\geq 0 , a_2 \\geq 0\\end{aligned}   Since  K_1 K_1  and  K_2 K_2  are positive semidefinite matrix. So for any\nvector X X , we h ave the following inequality   \\begin{split}\nX^TK_1X \\geq 0,\\space\nX^TK_2X \\geq 0 \n\\end{split}  \\begin{split}\nX^TK_1X \\geq 0,\\space\nX^TK_2X \\geq 0 \n\\end{split}   Taking any vector X and evaluating  X^TK_3X X^TK_3X   \\begin{split}\nX^TK_3X & = X^T (a_1K_1 + a_2K_2)X\\\\\n& = X^Ta_1K_1X + X^Ta_aK_2X\\\\\n& = a_1X^TK_1X + a_2X^TK_2X \\\\\n&\\geq 0 \n\\end{split}  \\begin{split}\nX^TK_3X & = X^T (a_1K_1 + a_2K_2)X\\\\\n& = X^Ta_1K_1X + X^Ta_aK_2X\\\\\n& = a_1X^TK_1X + a_2X^TK_2X \\\\\n&\\geq 0 \n\\end{split}",
            "title": "3.a"
        },
        {
            "location": "/solution_hw_2/#3b",
            "text": "K_4 K_4  has been defined by kernel function  k_4(x_1,x_2) = f(x_1)f(x_2) k_4(x_1,x_2) = f(x_1)f(x_2) \n, the matrix representation will look like following:   \\begin{split}\nK_4 & = \\begin{bmatrix}\nk_4(x_1,x_1) & k_4(x_1,x_2) &  . & .& . & k_4(x_1, x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & . \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)f(x_1) & f(x_1)f(x_2) &  . & .& . & f(x_1)f(x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)\\\\\nf(x_2)\\\\\n.  \\\\\n.  \\\\\nf(x_N)\n\\end{bmatrix} \\begin{bmatrix}\nf(x_1) & f(x_2) & . & . & f(x_N)\n\\end{bmatrix}\\\\\n& = \\boldsymbol{FF^T}\n\\end{split}  \\begin{split}\nK_4 & = \\begin{bmatrix}\nk_4(x_1,x_1) & k_4(x_1,x_2) &  . & .& . & k_4(x_1, x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & . \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)f(x_1) & f(x_1)f(x_2) &  . & .& . & f(x_1)f(x_N)\\\\\nk_4(x_2,x_1) & k_4(x_2,x_2) &  . & .& . & k_4(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_4(x_N,x_1) & k_4(x_N,x_2) &  . & .& . & k_4(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nf(x_1)\\\\\nf(x_2)\\\\\n.  \\\\\n.  \\\\\nf(x_N)\n\\end{bmatrix} \\begin{bmatrix}\nf(x_1) & f(x_2) & . & . & f(x_N)\n\\end{bmatrix}\\\\\n& = \\boldsymbol{FF^T}\n\\end{split}   Now taking any vector  X X  and evaluating  X^TK_4X X^TK_4X   \\begin{split}\nX^TK_4X & = X^T\\boldsymbol{FF^T}X \\\\\n& = (\\boldsymbol{F^T}X)^T \\boldsymbol{F^T}X\\\\\n& = ||\\boldsymbol{F^T}X||^2\\\\\n& \\geq 0\n\\end{split}  \\begin{split}\nX^TK_4X & = X^T\\boldsymbol{FF^T}X \\\\\n& = (\\boldsymbol{F^T}X)^T \\boldsymbol{F^T}X\\\\\n& = ||\\boldsymbol{F^T}X||^2\\\\\n& \\geq 0\n\\end{split}   Therefore  K_4 K_4  is also a positive semidefinite matrix.",
            "title": "3.b"
        },
        {
            "location": "/solution_hw_2/#3c",
            "text": "K_5 K_5  has been defined by kernel function k_5(x_1,x_2) = k_1(x_1, x_2)k_2(x_1,x_2) k_5(x_1,x_2) = k_1(x_1, x_2)k_2(x_1,x_2)  , the matrix representation\nwill look like following:   \\begin{split}\nK_5 & = \\begin{bmatrix}\nk_5(x_1,x_1) & k_5(x_1,x_2) &  . & .& . & k_5(x_1, x_N)\\\\\nk_5(x_2,x_1) & k_5(x_2,x_2) &  . & .& . & k_5(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_5(x_N,x_1) & k_5(x_N,x_2) &  . & .& . & k_5(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nk_1(x_1,x_1)k_2(x_1,x_1) & k_1(x_1,x_2)k_2(x_1,x_2) &  . & .& . & k_1(x_1,x_N)k_2(x_1,x_N)\\\\\nk_1(x_2,x_1)k_2(x_2,x_1) & k_1(x_2,x_2)k_2(x_2,x_2) &  . & .& . & k_1(x_2, x_N)k_2(x_2,x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_1(x_N,x_1)k_2(x_N,x_1) & k_1(x_N,x_2)k_2(x_N,x_2) &  . & .& . & k_1(x_N, x_N)k_2(x_N,x_N)\n\\end{bmatrix}\n\\end{split}  \\begin{split}\nK_5 & = \\begin{bmatrix}\nk_5(x_1,x_1) & k_5(x_1,x_2) &  . & .& . & k_5(x_1, x_N)\\\\\nk_5(x_2,x_1) & k_5(x_2,x_2) &  . & .& . & k_5(x_2, x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_5(x_N,x_1) & k_5(x_N,x_2) &  . & .& . & k_5(x_N, x_N)\n\\end{bmatrix}\\\\\n& = \\begin{bmatrix}\nk_1(x_1,x_1)k_2(x_1,x_1) & k_1(x_1,x_2)k_2(x_1,x_2) &  . & .& . & k_1(x_1,x_N)k_2(x_1,x_N)\\\\\nk_1(x_2,x_1)k_2(x_2,x_1) & k_1(x_2,x_2)k_2(x_2,x_2) &  . & .& . & k_1(x_2, x_N)k_2(x_2,x_N)\\\\\n. & . & . & . & . & .  \\\\\n. & . & . & . & . & .  \\\\\nk_1(x_N,x_1)k_2(x_N,x_1) & k_1(x_N,x_2)k_2(x_N,x_2) &  . & .& . & k_1(x_N, x_N)k_2(x_N,x_N)\n\\end{bmatrix}\n\\end{split}   Referring to Wikipedia web resource about Hadamard product, Schur\nproduct theorem it can be proved that the above kernel function is PSD\n(by the help of Wick\u2019s theorem). Since  k_1 k_1  and  k_2 k_2  are kernel\nfunction (so the matrix will be PSD). and their entrywise multiplication\n(Hadamard product) is the above resulting matrix. So it will be a PSD.",
            "title": "3.c"
        },
        {
            "location": "/solution_hw_2/#bias-variance-tradeoff",
            "text": "",
            "title": "Bias Variance Tradeoff"
        },
        {
            "location": "/solution_hw_2/#programming",
            "text": "",
            "title": "Programming"
        },
        {
            "location": "/solution_hw_2/#data-preparation",
            "text": "",
            "title": "Data preparation"
        },
        {
            "location": "/solution_hw_2/#feature-representation",
            "text": "",
            "title": "Feature representation"
        },
        {
            "location": "/solution_hw_2/#1",
            "text": "Top 3 most frequent words found in spam/ham data set are as following   enron    600 \n    will    351 \n   please   291     In ionosphere data I have used 1 for label \u201cg\u201d and 0 for label \u201cb\u201d.\nInitialization and extreme conditions has been considered during\nimplementation.",
            "title": "(1)"
        },
        {
            "location": "/solution_hw_2/#batch-gradient-descent",
            "text": "",
            "title": "Batch Gradient descent"
        },
        {
            "location": "/solution_hw_2/#2",
            "text": "Updating equation of  \\boldsymbol{w} \\boldsymbol{w}  and b. Here  \\boldsymbol{x} \\boldsymbol{x}  is N N x P P  vector where  N N  is number of data points, and  P P  is feature\ndimension.  y y  is  N N x 1 1  vector.  \\boldsymbol{w} \\boldsymbol{w}  is  P P x 1 1  vector and \\boldsymbol{b}_t \\boldsymbol{b}_t  is a  N N x 1 1  vector with each row having same values\nwhich is equal to bias. Without regularization:   \\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}  \\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}   With Regularization:   \\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n+ 2*\\lambda*\\boldsymbol{w}_t\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}  \\begin{split}\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - \\eta*\\left(\\boldsymbol{x}^T\\left(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t) - \\boldsymbol{y}\n\\right)\n+ 2*\\lambda*\\boldsymbol{w}_t\n\\right)\\\\\nb_{t+1} & = b_{t} - \\eta * \\left(\\boldsymbol{y}^T* (1 - \\sigma(\\boldsymbol{b}_t + \\boldsymbol{x}\\boldsymbol{w}_t) - (1- \\boldsymbol{y}) *(\\sigma(\\boldsymbol{b}_t+\\boldsymbol{x}\\boldsymbol{w}_t))\n\\right)\n\\end{split}",
            "title": "(2)"
        },
        {
            "location": "/solution_hw_2/#3a_1",
            "text": "fig:example  fig:example",
            "title": "(3)a"
        },
        {
            "location": "/solution_hw_2/#3b_1",
            "text": "L2 L2  norm of  \\boldsymbol{w} \\boldsymbol{w}  after 50 iterations for each step size \\eta_i \\eta_i",
            "title": "(3)b"
        },
        {
            "location": "/solution_hw_2/#4a",
            "text": "fig:example  fig:example",
            "title": "(4)a"
        },
        {
            "location": "/solution_hw_2/#4b",
            "text": "",
            "title": "(4)b"
        },
        {
            "location": "/solution_hw_2/#4c",
            "text": "fig:example  fig:example",
            "title": "(4)c"
        },
        {
            "location": "/solution_hw_2/#5",
            "text": "Note: Here we add one column (with all entries = 1 ) in the beginning of\ninput data matrix and the seed intercept  b b  as row 1 in the weight\nvector to inculcate the bias.  Without Regularization:  (Using the\nnotations and assumptions of (2)) Here I am using the derivation of\nHessian directly because it was already described in assignment #1.\nHere  H_b H_b  is used for second derivative w.r.t. bias.   \\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n \\right)\n \\right) \\\\\n H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n  \\right) \\\\\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\nb_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}  \\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n \\right)\n \\right) \\\\\n H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n  \\right) \\\\\n\\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\nb_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}   **With Regularization** In this case we shall add  2*\\lambda 2*\\lambda  to\ndiagonal entries of the hessian matrx that we found in case of without\nregularization(because for  i\\neq j i\\neq j  the second derivative will be zero\nfor regularized term). And in the first derivative we shall have 2*\\lambda*\\boldsymbol{w} 2*\\lambda*\\boldsymbol{w}  added to the weight vector. The bias is not\naffected by regularization.   \\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x} + 2*\\lambda*\\boldsymbol{I}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n  \\right)\n  \\right) \\\\\n  H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n   \\right) \\\\\n \\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\n b_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}  \\begin{split}\nH & = \\frac{\\partial^2 \\varepsilon(\\boldsymbol{w},b)}{\\boldsymbol{ww^T}} \\\\\n & = \\boldsymbol{x^T}\\sigma(b+ \\boldsymbol{xw})(1-\\sigma(\\boldsymbol{b}+\\boldsymbol{xw}))\\boldsymbol{x} + 2*\\lambda*\\boldsymbol{I}\\\\\n \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b} & = - \\left( \\sum_{i = 1}^{N} \\left( y_i - \\sigma(b + \\boldsymbol{x_iw}\n  \\right)\n  \\right) \\\\\n  H_b =  \\frac{\\partial^2(\\varepsilon(\\boldsymbol{w},b))}{\\partial b^2} & = \\sum_{i=1}^{N} \\left(\\sigma(b + \\boldsymbol{xw})*(1-\\sigma(b + \\boldsymbol{xw})\n   \\right) \\\\\n \\boldsymbol{w_{t+1}} & = \\boldsymbol{w_t} - H_t^{-1}\\nabla\\varepsilon_t \\\\\n b_{t+1} & = b_t - (H_b)^{-1} * \\frac{\\partial(\\varepsilon(\\boldsymbol{w},b))}{\\partial b}\n\\end{split}",
            "title": "(5)"
        },
        {
            "location": "/solution_hw_2/#6a",
            "text": "fig:example  fig:example",
            "title": "(6)a"
        },
        {
            "location": "/solution_hw_2/#6b",
            "text": "L2 norm of w without regularization:",
            "title": "(6)b"
        },
        {
            "location": "/solution_hw_2/#6c",
            "text": "Cross entropy of test data using newtons method (showed upto steps where\nit converges)",
            "title": "(6)c"
        },
        {
            "location": "/solution_hw_2/#7a",
            "text": "fig:example  fig:example",
            "title": "(7)a"
        },
        {
            "location": "/solution_hw_2/#7b",
            "text": "L2 norm of vector  \\boldsymbol{w} \\boldsymbol{w}",
            "title": "(7)b"
        },
        {
            "location": "/solution_hw_2/#8",
            "text": "In (3)a we see that with increase in step size overdamped situation is\nfound. Even with the regularization (in 4(a)) we see the spikes. The\nbehavior with higher values of  \\lambda \\lambda  in training and testing cross\nentropies with different step sizes. At higher values of step size and\nhigh values of lambda we expect to see the high value of CE which can be\nseen in the plots. In newton method we can see very sharp convergence\nwithin 5 steps, but we do see the trade off in time complexity w.r.t\ngradient descent method. It has not been reported but I did see giving\ngood values of weight vector newton method converges very fast",
            "title": "(8)"
        }
    ]
}